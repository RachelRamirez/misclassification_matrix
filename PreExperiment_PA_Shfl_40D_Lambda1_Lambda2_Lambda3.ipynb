{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJN5cGe+PHXd+cUs6Ray0r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachelRamirez/misclassification_matrix/blob/main/PreExperiment_PA_Shfl_40D_Lambda1_Lambda2_Lambda3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PreExperiment PA Shfl 40D Lambda1 Lambda2 Lambda3\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_t4Z4Nq-gQ26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In prior notebooks, I experimented with one variable; lambda, the value the cost-matrix takes on for whatever misclassification we are interested in.  The seeded neural network we trained using a normal cost-matrix of all ones usually had a higher misclassification count on the true 9s being mislabelled as 4s, which you will sometimes see written as \"9T, 4P\" or, \"w[9t,4p]\".\n",
        "\n",
        "We changed the lambda values and allowed as many epochs of training with  early-stopping and a patience of 10 to conclude once training was beginnnig to overfit the validation data (also the test set).   Lambda values chosen were 1, 10, 100, and 1000.   These values were chosen because it seemed that only very high values like 1000 could drive down the number of misclassifications of 9T,4P to zero.\n",
        "\n",
        "In this notebook, continuing to use a relatively balanced dataset, we're going to also experiment with a second variable, time of training.  This is a little more tricky to define because the variable lambda is thought to have an impact on the number of epochs needed.  Therefore if you have a certain lambda value in the beginning of training, you may only need 10 total epochs of training, but if you use it at the end of training, you may need more epochs of training.  In addition there is the question as to whether we should define   a static number of epochs or to allow early stopping.  \n",
        "\n",
        "As an example:\n",
        "\n",
        "\n",
        "|Lambda | Rep 1 Epochs | Rep 2 Epochs |  Rep 3 | Rep 4 |\tRep 5 |\tRep 6\t| Rep 7\t| Rep 8\t|Rep 9\t| Rep 10 |  Average of 10 Reps |\n",
        "|-- | -- | --- |  --| -- |  --| -- |  --| -- |  --| -- |  --| \n",
        "1\t|17|19|19|\t22|\t17\t|21\t|19\t|22\t|19|\t22|\t... 19*\n",
        "100 |14|14|14|\t11|\t14\t|14\t|14\t|14\t|14|\t14|\t... 13.7*\n",
        "1000:\t|18|23|22|\t35|\t7\t|25\t|21\t|19\t|23|\t24|\t... 21.7\n",
        "\n",
        "*However 1 and 100 were done with patience of 3, whereas 1000 was done with patience of 10 and more epochs.  Rerunning the 1's with the same patience appears to up the number of epochs til early stopping to mid-20s.  \n",
        "\n",
        "\n",
        "We'll test the conditions for using a static training cycle first, because it's easier to code and report on, and then test how to do a dynamic training cycle, \n"
      ],
      "metadata": {
        "id": "5u6fp0kHg4tG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reduced  capacity neural network with two layers of 40 connections\n",
        "\n",
        "  Filename \"PA_Shfl_w[9,4]_2.0_40D_Misclassification_Cost_Matrix_Example\""
      ],
      "metadata": {
        "id": "NqL4ADhFLsqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check timezone if incorrect restart"
      ],
      "metadata": {
        "id": "l4sBTo67FC9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How to change the local time in Google Colab\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/US/Eastern /etc/localtime\n",
        "!date\n",
        "\n",
        "#If this doesn't show the local time correctly, then you need to restart.\n",
        "import time\n",
        "time.localtime(time.time())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4I5Wm-6EPYR",
        "outputId": "81cf0a3f-a3a6-4d72-edc8-04cccb52d64c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu 02 Mar 2023 06:41:55 PM EST\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "time.struct_time(tm_year=2023, tm_mon=3, tm_mday=2, tm_hour=23, tm_min=41, tm_sec=56, tm_wday=3, tm_yday=61, tm_isdst=0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reproducible Seeds"
      ],
      "metadata": {
        "id": "Wn15dbArlsIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For Reproducibility\n",
        "import numpy as np\n",
        "# np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "import tensorflow as tf\n",
        "# tf.random.set_seed(33)\n",
        "\n",
        "import random as python_random\n",
        "# python_random.seed(4)\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed\n",
        "tf.keras.utils.set_random_seed(342) #Possibly use next iteration if the above doesn't work\n",
        "\n",
        "\n",
        "# Running more than once causes variation.  try adding this:\n",
        "# Set seed value\n",
        "seed_value = 56\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "print(\"TF version: \" , tf.__version__ )\n",
        "print(\"Keras version: \" , tf.keras.__version__ )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcjDfFIIbmbo",
        "outputId": "8e8fc2ea-7f32-4091-a438-e85fd3529750"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version:  2.11.0\n",
            "Keras version:  2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import rest of Library"
      ],
      "metadata": {
        "id": "mTW-hEgnlp44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from https://github.com/keras-team/keras/issues/2115#issuecomment-204060456\n",
        "# witha correction on the weighted function in the middle \n",
        "\n",
        "'''Train a simple deep NN on the MNIST dataset.\n",
        "Get to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function  #do i still need this?\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.utils import np_utils\n",
        "import keras.backend as K\n",
        "from itertools import product\n",
        "import functools\n",
        "from functools import partial\n",
        "from time import ctime\n",
        "from time import sleep\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "## MORE REPEATABILITY STUFF NEEDED - If theres a way to update this to V2 of Tensorflow great, otherwise I had to use TF 1.0 code\n",
        "# 5. Configure a new global `tensorflow` session (https://stackoverflow.com/questions/50659482/why-cant-i-get-reproducible-results-in-keras-even-though-i-set-the-random-seeds)\n",
        "# from keras import backend as K\n",
        "\n",
        "\n",
        "#I believe thecode below is to help things be repeatable each time different sections in my google colab notebook execute\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)"
      ],
      "metadata": {
        "id": "idfYNyyAgMsO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define batch, epochs, and format data"
      ],
      "metadata": {
        "id": "otcbfKF7mY9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256 # I originally had it very  high batch size to reduce the variation in the data each batch and hope it makes the model training more nearly identical which it did, then i bring it back down to something reasonable to get better results training the NN\n",
        "nb_classes = 10\n",
        "nb_epoch = 45\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B59UXDb8i8W5",
        "outputId": "ab003c6c-34ad-4e94-aab0-5b92c304e7bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weighted Categorical Cross Entropy Class"
      ],
      "metadata": {
        "id": "3fHQHrz8MwXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightedCategoricalCrossentropy(tf.keras.losses.CategoricalCrossentropy):\n",
        "\n",
        "  def __init__(self, cost_mat, name='weighted_categorical_crossentropy', **kwargs):\n",
        "\n",
        "    cost_mat = np.array(cost_mat)   \n",
        "    ## when loading from config, self.cost_mat returns as a list, rather than an numpy array. \n",
        "    ## Adding the above line fixes this issue, enabling .ndim to call sucessfully. \n",
        "    ## However, this is probably not the best implementation\n",
        "    assert(cost_mat.ndim == 2)\n",
        "    assert(cost_mat.shape[0] == cost_mat.shape[1])\n",
        "    super().__init__(name=name, **kwargs)\n",
        "    self.cost_mat = K.cast_to_floatx(cost_mat)\n",
        "\n",
        "  def __call__(self, y_true, y_pred, sample_weight=None):\n",
        "    assert sample_weight is None, \"should only be derived from the cost matrix\"  \n",
        "    return super().__call__(\n",
        "        y_true=y_true, \n",
        "        y_pred=y_pred, \n",
        "        sample_weight=get_sample_weights(y_true, y_pred, self.cost_mat),\n",
        "    )\n",
        "\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    # Calling .update on the line above, during assignment, causes an error with config becoming None-type.\n",
        "    config.update({'cost_mat': (self.cost_mat)})\n",
        "    return config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    # something goes wrong here and changes self.cost_mat to a list variable.\n",
        "    # See above for temporary fix\n",
        "    return cls(**config)\n",
        "\n",
        "def get_sample_weights(y_true, y_pred, cost_m):\n",
        "    num_classes = len(cost_m)\n",
        "\n",
        "    y_pred.shape.assert_has_rank(2)\n",
        "    assert(y_pred.shape[1] == num_classes)\n",
        "    y_pred.shape.assert_is_compatible_with(y_true.shape)\n",
        "\n",
        "    y_pred = K.one_hot(K.argmax(y_pred), num_classes)\n",
        "\n",
        "    y_true_nk1 = K.expand_dims(y_true, 2)\n",
        "    y_pred_n1k = K.expand_dims(y_pred, 1)\n",
        "    cost_m_1kk = K.expand_dims(cost_m, 0)\n",
        "\n",
        "    sample_weights_nkk = cost_m_1kk * y_true_nk1 * y_pred_n1k\n",
        "    sample_weights_n = K.sum(sample_weights_nkk, axis=[1, 2])\n",
        "\n",
        "    return sample_weights_n\n",
        "\n",
        "\n",
        "# Register the loss in the Keras namespace to enable loading of the custom object.\n",
        "tf.keras.losses.WeightedCategoricalCrossentropy = WeightedCategoricalCrossentropy\n",
        " "
      ],
      "metadata": {
        "id": "pUR1sLQ7MvVa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WeightedCategoricalCross Entropy Function "
      ],
      "metadata": {
        "id": "-uJmU0t4ANuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PA_method_epoch(cost_matrix, nb_epoch = 45, patience = 10 , **args):\n",
        "\n",
        "  model3 = Sequential()\n",
        "  model3.add(Dense(40, input_shape=(784,), kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model3.add(Activation('relu'))\n",
        "  model3.add(Dropout(0.2))\n",
        "  model3.add(Dense(40, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model3.add(Activation('relu'))\n",
        "  model3.add(Dropout(0.2))\n",
        "  model3.add(Dense(10,kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model3.add(Activation('softmax'))\n",
        "\n",
        "  rms = RMSprop()  #https://keras.io/api/optimizers/rmsprop/\n",
        "\n",
        "  model3.compile(loss=WeightedCategoricalCrossentropy(cost_matrix), optimizer=rms,  metrics='categorical_accuracy',)\n",
        "\n",
        "  #https://www.tensorflow.org/tensorboard/image_summaries\n",
        "  #I want to display the number of misclassifications for a certain value on the confusion matrix\n",
        "  #this existing code is to display the confusion matrix as an image to tensorboard each epoch\n",
        "  #I just need to use model.predict()\n",
        "  #I convert to confusion matrix\n",
        "  # and subset the confusion matrix to the right value\n",
        "  # and print that value\n",
        "\n",
        "  def log_confusion_matrix(epoch, logs):\n",
        "    # Use the model to predict the values from the validation dataset.\n",
        "    y_prediction = model3.predict(X_test)\n",
        "    y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "\n",
        "    #Create confusion matrix \n",
        "    cm = confusion_matrix(y_test, y_prediction)\n",
        "    print(cm)\n",
        "    print(\"4t,9p: \", cm[4,9])\n",
        "    print(\"9t,4p: \", cm[9,4])\n",
        "    # # Log the confusion matrix as an image summary.\n",
        "    # with file_writer_cm.as_default():\n",
        "    #   tf.summary.image(\"epoch_confusion_matrix\", cm_image, step=epoch)\n",
        "\n",
        "  # Define the per-epoch callback.\n",
        "  cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
        "\n",
        "  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, verbose=1, restore_best_weights = True)\n",
        "\n",
        "  # # Print the batch number at the beginning of every batch.\n",
        "  # batch_print_callback = tf.keras.callbacks.LambdaCallback(\n",
        "  #     on_batch_begin=lambda batch,logs: print(batch))\n",
        "\n",
        "\n",
        "  model3_history = model3.fit(X_train, Y_train,\n",
        "            batch_size=batch_size, epochs=nb_epoch, verbose=2,\n",
        "            validation_data=(X_test, Y_test), shuffle=True, use_multiprocessing=True\n",
        "            ,callbacks = [es_callback, cm_callback]\n",
        "            )\n",
        "\n",
        " \n",
        "\n",
        "  #Predict\n",
        "  y_prediction = model3.predict(X_test)\n",
        "  y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "  # Y_prediction = np_utils.to_categorical(y_prediction, nb_classes)\n",
        "\n",
        "  #Create confusion matrix and normalizes it over predicted (columns)\n",
        "  # result = confusion_matrix(y_test, y_prediction , normalize='pred')\n",
        "\n",
        "  \n",
        "\n",
        "  cm3 = confusion_matrix(y_test, y_prediction)\n",
        "  cm3 = pd.DataFrame(cm3, range(10),range(10))\n",
        "  # plt.figure(figsize = (10,10))\n",
        "  # cm3\n",
        "  # sns.heatmap(cm2, annot=True, annot_kws={\"size\": 12}) # font size\n",
        "  # plt.show()\n",
        "  # cm_using_weighted_new = cm3\n",
        "\n",
        "  # print(model3_history.history)\n",
        "  tot_epochs = max(model3_history.epoch)+1  #if the total epochs ran is 28, it'll show up as 27 in the epoch object so we must add 1\n",
        "  print(\"Total Epochs: \", tot_epochs)\n",
        "\n",
        "  #if tot_epochs is the total number of epochs ran then early stop did not happen, and we need not minus patience\n",
        "  if tot_epochs == nb_epoch:\n",
        "    restored_weights = tot_epochs\n",
        "  else:\n",
        "    restored_weights  = tot_epochs-patience   #when using restore-best-weights and patience, it'll restore the best weights back\n",
        "  print(\"Restored weights at \", restored_weights)\n",
        "  \n",
        "\n",
        "\n",
        "  #Label is the epoch weights are restored \n",
        "  label = f\"{restored_weights}\"\n",
        "  #Label_vale is the value at which the epoch weights are restored \n",
        "  label_value = f\"{ model3_history.history['val_categorical_accuracy'][restored_weights]}\"\n",
        "  print(\"Label: \", label, \"Val_Cat_Acc Value: \", label_value)\n",
        "\n",
        "\n",
        "\n",
        "  plt.plot(range(1,tot_epochs+1), model3_history.history['categorical_accuracy'],)\n",
        "  plt.plot(range(1,tot_epochs+1), model3_history.history['val_categorical_accuracy'])\n",
        "  plt.xlim(xmin=1)\n",
        "\n",
        "  plt.scatter((restored_weights), model3_history.history['val_categorical_accuracy'][restored_weights-1] , color='orange')\n",
        "\n",
        "  plt.annotate(text=label,  xy=(restored_weights, model3_history.history['val_categorical_accuracy'][restored_weights-1]),\n",
        "                 textcoords=\"offset points\", \n",
        "                 xytext=(0,10), \n",
        "                 ha='center')\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch (starts at 1)')\n",
        "\n",
        "  \n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  \n",
        "\n",
        "  plt.plot(range(1,tot_epochs+1), model3_history.history['loss'])\n",
        "  plt.plot(range(1,tot_epochs+1), model3_history.history['val_loss'])\n",
        "  plt.xlim(xmin=1)\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch (starts at 1)')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.scatter(restored_weights, model3_history.history['val_loss'][restored_weights-1])\n",
        "  plt.annotate(text=label,  xy=(restored_weights, model3_history.history['val_loss'][restored_weights-1]),\n",
        "                 textcoords=\"offset points\", \n",
        "                 xytext=(0,10), \n",
        "                 ha='center')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return cm3, model3_history, model3"
      ],
      "metadata": {
        "id": "3UWVdmRHNBhP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Keep Track of Experimental Admin Stuff - #Runs and #CostMatrix\n",
        "\n",
        "> Change the cost matrix and number of runs and check the file extension name \n"
      ],
      "metadata": {
        "id": "skXIN6S4npiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Define Cost Matrix and Method"
      ],
      "metadata": {
        "id": "q9YhLRi4NU2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimental Admin Stuff\n",
        "cost_matrix = np.ones((10,10))\n",
        "\n",
        "### Weight of Misclassification\n",
        "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "cost_matrix[9, 4] = 1\n",
        "cost_str = str(cost_matrix[9, 4])\n",
        "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "\n",
        "\n",
        "### File Extension to reference in JMP : weights_method_cost\n",
        "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "file_extension = \"w[9,4]_PA_\" + cost_str + \"_Shfl_40D_\"\n",
        "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "print(\"Last run using \", cost_str)"
      ],
      "metadata": {
        "id": "3bMXTRRBnn3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154d0d17-e3ae-4116-b4da-48f4fce650a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last run using  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run Experiments"
      ],
      "metadata": {
        "id": "x_EdEdJwOpvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "cm = np.zeros([10,10])\n",
        "combined_cms = np.empty((1,100))\n",
        "\n",
        "combined_history_dictionary = {}  #because there will be a unknown number of epochs a dictionary is probly a better fit\n",
        "combined_history_list       = []\n",
        "\n",
        "\n",
        "## Define the total number of runs\n",
        "### ~~~~~~~~~\n",
        "runs = 1\n",
        "### ~~~~~~~~~~\n",
        "\n",
        "#its easier for me to count my runs as \"1 and up\" instead of 0...   \n",
        "for i in range(1,runs+1):\n",
        "  cost_matrix[9, 4] = 1000\n",
        "  print(\"Run \", i, \"Starting with a  cost_matrix[9, 4] = \",  cost_matrix[9, 4] , \" for 45 epochs with Early Stopping and Restore Best Weights ... \")\n",
        "\n",
        "\n",
        "  cm2 , history, model =  PA_method_epoch(cost_matrix,nb_epoch=45 )    #Individual CM, and Training/Validation History\n",
        "  print(\"After first stage CM: \\n\", cm2)\n",
        "\n",
        "  print(\"After first stage CM[9,4]: \\n\", cm2[4][9])\n",
        "  \n",
        "\n",
        "\n",
        "  combined_history_dictionary[i] = history\n",
        "  combined_history_list.append(history)\n",
        "  # cm += cm2                   #Aggregating for an Average\n",
        "  cm2_array = np.asarray(cm2)  #Indiv CM as array for storing\n",
        "  combined_cms = np.vstack((combined_cms,cm2_array.reshape((1,100))))\n",
        "\n",
        "# ###############################\n",
        "# ## Code to update the fitted model with the new cost matrix\n",
        "# ###############################\n",
        "\n",
        "# cost_matrix[9, 4] = 1000\n",
        "\n",
        "# print(\"Run \", i, \" continued, with a  cost_matrix[9, 4] = \",  cost_matrix[9, 4] , \" for 45 epochs and Early Stopping on Val_Loss of patience 20 ... \")\n",
        "\n",
        "\n",
        "# rms = RMSprop()  #https://keras.io/api/optimizers/rmsprop/\n",
        "# patience  = 20\n",
        "\n",
        "# model.compile(loss=WeightedCategoricalCrossentropy(cost_matrix), optimizer=rms,  metrics='categorical_accuracy',)\n",
        "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, verbose=1, restore_best_weights = True)\n",
        "# model_history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=2,\n",
        "#               validation_data=(X_test, Y_test), shuffle=True, use_multiprocessing=True,callbacks = [callback])\n",
        "\n",
        "\n",
        "\n",
        "# #Predict\n",
        "# y_prediction = model.predict(X_test)\n",
        "# y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# cm3 = confusion_matrix(y_test, y_prediction)\n",
        "# cm3 = pd.DataFrame(cm3, range(10),range(10))\n",
        "# cm3\n",
        "\n",
        "# #Label is the epoch weights are restored \n",
        "# label = f\"{max(model_history.epoch)-patience}\"\n",
        "\n",
        " \n",
        "# plt.plot(model_history.history['categorical_accuracy'])\n",
        "# plt.plot(model_history.history['val_categorical_accuracy'])\n",
        "# plt.scatter(x=(max(model_history.epoch)-patience), y=model_history.history['val_categorical_accuracy'][max(model_history.epoch)-patience])\n",
        "\n",
        "# plt.annotate(text=label,  xy=(max(model_history.epoch)-patience, model_history.history['val_categorical_accuracy'][max(model_history.epoch)-patience]),\n",
        "#                 textcoords=\"offset points\", \n",
        "#                 xytext=(0,10), \n",
        "#                 ha='center')\n",
        "# plt.title('model accuracy')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "\n",
        "\n",
        "# plt.legend(['train', 'val'], loc='upper left')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# plt.plot(model_history.history['loss'])\n",
        "# plt.plot(model_history.history['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'val'], loc='upper left')\n",
        "# plt.scatter(x=(max(model_history.epoch)-patience), y=model_history.history['val_loss'][max(model_history.epoch)-patience])\n",
        "# plt.annotate(text=label,  xy=(max(model_history.epoch)-patience, model_history.history['val_loss'][max(model_history.epoch)-patience]),\n",
        "#                 textcoords=\"offset points\", \n",
        "#                 xytext=(0,10), \n",
        "#                 ha='center')\n",
        "# plt.show()\n",
        "\n",
        "# print(\"After second stage CM: \\n\", cm3)\n",
        "\n",
        "# print(\"After second stage CM[9,4]: \\n\",cm3[4][9])  #First number is COLUMN, second number is ROW so column 4 is Prediction is 4, Row 9 is Truly a Label 9\n",
        "  \n",
        "\n",
        "#######\n",
        "\n",
        "# cm_new = cm/30"
      ],
      "metadata": {
        "id": "OSq7jMYUOF4t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd1a559d-2b67-47a0-f4c7-194b2011dfc0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run  1 Starting with a  cost_matrix[9, 4] =  1000.0  for 45 epochs with Early Stopping and Restore Best Weights ... \n",
            "Epoch 1/45\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "[[ 930    0    1    2    0    7   21    1   15    3]\n",
            " [   0 1094   17    3    0    0    4    0   15    2]\n",
            " [  13   11  872   29    0    1   23   10   52   21]\n",
            " [   3    3   31  873    0   36    1   12   27   24]\n",
            " [   5    7    5    0   60    4   19    3   13  866]\n",
            " [  12    2    7   34    1  714   16   10   68   28]\n",
            " [  25    4   13    0    2   13  888    2   10    1]\n",
            " [   0   42   11    5    2    0    1  819   10  138]\n",
            " [  14   23   16   19    4   39   11    9  781   58]\n",
            " [   9    6    2   11    0    4    1   22    6  948]]\n",
            "866\n",
            "0\n",
            "235/235 - 5s - loss: 2.3161 - categorical_accuracy: 0.6047 - val_loss: 0.5747 - val_categorical_accuracy: 0.7979 - 5s/epoch - 21ms/step\n",
            "Epoch 2/45\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "[[ 955    0    0    1    0    6   12    1    5    0]\n",
            " [   0 1106    5    4    0    0    3    2   14    1]\n",
            " [  16   11  903   13    0    1   13   14   47   14]\n",
            " [   3    4   26  879    0   47    2   15   28    6]\n",
            " [   2    3    3    0  124    0   13    1    8  828]\n",
            " [  15    1    5   27    1  760   14    6   48   15]\n",
            " [  18    4    6    0    3   14  905    1    6    1]\n",
            " [   2   18   13    3    1    0    1  939    4   47]\n",
            " [  11   10   13   13    4   32   10   15  843   23]\n",
            " [   9    4    1   10    0    9    1   27    7  941]]\n",
            "828\n",
            "0\n",
            "235/235 - 3s - loss: 1.2011 - categorical_accuracy: 0.7688 - val_loss: 0.4085 - val_categorical_accuracy: 0.8355 - 3s/epoch - 13ms/step\n",
            "Epoch 3/45\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "[[ 953    0    1    1    1    5   13    1    5    0]\n",
            " [   0 1112    4    4    0    0    3    2    9    1]\n",
            " [  12    8  930   14    3    0   12   12   30   11]\n",
            " [   2    3   24  923    1   24    0   13   16    4]\n",
            " [   1    3    2    0  276    0   15    0    5  680]\n",
            " [  10    1    2   35    3  776   16    4   31   14]\n",
            " [  11    4    2    0    2   14  918    0    6    1]\n",
            " [   2   12   20    3    5    0    0  942    2   42]\n",
            " [   7    8   13   17    4   24   13   13  865   10]\n",
            " [   7    5    0   13    0    6    1   20    5  952]]\n",
            "680\n",
            "0\n",
            "235/235 - 3s - loss: 1.0509 - categorical_accuracy: 0.8168 - val_loss: 0.3387 - val_categorical_accuracy: 0.8647 - 3s/epoch - 15ms/step\n",
            "Epoch 4/45\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "[[ 960    0    1    1    0    3    7    1    5    2]\n",
            " [   0 1111    4    5    0    0    3    1   10    1]\n",
            " [  13    3  947   11    3    0    8   12   26    9]\n",
            " [   2    3   20  934    0   18    1   15   14    3]\n",
            " [   2    4    4    0  224    0    9    1    4  734]\n",
            " [   8    1    2   35    2  787   11    3   29   14]\n",
            " [  17    4    2    0    3   14  907    0    7    4]\n",
            " [   1    9   19    6    1    0    0  959    0   33]\n",
            " [   8    4    9   13    2   21    9   16  874   18]\n",
            " [   6    3    0   15    0    4    0   15    5  961]]\n",
            "734\n",
            "0\n",
            "235/235 - 2s - loss: 0.9591 - categorical_accuracy: 0.8411 - val_loss: 0.3297 - val_categorical_accuracy: 0.8664 - 2s/epoch - 11ms/step\n",
            "Epoch 5/45\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "[[ 956    0    0    1    2    5   12    2    2    0]\n",
            " [   0 1114    4    3    0    1    3    2    7    1]\n",
            " [   8    4  960    9    5    0    7    7   22   10]\n",
            " [   1    3   26  936    2   17    0   12   10    3]\n",
            " [   1    3    6    0  249    0   14    0    4  705]\n",
            " [   6    1    2   32    2  802   11    2   21   13]\n",
            " [  10    4    2    0    4   13  919    0    3    3]\n",
            " [   3    8   22    3    3    0    0  953    0   36]\n",
            " [   6    6   11   11    7   23    9   14  872   15]\n",
            " [   9    5    0   14    0    5    0   16    4  956]]\n",
            "705\n",
            "0\n",
            "235/235 - 3s - loss: 0.8238 - categorical_accuracy: 0.8573 - val_loss: 0.3057 - val_categorical_accuracy: 0.8717 - 3s/epoch - 13ms/step\n",
            "Epoch 6/45\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "[[ 953    0    0    1    4    5   10    2    5    0]\n",
            " [   0 1103    4    4    1    0    3    1   18    1]\n",
            " [   6    4  946   15    6    1    5    9   33    7]\n",
            " [   0    1   11  955    1   12    0   12   15    3]\n",
            " [   1    1    4    0  476    0   11    1    7  481]\n",
            " [   5    1    0   23    4  814   11    0   23   11]\n",
            " [   9    4    1    0    6   22  910    0    5    1]\n",
            " [   1   10   18    7    2    1    1  960    1   27]\n",
            " [   4    5    6   12    7   17    6   10  901    6]\n",
            " [   4    4    0   16    0    8    1    9    4  963]]\n",
            "481\n",
            "0\n",
            "235/235 - 2s - loss: 0.7809 - categorical_accuracy: 0.8693 - val_loss: 0.2631 - val_categorical_accuracy: 0.8981 - 2s/epoch - 10ms/step\n",
            "Epoch 7/45\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "[[ 950    0    0    1    4    5   11    2    5    2]\n",
            " [   0 1111    4    3    0    0    3    1   12    1]\n",
            " [   5    3  959   13    1    1    5   13   24    8]\n",
            " [   0    2   18  954    1    9    0   12   10    4]\n",
            " [   1    3    3    0  247    0   10    1    4  713]\n",
            " [   5    1    2   33    3  805   12    1   19   11]\n",
            " [  10    4    2    0    4    7  924    0    4    3]\n",
            " [   1   11   15    8    2    0    0  966    1   24]\n",
            " [   4    4    9   12    4   16    9    9  893   14]\n",
            " [   5    5    0   17    0    5    0    9    4  964]]\n",
            "713\n",
            "0\n",
            "235/235 - 3s - loss: 0.8232 - categorical_accuracy: 0.8663 - val_loss: 0.2808 - val_categorical_accuracy: 0.8773 - 3s/epoch - 11ms/step\n",
            "Epoch 8/45\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "[[ 958    0    0    1    2    5    9    1    2    2]\n",
            " [   0 1117    4    4    0    0    3    1    5    1]\n",
            " [   7    3  955   12    2    1    5   13   25    9]\n",
            " [   0    2   14  953    1   11    0   12   11    6]\n",
            " [   2    2    4    0  345    0   10    1    3  615]\n",
            " [   6    1    2   23    3  817   10    2   14   14]\n",
            " [  11    4    1    0    3   11  921    0    4    3]\n",
            " [   1   11   15    6    2    0    0  970    0   23]\n",
            " [   6    7    9   11    6   12   10   11  888   14]\n",
            " [   8    5    1   12    0    7    0    8    3  965]]\n",
            "615\n",
            "0\n",
            "235/235 - 2s - loss: 0.8240 - categorical_accuracy: 0.8740 - val_loss: 0.2651 - val_categorical_accuracy: 0.8889 - 2s/epoch - 10ms/step\n",
            "Epoch 9/45\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 960    0    0    1    1    4   10    1    2    1]\n",
            " [   0 1118    3    3    0    0    4    1    5    1]\n",
            " [   8    3  961    8    2    1    5   15   21    8]\n",
            " [   0    2   17  944    1   17    0   12   15    2]\n",
            " [   1    1    3    0  363    0   15    1    3  595]\n",
            " [   6    1    1   14    3  823   14    2   16   12]\n",
            " [  10    4    0    0    4    7  930    0    2    1]\n",
            " [   3   10   15    7    0    0    0  974    0   19]\n",
            " [   9    6    5    7    5   10   14    8  899   11]\n",
            " [   9    6    0   11    0    6    0    8    3  966]]\n",
            "595\n",
            "0\n",
            "235/235 - 3s - loss: 0.6635 - categorical_accuracy: 0.8807 - val_loss: 0.2521 - val_categorical_accuracy: 0.8938 - 3s/epoch - 11ms/step\n",
            "Epoch 10/45\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 964    0    0    1    1    4    7    1    2    0]\n",
            " [   0 1115    4    4    0    1    3    1    7    0]\n",
            " [   7    2  976    9    2    1    5    8   18    4]\n",
            " [   0    1   20  947    1   19    0   10   10    2]\n",
            " [   2    1    6    0  623    0   12    0    6  332]\n",
            " [   5    0    1   16    3  838   11    2   12    4]\n",
            " [  12    3    1    0    6   11  920    0    5    0]\n",
            " [   4    8   25    3    2    0    0  972    0   14]\n",
            " [   7    4    9    9    5   12    9    8  907    4]\n",
            " [   9    4    0   14    2    7    0    9    3  961]]\n",
            "332\n",
            "2\n",
            "235/235 - 2s - loss: 0.7127 - categorical_accuracy: 0.8880 - val_loss: 0.4212 - val_categorical_accuracy: 0.9223 - 2s/epoch - 7ms/step\n",
            "Epoch 11/45\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "[[ 962    0    2    0    1    4    7    1    3    0]\n",
            " [   0 1114    3    4    0    1    3    2    8    0]\n",
            " [   7    2  974    8    1    1    5    9   19    6]\n",
            " [   0    1   16  943    1   24    0   11   12    2]\n",
            " [   1    1    5    0  675    0   18    0    3  279]\n",
            " [   4    0    1   12    1  850   12    2    5    5]\n",
            " [   9    3    0    0    4   11  928    0    3    0]\n",
            " [   4    8   17    2    0    0    0  982    1   14]\n",
            " [   5    5    8    7    5   21    9    6  901    7]\n",
            " [   8    4    0   13    3    9    0   12    3  957]]\n",
            "279\n",
            "3\n",
            "235/235 - 2s - loss: 0.7093 - categorical_accuracy: 0.8897 - val_loss: 0.5051 - val_categorical_accuracy: 0.9286 - 2s/epoch - 9ms/step\n",
            "Epoch 12/45\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 961    0    2    1    1    3    6    1    5    0]\n",
            " [   0 1117    3    3    0    1    4    1    6    0]\n",
            " [   7    2  966   11    2    1    6   11   20    6]\n",
            " [   0    1   15  958    1   13    0   11   10    1]\n",
            " [   1    1    4    0  344    0   11    1    4  616]\n",
            " [   5    0    0   20    2  835   11    2   13    4]\n",
            " [   8    5    0    0    3   11  927    0    2    2]\n",
            " [   3   11   18    4    1    0    0  978    0   13]\n",
            " [   4    4    7    9    2   13    7    3  918    7]\n",
            " [   5    7    0   19    0    4    0    9    3  962]]\n",
            "616\n",
            "0\n",
            "235/235 - 2s - loss: 0.6145 - categorical_accuracy: 0.8946 - val_loss: 0.2337 - val_categorical_accuracy: 0.8966 - 2s/epoch - 7ms/step\n",
            "Epoch 13/45\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "[[ 961    0    2    2    1    4    7    1    2    0]\n",
            " [   0 1120    4    3    0    1    3    1    3    0]\n",
            " [   7    4  975    6    1    1    5   10   17    6]\n",
            " [   0    2   13  961    1   11    0   12    9    1]\n",
            " [   1    1    4    0  417    0   13    1    4  541]\n",
            " [   5    1    1   19    1  837   11    3   10    4]\n",
            " [   7    4    0    0    3   10  931    0    2    1]\n",
            " [   3   11   16    5    0    0    0  981    0   12]\n",
            " [   6    5    5   11    4   13    7    5  910    8]\n",
            " [   6    7    0   14    0    6    0    9    3  964]]\n",
            "541\n",
            "0\n",
            "235/235 - 3s - loss: 0.5535 - categorical_accuracy: 0.8977 - val_loss: 0.2230 - val_categorical_accuracy: 0.9057 - 3s/epoch - 15ms/step\n",
            "Epoch 14/45\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 964    0    2    1    1    3    6    1    2    0]\n",
            " [   0 1116    5    3    0    1    3    1    6    0]\n",
            " [   7    4  979    8    1    1    5    9   15    3]\n",
            " [   0    1   12  968    1   10    0   10    7    1]\n",
            " [   0    1    7    0  680    1   13    0    6  274]\n",
            " [   4    0    0   22    3  833    9    2   16    3]\n",
            " [   8    4    1    0    4   12  928    0    1    0]\n",
            " [   3   11   16    6    0    0    0  978    1   13]\n",
            " [   7    4    5   13    3    9    6    3  918    6]\n",
            " [   7    8    0   16    4    7    0   10    3  954]]\n",
            "274\n",
            "4\n",
            "235/235 - 2s - loss: 0.5540 - categorical_accuracy: 0.8917 - val_loss: 0.5904 - val_categorical_accuracy: 0.9318 - 2s/epoch - 9ms/step\n",
            "Epoch 15/45\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 965    0    1    1    0    1    8    1    3    0]\n",
            " [   0 1115    4    3    0    1    3    2    7    0]\n",
            " [   8    1  981    4    1    1    7   12   14    3]\n",
            " [   0    1   13  964    1   14    0   11    5    1]\n",
            " [   0    1    6    0  516    0   12    1    3  443]\n",
            " [   4    0    0   19    3  837   11    2   13    3]\n",
            " [   7    3    1    0    4    8  932    0    3    0]\n",
            " [   3   11   15    5    1    0    0  984    0    9]\n",
            " [   7    5    6   14    3   10    8    4  910    7]\n",
            " [   6    6    0   21    0    4    0   11    2  959]]\n",
            "443\n",
            "0\n",
            "235/235 - 2s - loss: 0.6142 - categorical_accuracy: 0.8960 - val_loss: 0.2082 - val_categorical_accuracy: 0.9163 - 2s/epoch - 7ms/step\n",
            "Epoch 16/45\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 964    0    2    1    1    4    6    1    1    0]\n",
            " [   0 1116    5    3    0    1    3    1    6    0]\n",
            " [   8    1  984    2    1    1    5   12   14    4]\n",
            " [   0    1   19  953    1   15    0   12    8    1]\n",
            " [   0    1    5    0  735    0   10    1    3  227]\n",
            " [   4    0    0   13    3  843   10    5    9    5]\n",
            " [   5    2    3    0    4   11  932    0    1    0]\n",
            " [   3    9   17    4    0    0    0  985    0   10]\n",
            " [   6    3    7   13    3   12    8    5  911    6]\n",
            " [   4    5    0   13    3    9    0   12    2  961]]\n",
            "227\n",
            "3\n",
            "235/235 - 2s - loss: 0.5182 - categorical_accuracy: 0.8996 - val_loss: 0.5034 - val_categorical_accuracy: 0.9384 - 2s/epoch - 10ms/step\n",
            "Epoch 17/45\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "[[ 963    1    2    1    0    3    7    1    1    1]\n",
            " [   0 1117    4    3    0    1    4    1    5    0]\n",
            " [   7    3  982    5    3    1    4   10   13    4]\n",
            " [   0    1   17  966    1   10    0    9    6    0]\n",
            " [   0    1    6    0  630    0    8    1    5  331]\n",
            " [   5    0    0   15    3  837   12    3   11    6]\n",
            " [   7    2    2    0    5    7  933    0    2    0]\n",
            " [   3   11   15    7    0    0    0  975    1   16]\n",
            " [   6    4    5   13    3    8    7    4  920    4]\n",
            " [   5    9    0   18    2    5    0    7    3  960]]\n",
            "331\n",
            "2\n",
            "235/235 - 3s - loss: 0.5731 - categorical_accuracy: 0.9036 - val_loss: 0.4191 - val_categorical_accuracy: 0.9283 - 3s/epoch - 15ms/step\n",
            "Epoch 18/45\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "[[ 961    0    3    2    0    4    6    2    2    0]\n",
            " [   0 1113    3    5    0    1    3    2    8    0]\n",
            " [   6    1  976   11    4    1    5   11   14    3]\n",
            " [   0    0   16  961    0   14    0   11    7    1]\n",
            " [   0    0    5    0  766    1   11    1    3  195]\n",
            " [   4    0    0   17    3  841   10    4    9    4]\n",
            " [   6    3    1    0    4    9  934    0    1    0]\n",
            " [   3    8   13    7    0    0    0  987    0   10]\n",
            " [   6    3    4   11    3    9    5    5  923    5]\n",
            " [   7    5    0   17   10    7    0   14    1  948]]\n",
            "195\n",
            "10\n",
            "235/235 - 3s - loss: 0.5112 - categorical_accuracy: 0.9083 - val_loss: 1.2965 - val_categorical_accuracy: 0.9410 - 3s/epoch - 12ms/step\n",
            "Epoch 19/45\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 962    1    2    1    0    2    7    2    3    0]\n",
            " [   0 1119    4    3    0    1    3    1    4    0]\n",
            " [   7    3  984    3    4    1    5   11   10    4]\n",
            " [   0    3   17  959    0   14    0   11    5    1]\n",
            " [   0    1    5    0  322    0   11    1    3  639]\n",
            " [   4    1    0   12    2  842   11    3   10    7]\n",
            " [   5    4    1    0    3    9  934    0    1    1]\n",
            " [   2   11   13    5    0    0    0  984    0   13]\n",
            " [   6    4    5    8    3    7    5    5  924    7]\n",
            " [   6    7    0   11    0   10    0    7    2  966]]\n",
            "639\n",
            "0\n",
            "235/235 - 2s - loss: 0.6251 - categorical_accuracy: 0.9058 - val_loss: 0.2210 - val_categorical_accuracy: 0.8996 - 2s/epoch - 10ms/step\n",
            "Epoch 20/45\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 961    0    2    2    1    3    5    4    2    0]\n",
            " [   0 1117    3    3    0    1    3    2    6    0]\n",
            " [   6    2  974   10    2    1    5   13   13    6]\n",
            " [   0    0   13  964    0   12    0   13    6    2]\n",
            " [   1    1    3    0  463    0   10    1    2  501]\n",
            " [   4    0    0   15    2  842   10    4    9    6]\n",
            " [   6    2    1    0    4    7  936    0    2    0]\n",
            " [   1    9    9    5    1    0    0  993    0   10]\n",
            " [   9    4    4    9    3    9    8    5  914    9]\n",
            " [   5    5    0   11    2   10    0    9    1  966]]\n",
            "501\n",
            "2\n",
            "235/235 - 2s - loss: 0.6076 - categorical_accuracy: 0.8962 - val_loss: 0.4599 - val_categorical_accuracy: 0.9130 - 2s/epoch - 7ms/step\n",
            "Epoch 21/45\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "[[ 968    1    2    1    0    1    5    1    1    0]\n",
            " [   0 1120    4    3    0    1    3    1    3    0]\n",
            " [   7    2  979    4    4    1    6   13   14    2]\n",
            " [   0    1   16  964    0   10    0   12    5    2]\n",
            " [   1    1    5    0  593    1   11    1    3  366]\n",
            " [   4    0    0   20    1  837   12    3   10    5]\n",
            " [   6    4    1    0    4    7  935    0    1    0]\n",
            " [   2   10    9    5    1    0    0  988    1   12]\n",
            " [  10    3    5    8    3    6    5    4  921    9]\n",
            " [   5    9    0    9    1    9    1    8    4  963]]\n",
            "366\n",
            "1\n",
            "235/235 - 3s - loss: 0.4982 - categorical_accuracy: 0.9107 - val_loss: 0.2795 - val_categorical_accuracy: 0.9268 - 3s/epoch - 15ms/step\n",
            "Epoch 22/45\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 967    0    2    2    0    2    5    1    1    0]\n",
            " [   0 1116    3    2    0    1    3    1    9    0]\n",
            " [   9    3  976    6    3    1    5   12   15    2]\n",
            " [   0    1   17  952    1   16    0   11    7    5]\n",
            " [   0    1    5    0  559    0   13    1    4  399]\n",
            " [   4    0    0    8    1  846   15    4    9    5]\n",
            " [   9    2    1    0    4    7  933    0    2    0]\n",
            " [   2    9   11    6    1    0    0  986    2   11]\n",
            " [   8    3    5    5    3    6    6    4  928    6]\n",
            " [   4    5    0    9    5   10    1    7    3  965]]\n",
            "399\n",
            "5\n",
            "235/235 - 2s - loss: 0.6169 - categorical_accuracy: 0.9082 - val_loss: 0.8214 - val_categorical_accuracy: 0.9228 - 2s/epoch - 9ms/step\n",
            "Epoch 23/45\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "[[ 966    1    2    1    0    3    4    2    1    0]\n",
            " [   0 1116    4    3    0    1    3    1    7    0]\n",
            " [   6    2  991    5    4    1    4   10    7    2]\n",
            " [   0    1   14  970    0    7    0   11    6    1]\n",
            " [   1    0    6    0  600    0    7    1    4  363]\n",
            " [   4    0    0   19    2  845    7    3    8    4]\n",
            " [  11    4    1    0    4   11  926    0    1    0]\n",
            " [   2   11   14    6    1    0    0  983    0   11]\n",
            " [   7    3    4   11    2    7    5    5  925    5]\n",
            " [   3    4    0   11    3   10    0    6    2  970]]\n",
            "363\n",
            "3\n",
            "235/235 - 2s - loss: 0.5783 - categorical_accuracy: 0.9051 - val_loss: 0.5807 - val_categorical_accuracy: 0.9292 - 2s/epoch - 10ms/step\n",
            "Epoch 24/45\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 965    0    2    2    0    2    5    2    2    0]\n",
            " [   0 1118    3    3    0    0    3    1    7    0]\n",
            " [   7    5  969    8    3    1    6   14   16    3]\n",
            " [   0    1    9  968    0   10    0   12    7    3]\n",
            " [   1    0    2    1  654    0   10    2    7  305]\n",
            " [   4    0    0   14    1  843   10    3   13    4]\n",
            " [   5    4    1    0    4   10  932    0    2    0]\n",
            " [   3   11    7    5    1    0    0  989    1   11]\n",
            " [   6    4    3    8    3    5    6    4  930    5]\n",
            " [   4    6    0   10    0    8    0    6    4  971]]\n",
            "305\n",
            "0\n",
            "235/235 - 2s - loss: 0.5509 - categorical_accuracy: 0.9116 - val_loss: 0.1876 - val_categorical_accuracy: 0.9339 - 2s/epoch - 7ms/step\n",
            "Epoch 25/45\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "[[ 964    1    3    1    0    1    5    4    1    0]\n",
            " [   0 1120    4    2    0    1    3    2    3    0]\n",
            " [   7    3  986    5    2    1    6    9   10    3]\n",
            " [   0    1   14  969    1    6    0   13    6    0]\n",
            " [   1    0    5    0  672    1   15    2    4  282]\n",
            " [   4    0    0   17    0  840   12    5   11    3]\n",
            " [   9    2    1    0    4    7  933    0    2    0]\n",
            " [   2   10   14    4    0    0    0  990    0    8]\n",
            " [  11    3    4   11    3    7    7    6  918    4]\n",
            " [   3    6    0   12    4    8    1   12    2  961]]\n",
            "282\n",
            "4\n",
            "235/235 - 2s - loss: 0.6287 - categorical_accuracy: 0.9075 - val_loss: 0.7330 - val_categorical_accuracy: 0.9353 - 2s/epoch - 10ms/step\n",
            "Epoch 26/45\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 965    1    1    1    0    2    6    3    0    1]\n",
            " [   0 1120    3    3    0    1    4    1    3    0]\n",
            " [   6    3  986    4    2    1    5   11   11    3]\n",
            " [   0    0   14  962    0   13    0   11    6    4]\n",
            " [   1    0    5    0  558    0   15    2    3  398]\n",
            " [   4    0    0   10    1  849   14    3    8    3]\n",
            " [   5    4    1    0    6    7  934    0    1    0]\n",
            " [   3   10   11    5    0    0    0  983    1   15]\n",
            " [   9    5    3    8    2    7    7    6  920    7]\n",
            " [   3    4    0   10    3   11    1    5    1  971]]\n",
            "398\n",
            "3\n",
            "235/235 - 2s - loss: 0.5488 - categorical_accuracy: 0.9038 - val_loss: 0.5803 - val_categorical_accuracy: 0.9248 - 2s/epoch - 9ms/step\n",
            "Epoch 27/45\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 964    0    2    2    0    2    6    3    1    0]\n",
            " [   0 1119    4    3    0    1    3    1    4    0]\n",
            " [   7    2  992    5    2    1    5    9    6    3]\n",
            " [   0    0   15  960    0   17    0   11    5    2]\n",
            " [   1    1    5    0  547    0   13    2    5  408]\n",
            " [   4    0    0   10    0  854   11    3    7    3]\n",
            " [   8    2    2    0    4   10  929    0    2    1]\n",
            " [   2   11   12    4    0    0    0  991    1    7]\n",
            " [   8    3    5   10    3    9    6    3  922    5]\n",
            " [   4    5    0   13    1   13    0    6    2  965]]\n",
            "408\n",
            "1\n",
            "235/235 - 2s - loss: 0.5713 - categorical_accuracy: 0.9034 - val_loss: 0.2709 - val_categorical_accuracy: 0.9243 - 2s/epoch - 7ms/step\n",
            "Epoch 28/45\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "[[ 962    0    2    2    0    2    7    4    1    0]\n",
            " [   0 1117    3    3    0    1    4    1    6    0]\n",
            " [   7    2  990    2    1    1    6   10    8    5]\n",
            " [   0    1   17  961    1   11    0   13    5    1]\n",
            " [   1    0    5    0  620    0   10    1    3  342]\n",
            " [   4    0    0   10    1  847   11    5    9    5]\n",
            " [   4    3    1    0    5   10  932    0    2    1]\n",
            " [   2   12   10    4    0    0    0  991    1    8]\n",
            " [   9    4    6    9    2    6    8    4  919    7]\n",
            " [   3    6    0    9    1   11    2    6    1  970]]\n",
            "342\n",
            "1\n",
            "235/235 - 2s - loss: 0.5508 - categorical_accuracy: 0.9033 - val_loss: 0.2704 - val_categorical_accuracy: 0.9309 - 2s/epoch - 10ms/step\n",
            "Epoch 29/45\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "[[ 961    0    2    2    0    3    8    2    2    0]\n",
            " [   0 1114    3    3    0    1    3    2    9    0]\n",
            " [   6    2  991    3    2    1    6    9   10    2]\n",
            " [   0    0   16  964    1   15    0    9    5    0]\n",
            " [   1    0    5    0  717    0   15    3    4  237]\n",
            " [   4    0    0   11    1  850   12    3    9    2]\n",
            " [   4    2    1    0    3    9  936    0    2    1]\n",
            " [   2   11   13    6    1    0    0  985    1    9]\n",
            " [   7    3    5    6    2    8    9    4  926    4]\n",
            " [   4    6    0   13    1   15    2    6    2  960]]\n",
            "237\n",
            "1\n",
            "235/235 - 3s - loss: 0.4548 - categorical_accuracy: 0.9120 - val_loss: 0.2875 - val_categorical_accuracy: 0.9404 - 3s/epoch - 12ms/step\n",
            "Epoch 30/45\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "[[ 967    0    2    2    0    1    5    2    1    0]\n",
            " [   0 1112    3    3    0    1    3    1   12    0]\n",
            " [   8    2  986    5    2    1    6   12    8    2]\n",
            " [   0    0   11  962    1   13    0   14    6    3]\n",
            " [   1    0    6    0  755    1   16    2    5  196]\n",
            " [   4    0    0   11    1  849   10    4   12    1]\n",
            " [  10    4    2    0    3    7  929    0    2    1]\n",
            " [   2    9   10    6    1    0    0  992    1    7]\n",
            " [   9    2    5    4    2    5    7    5  932    3]\n",
            " [   6    3    0   10    3    7    1    8    8  963]]\n",
            "196\n",
            "3\n",
            "235/235 - 4s - loss: 0.4529 - categorical_accuracy: 0.9160 - val_loss: 0.4811 - val_categorical_accuracy: 0.9447 - 4s/epoch - 16ms/step\n",
            "Epoch 31/45\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "[[ 966    0    3    2    0    0    7    1    1    0]\n",
            " [   0 1119    3    3    0    1    3    1    5    0]\n",
            " [   6    2  987    6    2    1    4   10   11    3]\n",
            " [   0    2   15  972    0    8    0   10    2    1]\n",
            " [   1    0    7    0  669    0   14    1    4  286]\n",
            " [   5    0    0    9    1  851    9    3    9    5]\n",
            " [   9    4    2    0    3    9  929    0    1    1]\n",
            " [   2   10   10    6    1    0    0  990    0    9]\n",
            " [   9    3    4    8    2    7    8    5  923    5]\n",
            " [   4    3    0   12    2   10    1    8    1  968]]\n",
            "286\n",
            "2\n",
            "235/235 - 2s - loss: 0.4821 - categorical_accuracy: 0.9176 - val_loss: 0.4451 - val_categorical_accuracy: 0.9374 - 2s/epoch - 10ms/step\n",
            "Epoch 32/45\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "[[ 964    0    2    1    1    0    7    2    3    0]\n",
            " [   0 1122    3    3    0    2    1    1    3    0]\n",
            " [   4    3  994    3    2    1    6    8    9    2]\n",
            " [   0    2   15  967    1   11    0    9    5    0]\n",
            " [   1    0    6    0  819    0   16    1    5  134]\n",
            " [   3    0    0   14    1  848    8    3   12    3]\n",
            " [   6    4    1    0    5    8  932    0    2    0]\n",
            " [   2   12   16    7    2    0    0  981    1    7]\n",
            " [   6    5    5    7    3    5    4    3  933    3]\n",
            " [   4   12    0   16    8    9    2    5    4  949]]\n",
            "134\n",
            "8\n",
            "235/235 - 6s - loss: 0.4499 - categorical_accuracy: 0.9142 - val_loss: 0.9819 - val_categorical_accuracy: 0.9509 - 6s/epoch - 26ms/step\n",
            "Epoch 33/45\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "[[ 965    0    2    2    0    3    6    2    0    0]\n",
            " [   0 1115    4    3    0    1    4    1    7    0]\n",
            " [   4    2  999    2    2    1    4   12    4    2]\n",
            " [   0    1   18  965    0   11    0   11    4    0]\n",
            " [   1    0    7    0  648    2   11    2    3  308]\n",
            " [   3    0    0   11    0  847   12    4   10    5]\n",
            " [   7    4    1    0    4    9  931    0    1    1]\n",
            " [   2   11   10    4    1    0    0  990    1    9]\n",
            " [   9    4    8    9    2    8    6    4  920    4]\n",
            " [   4    5    0    9    1   15    1    9    3  962]]\n",
            "308\n",
            "1\n",
            "235/235 - 3s - loss: 0.5002 - categorical_accuracy: 0.9127 - val_loss: 0.2831 - val_categorical_accuracy: 0.9342 - 3s/epoch - 15ms/step\n",
            "Epoch 34/45\n",
            "Restoring model weights from the end of the best epoch: 24.\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "[[ 965    0    2    2    0    2    5    2    2    0]\n",
            " [   0 1118    3    3    0    0    3    1    7    0]\n",
            " [   7    5  969    8    3    1    6   14   16    3]\n",
            " [   0    1    9  968    0   10    0   12    7    3]\n",
            " [   1    0    2    1  654    0   10    2    7  305]\n",
            " [   4    0    0   14    1  843   10    3   13    4]\n",
            " [   5    4    1    0    4   10  932    0    2    0]\n",
            " [   3   11    7    5    1    0    0  989    1   11]\n",
            " [   6    4    3    8    3    5    6    4  930    5]\n",
            " [   4    6    0   10    0    8    0    6    4  971]]\n",
            "305\n",
            "0\n",
            "235/235 - 3s - loss: 0.4600 - categorical_accuracy: 0.9183 - val_loss: 0.4679 - val_categorical_accuracy: 0.9392 - 3s/epoch - 15ms/step\n",
            "Epoch 34: early stopping\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Total Epochs:  34\n",
            "Restored weights at  24\n",
            "Label:  24 Val_Cat_Acc Value:  0.9352999925613403\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After first stage CM: \n",
            "      0     1    2    3    4    5    6    7    8    9\n",
            "0  965     0    2    2    0    2    5    2    2    0\n",
            "1    0  1118    3    3    0    0    3    1    7    0\n",
            "2    7     5  969    8    3    1    6   14   16    3\n",
            "3    0     1    9  968    0   10    0   12    7    3\n",
            "4    1     0    2    1  654    0   10    2    7  305\n",
            "5    4     0    0   14    1  843   10    3   13    4\n",
            "6    5     4    1    0    4   10  932    0    2    0\n",
            "7    3    11    7    5    1    0    0  989    1   11\n",
            "8    6     4    3    8    3    5    6    4  930    5\n",
            "9    4     6    0   10    0    8    0    6    4  971\n",
            "After first stage CM[9,4]: \n",
            " 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dir(history) and # print(history.__dict__)  are useful for digging into what variables are inside a variable"
      ],
      "metadata": {
        "id": "s6HsboVWsimi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combined_history_dictionary[1].history['loss'] #inside each combined_history_dictionary is a list\n",
        "# combined_history_dictionary[1].history['val_loss']\n",
        "# combined_history_dictionary[1].history['categorical_accuracy']\n",
        "# combined_history_dictionary[1].history['val_categorical_accuracy']\n",
        "# combined_history_dictionary[1].epoch\n",
        "\n",
        "# len(combined_history_dictionary)  # the length is 1, but the dictionary starts at 1\n",
        "# # len(combined_history_list)      # the length is 1, but the list starts at 0\n",
        "# combined_history_list[0].history['loss'][17:19]\n",
        "# combined_history_list[0].history['val_loss'][18-1]  #epoch 18 is where my first run stopped aand restored weights.  Epoch 18 is #17 with base 0 counting.\n",
        "\n",
        "\n",
        "(combined_history_dictionary[1].history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "JMQNfNee3vWl",
        "outputId": "ffe75db0-1d39-4194-8f82-0ffd1bb4a67b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f30f1e064b32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# combined_history_dictionary[1].history['loss'] #inside each combined_history_dictionary is a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcombined_history_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# combined_history_dictionary[1].history['categorical_accuracy']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# combined_history_dictionary[1].history['val_categorical_accuracy']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# combined_history_dictionary[1].epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'combined_history_dictionary' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fxIL-2WZ6oBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fYeMRVha6oEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I need to remove the first placeholder row of zeros\n",
        "combined_cms = combined_cms[1:(runs+1)]"
      ],
      "metadata": {
        "id": "Z7qMXMuN4kS1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save the 30/X confusion matrices"
      ],
      "metadata": {
        "id": "u-MSCXKC48ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save 30 confusion matrices\n",
        "\n",
        "import pickle\n",
        "\n",
        "str_runs = str(runs)\n",
        "\n",
        "\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "today = date.today()\n",
        "file_date = today.strftime(\"%Y_%m_%d\")\n",
        "now = datetime.now() # current date and time\n",
        "file_time = now.strftime(\"%H%M\")\n",
        "print(\"time:\", file_time)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "file_name = str_runs + \"CM_\" + file_extension + \"_\" + file_date + \"_\" + file_time +  \"_.pkl\"\n",
        "print(file_name, \" will be saved with \", combined_cms.shape)\n",
        "\n",
        "with open(file_name, 'wb') as file_write:\n",
        "      \n",
        "    # A new file will be created\n",
        "    pickle.dump(combined_cms, file_write)\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "# Open the file in binary mode\n",
        "with open(file_name, 'rb') as file:\n",
        "      \n",
        "    # Call load method to deserialze\n",
        "    var = pickle.load(file)\n",
        "  \n",
        "    print(var)\n",
        "    \n",
        "print(file_name, \" was opened with \", var.shape)\n",
        "\n",
        "from google.colab import files\n",
        "files.download( file_name )  \n",
        "\n",
        "print(file_name, \".pkl was saved to Downloads \")\n"
      ],
      "metadata": {
        "id": "9purX_onqXGo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "612b5b2f-0ff3-4d38-bd7c-fd229d982c47"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1522\n",
            "1CM_w[9,4]_PA_1.0_Shfl_40D__2023_03_02_1522_.pkl  will be saved with  (1, 100)\n",
            "[[ 962.    0.    2.    0.    1.    4.    7.    1.    3.    0.    0. 1114.\n",
            "     3.    4.    0.    1.    3.    2.    8.    0.    7.    2.  974.    8.\n",
            "     1.    1.    5.    9.   19.    6.    0.    1.   16.  943.    1.   24.\n",
            "     0.   11.   12.    2.    1.    1.    5.    0.  675.    0.   18.    0.\n",
            "     3.  279.    4.    0.    1.   12.    1.  850.   12.    2.    5.    5.\n",
            "     9.    3.    0.    0.    4.   11.  928.    0.    3.    0.    4.    8.\n",
            "    17.    2.    0.    0.    0.  982.    1.   14.    5.    5.    8.    7.\n",
            "     5.   21.    9.    6.  901.    7.    8.    4.    0.   13.    3.    9.\n",
            "     0.   12.    3.  957.]]\n",
            "1CM_w[9,4]_PA_1.0_Shfl_40D__2023_03_02_1522_.pkl  was opened with  (1, 100)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_865e5175-8a1b-4487-895a-9658c179df93\", \"1CM_w[9,4]_PA_1.0_Shfl_40D__2023_03_02_1522_.pkl\", 952)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1CM_w[9,4]_PA_1.0_Shfl_40D__2023_03_02_1522_.pkl .pkl was saved to Downloads \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many categories are there in the test set?\n",
        "\n",
        "truth_num_per_category = Y_test.sum(axis=0)\n",
        "print(truth_num_per_category)"
      ],
      "metadata": {
        "id": "id_ythTutuo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3299d1b-55dd-488f-cd2d-499350f7b1a9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 980. 1135. 1032. 1010.  982.  892.  958. 1028.  974. 1009.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze \n",
        "\n",
        "I am now going to load the Average CM and try to get it in a format where I can make it a 1x100 and load all 30 CMs so that we can visualize their distributions in a a big histogram_matrix. At this point the Google Colab variables are gone and I have to reoad them "
      ],
      "metadata": {
        "id": "NP_kxNkhn6Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "empty_cm = np.zeros((10,10))  \n",
        "empty_cm=pd.DataFrame(empty_cm)\n",
        "\n",
        "empty_cm.columns = ['0p', '1p', '2p', '3p', '4p', '5p', '6p', '7p', '8p', '9p']\n",
        "empty_cm.index = ['0t', '1t', '2t', '3t', '4t', '5t', '6t', '7t', '8t', '9t']\n",
        "\n",
        "# print(myvar_cm_average)\n",
        "\n",
        "empty_cm_array = np.asarray(empty_cm)\n",
        "empty_cm_array_1_100 = np.reshape(empty_cm_array,(1,100))\n",
        "# print(cm_average_array)\n",
        "\n",
        "df = empty_cm\n",
        "df_new = pd.DataFrame(empty_cm_array_1_100,  columns=pd.MultiIndex.from_product([ df.index,df.columns]))\n",
        "df_new.columns.to_flat_index()\n",
        "df_new.columns   = ['_'.join(col) for col in df_new.columns.values]\n",
        "\n",
        "# Now convert combined_cms of size 30x100 to a panda dataframe\n",
        "combined_cms_df = pd.DataFrame(combined_cms, columns=[df_new.columns])\n",
        "\n",
        "combined_cms_df"
      ],
      "metadata": {
        "id": "kLrNJE0s53pb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "b06cdec4-bc5d-4303-f404-b0373b731c4d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0t_0p 0t_1p 0t_2p 0t_3p 0t_4p 0t_5p 0t_6p 0t_7p 0t_8p 0t_9p  ... 9t_0p  \\\n",
              "0  962.0   0.0   2.0   0.0   1.0   4.0   7.0   1.0   3.0   0.0  ...   8.0   \n",
              "\n",
              "  9t_1p 9t_2p 9t_3p 9t_4p 9t_5p 9t_6p 9t_7p 9t_8p  9t_9p  \n",
              "0   4.0   0.0  13.0   3.0   9.0   0.0  12.0   3.0  957.0  \n",
              "\n",
              "[1 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4116c292-b464-4d91-9a51-991b29731e96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>0t_0p</th>\n",
              "      <th>0t_1p</th>\n",
              "      <th>0t_2p</th>\n",
              "      <th>0t_3p</th>\n",
              "      <th>0t_4p</th>\n",
              "      <th>0t_5p</th>\n",
              "      <th>0t_6p</th>\n",
              "      <th>0t_7p</th>\n",
              "      <th>0t_8p</th>\n",
              "      <th>0t_9p</th>\n",
              "      <th>...</th>\n",
              "      <th>9t_0p</th>\n",
              "      <th>9t_1p</th>\n",
              "      <th>9t_2p</th>\n",
              "      <th>9t_3p</th>\n",
              "      <th>9t_4p</th>\n",
              "      <th>9t_5p</th>\n",
              "      <th>9t_6p</th>\n",
              "      <th>9t_7p</th>\n",
              "      <th>9t_8p</th>\n",
              "      <th>9t_9p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>962.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>957.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 100 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4116c292-b464-4d91-9a51-991b29731e96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4116c292-b464-4d91-9a51-991b29731e96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4116c292-b464-4d91-9a51-991b29731e96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_cms_df[\"9t_4p\"]"
      ],
      "metadata": {
        "id": "HgPClcrAUdxu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "6b3ee6d7-575f-4445-e4f9-70b9bd82e960"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  9t_4p\n",
              "0   3.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b59d457-8b8c-4cfd-bbbe-4e31e71d1f8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>9t_4p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b59d457-8b8c-4cfd-bbbe-4e31e71d1f8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b59d457-8b8c-4cfd-bbbe-4e31e71d1f8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b59d457-8b8c-4cfd-bbbe-4e31e71d1f8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.average(combined_cms_df[\"9t_4p\"])"
      ],
      "metadata": {
        "id": "TY59hUTadVyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9983e662-2e7d-438c-afae-ad1228ff8774"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_filename = file_name[:-4] + \".csv\"\n",
        "\n",
        "combined_cms_df.to_csv(csv_filename)\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.download(csv_filename )\n",
        "\n",
        "print(\"Downloading \", csv_filename , \" of shape \", combined_cms_df.shape)"
      ],
      "metadata": {
        "id": "ceUFAr_z9xsk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a09bcb85-7321-44d0-b8b5-176616028f06"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e7da8fed-ca65-4762-8832-ea2892e542f5\", \"1CM_w[9,4]_PA_1.0_Shfl_40D__2023_03_02_1522_.csv\", 1040)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading  1CM_w[9,4]_PA_1.0_Shfl_40D__2023_03_02_1522_.csv  of shape  (1, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(sum(var)/len(var), columns=[\"Values\"]) \n",
        "# print(df)\n",
        "\n",
        "df.style.format({\n",
        "  'Values': lambda val: f'{val:,.2f}',\n",
        "})\n",
        "\n",
        "(df.sort_values(by=\"Values\", ascending=False)[0:20])\n",
        "\n",
        "\n",
        "df_sorted = df.sort_values(by=\"Values\", ascending=False)[10:]  #the top 10 are usually diagonal\n",
        "\n",
        "\n",
        "df_sorted.style.format({\n",
        "  'Values': lambda val: f'{val:,.2f}',\n",
        "})\n",
        "\n",
        "import math\n",
        "\n",
        "print(\"On average...\")\n",
        "print(\"Num 1 misclassifications are misclassifying a \", math.floor((df_sorted[\"Values\"].index[0])/10), \" as a \", df_sorted[\"Values\"].index[0]%10, \"  (\", (df_sorted[\"Values\"].values[0]), \" times)\" )\n",
        "print(\"Num 2 misclassifications are misclassifying a \", math.floor((df_sorted[\"Values\"].index[1])/10), \" as a \", df_sorted[\"Values\"].index[1]%10, \"  (\", (df_sorted[\"Values\"].values[1]), \" times)\" )\n",
        "print(\"Num 3 misclassifications are misclassifying a \", math.floor((df_sorted[\"Values\"].index[2])/10), \" as a \", df_sorted[\"Values\"].index[2]%10, \"  (\", (df_sorted[\"Values\"].values[2]), \" times)\" )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-pGNLuE8gNrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "264b7b50-3f55-4c21-835b-0752b3bf5e5b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On average...\n",
            "Num 1 misclassifications are misclassifying a  4  as a  9   ( 279.0  times)\n",
            "Num 2 misclassifications are misclassifying a  3  as a  5   ( 24.0  times)\n",
            "Num 3 misclassifications are misclassifying a  8  as a  5   ( 21.0  times)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_percents = pd.DataFrame( ((sum(var)*100/len(var)).reshape((10,10))/truth_num_per_category).reshape((100)), columns = [\"Values\"])\n",
        "\n",
        "\n",
        "df_sorted_percents = df_percents.sort_values(by=\"Values\", ascending=False)[10:]  #the top 10 are usually diagonal\n",
        "\n",
        "df_sorted_percents.style.format({\n",
        "  'Values': lambda val: f'{val:,.2f}',\n",
        "})\n",
        "\n",
        "print(\"On average .. \")\n",
        "print(\"Num 1 percent misclassifications\", math.floor((df_sorted_percents[\"Values\"].index[0])/10), \" as \", df_sorted_percents[\"Values\"].index[0]%10, (df_sorted_percents[\"Values\"].values[0]), \" percent\" )\n",
        "print(\"Num 2 percent misclassifications\", math.floor((df_sorted_percents[\"Values\"].index[1])/10), \" as \", df_sorted_percents[\"Values\"].index[1]%10,  (df_sorted_percents[\"Values\"].values[1]), \" percent\" )\n",
        "print(\"Num 3 percent misclassifications\", math.floor((df_sorted_percents[\"Values\"].index[2])/10), \" as \", df_sorted_percents[\"Values\"].index[2]%10, (df_sorted_percents[\"Values\"].values[2]), \" percent\" )\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AKYclir2p8wk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22164a88-f585-4a9a-98d0-ae15f5c3ab20"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On average .. \n",
            "Num 1 percent misclassifications 4  as  9 27.651139742319128  percent\n",
            "Num 2 percent misclassifications 3  as  5 2.690582959641256  percent\n",
            "Num 3 percent misclassifications 8  as  5 2.3542600896860986  percent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FrT9iz3dp8rZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraneous"
      ],
      "metadata": {
        "id": "GZfPCKu_oqrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To reference later: \n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#scrollTo=UJ589fn8ST3x\n",
        "\n",
        "To train a model with class weights:\n",
        "\n",
        "```\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "weighted_model = make_model()\n",
        "weighted_model.load_weights(initial_weights)\n",
        "\n",
        "weighted_history = weighted_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stopping],\n",
        "    validation_data=(val_features, val_labels),\n",
        "\n",
        "    # The class weights go here\n",
        "    class_weight=class_weight)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "iLEt0OL5ziEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraneous information I am not using at the moment\n",
        "\n",
        "# model.compile(\n",
        "#      optimizer='adam',\n",
        "#      loss=WeightedCategoricalCrossentropy(cost_matrix)\n",
        "#      )\n",
        "\n",
        "## Model Saving\n",
        "\n",
        "# model.save(save_version_dir,save_format='tf')\n",
        "\n",
        "## Model Loading\n",
        "\n",
        "# model = tf.keras.models.load_model(\n",
        "#     save_version_dir,\n",
        "#     compile=True,\n",
        "#     custom_objects={\n",
        "#         'WeightedCategoricalCrossentropy': WeightedCategoricalCrossentropy(cost_matrix)\n",
        "#         }\n",
        "#     )\n",
        " "
      ],
      "metadata": {
        "id": "WRzuOuZeKVpJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "starting to think about how i would shape the initial, middle and late training experiments.  "
      ],
      "metadata": {
        "id": "GH-yoluLM0sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "\n",
        "\n",
        "print(\"     | --- Init --- | | --- Mid --- | | --- Late --- | \")\n",
        "for i in [\"   1\",\" 100\", \"1000\"]:\n",
        "  for j in  [\"   1\",\" 100\", \"1000\"]:\n",
        "    for k in   [\"   1\",\" 100\", \"1000\"]:\n",
        "      count+=1\n",
        "      print(f\"{count}    |     {i}     ,     {j}    ,    {k}     | \")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EisEf8F6MzFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0daf70-4003-4fe0-f156-10cd43c651c6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     | --- Init --- | | --- Mid --- | | --- Late --- | \n",
            "1    |        1     ,        1    ,       1     | \n",
            "2    |        1     ,        1    ,     100     | \n",
            "3    |        1     ,        1    ,    1000     | \n",
            "4    |        1     ,      100    ,       1     | \n",
            "5    |        1     ,      100    ,     100     | \n",
            "6    |        1     ,      100    ,    1000     | \n",
            "7    |        1     ,     1000    ,       1     | \n",
            "8    |        1     ,     1000    ,     100     | \n",
            "9    |        1     ,     1000    ,    1000     | \n",
            "10    |      100     ,        1    ,       1     | \n",
            "11    |      100     ,        1    ,     100     | \n",
            "12    |      100     ,        1    ,    1000     | \n",
            "13    |      100     ,      100    ,       1     | \n",
            "14    |      100     ,      100    ,     100     | \n",
            "15    |      100     ,      100    ,    1000     | \n",
            "16    |      100     ,     1000    ,       1     | \n",
            "17    |      100     ,     1000    ,     100     | \n",
            "18    |      100     ,     1000    ,    1000     | \n",
            "19    |     1000     ,        1    ,       1     | \n",
            "20    |     1000     ,        1    ,     100     | \n",
            "21    |     1000     ,        1    ,    1000     | \n",
            "22    |     1000     ,      100    ,       1     | \n",
            "23    |     1000     ,      100    ,     100     | \n",
            "24    |     1000     ,      100    ,    1000     | \n",
            "25    |     1000     ,     1000    ,       1     | \n",
            "26    |     1000     ,     1000    ,     100     | \n",
            "27    |     1000     ,     1000    ,    1000     | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xVGDsrmmNLed"
      }
    }
  ]
}