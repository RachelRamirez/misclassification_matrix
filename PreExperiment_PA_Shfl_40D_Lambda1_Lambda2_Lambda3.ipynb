{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2NsZvgShb8NkKXfzKsIrg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachelRamirez/misclassification_matrix/blob/main/PreExperiment_PA_Shfl_40D_Lambda1_Lambda2_Lambda3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PreExperiment PA Shfl 40D Lambda1 Lambda2 Lambda3\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_t4Z4Nq-gQ26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reduced  capacity neural network with two layers of 40 connections\n",
        "\n",
        "  Filename \"PA_Shfl_w[9,4]_2.0_40D_Misclassification_Cost_Matrix_Example\""
      ],
      "metadata": {
        "id": "NqL4ADhFLsqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its hard to see if the misclassification weight is making a difference so I am now making the neural network not as great by reducing the number of dense connections in each layer from 512 to X/40.  Realized after I saved that everything was taking 15 epochs so I need to increase training time - turns out it only needed 16"
      ],
      "metadata": {
        "id": "kq-OgF8xLiia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm changing Model Shuffle=True to see if that helps with the validation loss jumping around"
      ],
      "metadata": {
        "id": "kOGlieEKlMrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of running the  ISantaro appeared counterintuitive, because when I increased the cost of a misclassification, more misclassifications were made. It was hard to see at first because it wasn't consistently happening, it happened 7 out of 30 times, but when it happened it was a very large number of misclassifications.   So now I'm looking to compare another code implementation,  by Phil Alton here:  https://stackoverflow.com/a/61963004 "
      ],
      "metadata": {
        "id": "xW_9TgRZB0s6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember to change the [Admin File stuff]  below and the Weight Matrix before Running"
      ],
      "metadata": {
        "id": "HhaPibIBBS80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check timezone if incorrect restart"
      ],
      "metadata": {
        "id": "l4sBTo67FC9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How to change the local time in Google Colab\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/US/Eastern /etc/localtime\n",
        "!date\n",
        "\n",
        "#If this doesn't show the local time correctly, then you need to restart.\n",
        "import time\n",
        "time.localtime(time.time())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4I5Wm-6EPYR",
        "outputId": "8db4d2de-8514-42c4-eff2-8bcd1cd7e030"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed 01 Mar 2023 03:39:19 PM EST\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "time.struct_time(tm_year=2023, tm_mon=3, tm_mday=1, tm_hour=15, tm_min=39, tm_sec=19, tm_wday=2, tm_yday=60, tm_isdst=0)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reproducible Seeds"
      ],
      "metadata": {
        "id": "Wn15dbArlsIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For Reproducibility\n",
        "import numpy as np\n",
        "# np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "import tensorflow as tf\n",
        "# tf.random.set_seed(33)\n",
        "\n",
        "import random as python_random\n",
        "# python_random.seed(4)\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed\n",
        "tf.keras.utils.set_random_seed(342) #Possibly use next iteration if the above doesn't work\n",
        "\n",
        "\n",
        "# Running more than once causes variation.  try adding this:\n",
        "# Set seed value\n",
        "seed_value = 56\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "print(\"TF version: \" , tf.__version__ )\n",
        "print(\"Keras version: \" , tf.keras.__version__ )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcjDfFIIbmbo",
        "outputId": "84e11a0b-b7ef-4d76-c2ec-0dce7534ae67"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version:  2.11.0\n",
            "Keras version:  2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import rest of Library"
      ],
      "metadata": {
        "id": "mTW-hEgnlp44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from https://github.com/keras-team/keras/issues/2115#issuecomment-204060456\n",
        "# witha correction on the weighted function in the middle \n",
        "\n",
        "'''Train a simple deep NN on the MNIST dataset.\n",
        "Get to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function  #do i still need this?\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.utils import np_utils\n",
        "import keras.backend as K\n",
        "from itertools import product\n",
        "import functools\n",
        "from functools import partial\n",
        "from time import ctime\n",
        "from time import sleep\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "## MORE REPEATABILITY STUFF NEEDED - If theres a way to update this to V2 of Tensorflow great, otherwise I had to use TF 1.0 code\n",
        "# 5. Configure a new global `tensorflow` session (https://stackoverflow.com/questions/50659482/why-cant-i-get-reproducible-results-in-keras-even-though-i-set-the-random-seeds)\n",
        "# from keras import backend as K\n",
        "\n",
        "\n",
        "#I believe thecode below is to help things be repeatable each time different sections in my google colab notebook execute\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)"
      ],
      "metadata": {
        "id": "idfYNyyAgMsO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define batch, epochs, and format data"
      ],
      "metadata": {
        "id": "otcbfKF7mY9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256 # I originally had it very  high batch size to reduce the variation in the data each batch and hope it makes the model training more nearly identical which it did, then i bring it back down to something reasonable to get better results training the NN\n",
        "nb_classes = 10\n",
        "nb_epoch = 45\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B59UXDb8i8W5",
        "outputId": "80b113d5-49e8-4169-be2e-2de2cbc4bdd7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weighted Categorical Cross Entropy Class"
      ],
      "metadata": {
        "id": "3fHQHrz8MwXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightedCategoricalCrossentropy(tf.keras.losses.CategoricalCrossentropy):\n",
        "\n",
        "  def __init__(self, cost_mat, name='weighted_categorical_crossentropy', **kwargs):\n",
        "\n",
        "    cost_mat = np.array(cost_mat)   \n",
        "    ## when loading from config, self.cost_mat returns as a list, rather than an numpy array. \n",
        "    ## Adding the above line fixes this issue, enabling .ndim to call sucessfully. \n",
        "    ## However, this is probably not the best implementation\n",
        "    assert(cost_mat.ndim == 2)\n",
        "    assert(cost_mat.shape[0] == cost_mat.shape[1])\n",
        "    super().__init__(name=name, **kwargs)\n",
        "    self.cost_mat = K.cast_to_floatx(cost_mat)\n",
        "\n",
        "  def __call__(self, y_true, y_pred, sample_weight=None):\n",
        "    assert sample_weight is None, \"should only be derived from the cost matrix\"  \n",
        "    return super().__call__(\n",
        "        y_true=y_true, \n",
        "        y_pred=y_pred, \n",
        "        sample_weight=get_sample_weights(y_true, y_pred, self.cost_mat),\n",
        "    )\n",
        "\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    # Calling .update on the line above, during assignment, causes an error with config becoming None-type.\n",
        "    config.update({'cost_mat': (self.cost_mat)})\n",
        "    return config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    # something goes wrong here and changes self.cost_mat to a list variable.\n",
        "    # See above for temporary fix\n",
        "    return cls(**config)\n",
        "\n",
        "def get_sample_weights(y_true, y_pred, cost_m):\n",
        "    num_classes = len(cost_m)\n",
        "\n",
        "    y_pred.shape.assert_has_rank(2)\n",
        "    assert(y_pred.shape[1] == num_classes)\n",
        "    y_pred.shape.assert_is_compatible_with(y_true.shape)\n",
        "\n",
        "    y_pred = K.one_hot(K.argmax(y_pred), num_classes)\n",
        "\n",
        "    y_true_nk1 = K.expand_dims(y_true, 2)\n",
        "    y_pred_n1k = K.expand_dims(y_pred, 1)\n",
        "    cost_m_1kk = K.expand_dims(cost_m, 0)\n",
        "\n",
        "    sample_weights_nkk = cost_m_1kk * y_true_nk1 * y_pred_n1k\n",
        "    sample_weights_n = K.sum(sample_weights_nkk, axis=[1, 2])\n",
        "\n",
        "    return sample_weights_n\n",
        "\n",
        "\n",
        "# Register the loss in the Keras namespace to enable loading of the custom object.\n",
        "tf.keras.losses.WeightedCategoricalCrossentropy = WeightedCategoricalCrossentropy\n",
        " "
      ],
      "metadata": {
        "id": "pUR1sLQ7MvVa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WeightedCategoricalCross Entropy Function "
      ],
      "metadata": {
        "id": "-uJmU0t4ANuv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hou6f0Sp3MuO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PA_method_epoch(cost_matrix, nb_epoch = 45, patience = 10 , **args):\n",
        "\n",
        "  model3 = Sequential()\n",
        "  model3.add(Dense(40, input_shape=(784,), kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model3.add(Activation('relu'))\n",
        "  model3.add(Dropout(0.2))\n",
        "  model3.add(Dense(40, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model3.add(Activation('relu'))\n",
        "  model3.add(Dropout(0.2))\n",
        "  model3.add(Dense(10,kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model3.add(Activation('softmax'))\n",
        "\n",
        "  rms = RMSprop()  #https://keras.io/api/optimizers/rmsprop/\n",
        "\n",
        "  model3.compile(loss=WeightedCategoricalCrossentropy(cost_matrix), optimizer=rms,  metrics='categorical_accuracy',)\n",
        "\n",
        "  #https://www.tensorflow.org/tensorboard/image_summaries\n",
        "  #I want to display the number of misclassifications for a certain value on the confusion matrix\n",
        "  #this existing code is to display the confusion matrix as an image to tensorboard each epoch\n",
        "  #I just need to use model.predict()\n",
        "  #I convert to confusion matrix\n",
        "  # and subset the confusion matrix to the right value\n",
        "  # and print that value\n",
        "\n",
        "  def log_confusion_matrix(epoch, logs):\n",
        "    # Use the model to predict the values from the validation dataset.\n",
        "    y_prediction = model3.predict(X_test)\n",
        "    y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "\n",
        "    #Create confusion matrix \n",
        "    cm = confusion_matrix(y_test, y_prediction)\n",
        "    print(cm)\n",
        "    print(cm[4,9])\n",
        "    print(cm[9,4])\n",
        "    # # Log the confusion matrix as an image summary.\n",
        "    # with file_writer_cm.as_default():\n",
        "    #   tf.summary.image(\"epoch_confusion_matrix\", cm_image, step=epoch)\n",
        "\n",
        "  # Define the per-epoch callback.\n",
        "  cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
        "\n",
        "  callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, verbose=1, restore_best_weights = True)\n",
        "\n",
        "  # # Print the batch number at the beginning of every batch.\n",
        "  # batch_print_callback = tf.keras.callbacks.LambdaCallback(\n",
        "  #     on_batch_begin=lambda batch,logs: print(batch))\n",
        "\n",
        "\n",
        "  model3_history = model3.fit(X_train, Y_train,\n",
        "            batch_size=batch_size, epochs=nb_epoch, verbose=2,\n",
        "            validation_data=(X_test, Y_test), shuffle=True, use_multiprocessing=True\n",
        "            ,callbacks = [callback, cm_callback]\n",
        "            )\n",
        "\n",
        " \n",
        "\n",
        "  #Predict\n",
        "  y_prediction = model3.predict(X_test)\n",
        "  y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "  # Y_prediction = np_utils.to_categorical(y_prediction, nb_classes)\n",
        "\n",
        "  #Create confusion matrix and normalizes it over predicted (columns)\n",
        "  # result = confusion_matrix(y_test, y_prediction , normalize='pred')\n",
        "\n",
        "  \n",
        "\n",
        "  cm3 = confusion_matrix(y_test, y_prediction)\n",
        "  cm3 = pd.DataFrame(cm3, range(10),range(10))\n",
        "  # plt.figure(figsize = (10,10))\n",
        "  # cm3\n",
        "  # sns.heatmap(cm2, annot=True, annot_kws={\"size\": 12}) # font size\n",
        "  # plt.show()\n",
        "\n",
        "  # cm_using_weighted_new = cm3\n",
        "\n",
        "  # print(model3_history.history)\n",
        "  tot_epochs = max(model3_history.epoch)+1  #if the total epochs ran is 28, it'll show up as 27 in the epoch object so we must add 1\n",
        "  print(\"Total Epochs: \", tot_epochs)\n",
        "  restored_weights  = tot_epochs-patience   #when using restore-best-weights and patience, it'll restore the best weights back\n",
        "  print(\"Restored weights at \", restored_weights)\n",
        "  \n",
        "\n",
        "\n",
        "  #Label is the epoch weights are restored \n",
        "  label = f\"{restored_weights}\"\n",
        "  #Label_vale is the value at which the epoch weights are restored \n",
        "  label_value = f\"{ model3_history.history['val_categorical_accuracy'][restored_weights]}\"\n",
        "  print(\"Label: \", label, \"Val_Cat_Acc Value: \", label_value)\n",
        "\n",
        "\n",
        "\n",
        "  plt.plot(range(1,tot_epochs+1), model3_history.history['categorical_accuracy'],)\n",
        "  plt.plot(range(1,tot_epochs+1), model3_history.history['val_categorical_accuracy'])\n",
        "  plt.scatter((restored_weights), model3_history.history['val_categorical_accuracy'][restored_weights])\n",
        "\n",
        "  plt.annotate(text=label,  xy=(restored_weights, model3_history.history['val_categorical_accuracy'][restored_weights]),\n",
        "                 textcoords=\"offset points\", \n",
        "                 xytext=(0,10), \n",
        "                 ha='center')\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "\n",
        "  \n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  \n",
        "\n",
        "  plt.plot(range(1,tot_epochs+1), model3_history.history['loss'])\n",
        "  plt.plot(range(1,tot_epochs+1), model3_history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.scatter(restored_weights, model3_history.history['val_loss'][restored_weights])\n",
        "  plt.annotate(text=label,  xy=(restored_weights, model3_history.history['val_loss'][restored_weights]),\n",
        "                 textcoords=\"offset points\", \n",
        "                 xytext=(0,10), \n",
        "                 ha='center')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return cm3, model3_history, model3"
      ],
      "metadata": {
        "id": "3UWVdmRHNBhP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Keep Track of Experimental Admin Stuff - #Runs and #CostMatrix\n",
        "\n",
        "> Change the cost matrix and number of runs and check the file extension name \n"
      ],
      "metadata": {
        "id": "skXIN6S4npiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Define Cost Matrix and Method"
      ],
      "metadata": {
        "id": "q9YhLRi4NU2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimental Admin Stuff\n",
        "cost_matrix = np.ones((10,10))\n",
        "\n",
        "### Weight of Misclassification\n",
        "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "cost_matrix[9, 4] = 1\n",
        "cost_str = str(cost_matrix[9, 4])\n",
        "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "\n",
        "\n",
        "### File Extension to reference in JMP : weights_method_cost\n",
        "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "file_extension = \"w[9,4]_PA_\" + cost_str + \"_Shfl_40D_\"\n",
        "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "print(\"Last run using \", cost_str)"
      ],
      "metadata": {
        "id": "3bMXTRRBnn3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dad0e5e-4acd-4f16-ffca-7cc03bdd8711"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last run using  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run Experiments"
      ],
      "metadata": {
        "id": "x_EdEdJwOpvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "cm = np.zeros([10,10])\n",
        "combined_cms = np.empty((1,100))\n",
        "\n",
        "combined_history_dictionary = {}  #because there will be a unknown number of epochs a dictionary is probly a better fit\n",
        "combined_history_list       = []\n",
        "\n",
        "\n",
        "## Define the total number of runs\n",
        "### ~~~~~~~~~\n",
        "runs = 1\n",
        "### ~~~~~~~~~~\n",
        "\n",
        "#its easier for me to count my runs as \"1 and up\" instead of 0...   \n",
        "for i in range(1,runs+1):\n",
        "  cost_matrix[9, 4] = 1000\n",
        "  print(\"Run \", i, \"Starting with a  cost_matrix[9, 4] = \",  cost_matrix[9, 4] , \" for 45 epochs with Early Stopping and Restore Best Weights ... \")\n",
        "\n",
        "\n",
        "  cm2 , history, model =  PA_method_epoch(cost_matrix,nb_epoch=11 )    #Individual CM, and Training/Validation History\n",
        "  print(\"After first stage CM: \\n\", cm2)\n",
        "\n",
        "  print(\"After first stage CM[9,4]: \\n\", cm2[4][9])\n",
        "  \n",
        "\n",
        "\n",
        "  combined_history_dictionary[i] = history\n",
        "  combined_history_list.append(history)\n",
        "  # cm += cm2                   #Aggregating for an Average\n",
        "  cm2_array = np.asarray(cm2)  #Indiv CM as array for storing\n",
        "  combined_cms = np.vstack((combined_cms,cm2_array.reshape((1,100))))\n",
        "\n",
        "# ###############################\n",
        "# ## Code to update the fitted model with the new cost matrix\n",
        "# ###############################\n",
        "\n",
        "# cost_matrix[9, 4] = 1000\n",
        "\n",
        "# print(\"Run \", i, \" continued, with a  cost_matrix[9, 4] = \",  cost_matrix[9, 4] , \" for 45 epochs and Early Stopping on Val_Loss of patience 20 ... \")\n",
        "\n",
        "\n",
        "# rms = RMSprop()  #https://keras.io/api/optimizers/rmsprop/\n",
        "# patience  = 20\n",
        "\n",
        "# model.compile(loss=WeightedCategoricalCrossentropy(cost_matrix), optimizer=rms,  metrics='categorical_accuracy',)\n",
        "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, verbose=1, restore_best_weights = True)\n",
        "# model_history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=2,\n",
        "#               validation_data=(X_test, Y_test), shuffle=True, use_multiprocessing=True,callbacks = [callback])\n",
        "\n",
        "\n",
        "\n",
        "# #Predict\n",
        "# y_prediction = model.predict(X_test)\n",
        "# y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# cm3 = confusion_matrix(y_test, y_prediction)\n",
        "# cm3 = pd.DataFrame(cm3, range(10),range(10))\n",
        "# cm3\n",
        "\n",
        "# #Label is the epoch weights are restored \n",
        "# label = f\"{max(model_history.epoch)-patience}\"\n",
        "\n",
        " \n",
        "# plt.plot(model_history.history['categorical_accuracy'])\n",
        "# plt.plot(model_history.history['val_categorical_accuracy'])\n",
        "# plt.scatter(x=(max(model_history.epoch)-patience), y=model_history.history['val_categorical_accuracy'][max(model_history.epoch)-patience])\n",
        "\n",
        "# plt.annotate(text=label,  xy=(max(model_history.epoch)-patience, model_history.history['val_categorical_accuracy'][max(model_history.epoch)-patience]),\n",
        "#                 textcoords=\"offset points\", \n",
        "#                 xytext=(0,10), \n",
        "#                 ha='center')\n",
        "# plt.title('model accuracy')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "\n",
        "\n",
        "# plt.legend(['train', 'val'], loc='upper left')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# plt.plot(model_history.history['loss'])\n",
        "# plt.plot(model_history.history['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'val'], loc='upper left')\n",
        "# plt.scatter(x=(max(model_history.epoch)-patience), y=model_history.history['val_loss'][max(model_history.epoch)-patience])\n",
        "# plt.annotate(text=label,  xy=(max(model_history.epoch)-patience, model_history.history['val_loss'][max(model_history.epoch)-patience]),\n",
        "#                 textcoords=\"offset points\", \n",
        "#                 xytext=(0,10), \n",
        "#                 ha='center')\n",
        "# plt.show()\n",
        "\n",
        "# print(\"After second stage CM: \\n\", cm3)\n",
        "\n",
        "# print(\"After second stage CM[9,4]: \\n\",cm3[4][9])  #First number is COLUMN, second number is ROW so column 4 is Prediction is 4, Row 9 is Truly a Label 9\n",
        "  \n",
        "\n",
        "#######\n",
        "\n",
        "# cm_new = cm/30"
      ],
      "metadata": {
        "id": "OSq7jMYUOF4t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69bd9945-275d-427f-c920-53ec4a349655"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run  1 Starting with a  cost_matrix[9, 4] =  1000.0  for 45 epochs with Early Stopping and Restore Best Weights ... \n",
            "Epoch 1/11\n",
            "313/313 [==============================] - 7s 21ms/step\n",
            "[[ 930    0    1    2    0    7   21    1   15    3]\n",
            " [   0 1094   17    3    0    0    4    0   15    2]\n",
            " [  13   11  872   29    0    1   23   10   52   21]\n",
            " [   3    3   31  873    0   36    1   12   27   24]\n",
            " [   5    7    5    0   60    4   19    3   13  866]\n",
            " [  12    2    7   34    1  714   16   10   68   28]\n",
            " [  25    4   13    0    2   13  888    2   10    1]\n",
            " [   0   42   11    5    2    0    1  819   10  138]\n",
            " [  14   23   16   19    4   39   11    9  781   58]\n",
            " [   9    6    2   11    0    4    1   22    6  948]]\n",
            "866\n",
            "0\n",
            "235/235 - 10s - loss: 2.3161 - categorical_accuracy: 0.6047 - val_loss: 0.5747 - val_categorical_accuracy: 0.7979 - 10s/epoch - 41ms/step\n",
            "Epoch 2/11\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "[[ 955    0    0    1    0    6   12    1    5    0]\n",
            " [   0 1106    5    4    0    0    3    2   14    1]\n",
            " [  16   11  903   13    0    1   13   14   47   14]\n",
            " [   3    4   26  879    0   47    2   15   28    6]\n",
            " [   2    3    3    0  124    0   13    1    8  828]\n",
            " [  15    1    5   27    1  760   14    6   48   15]\n",
            " [  18    4    6    0    3   14  905    1    6    1]\n",
            " [   2   18   13    3    1    0    1  939    4   47]\n",
            " [  11   10   13   13    4   32   10   15  843   23]\n",
            " [   9    4    1   10    0    9    1   27    7  941]]\n",
            "828\n",
            "0\n",
            "235/235 - 5s - loss: 1.2011 - categorical_accuracy: 0.7688 - val_loss: 0.4085 - val_categorical_accuracy: 0.8355 - 5s/epoch - 21ms/step\n",
            "Epoch 3/11\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "[[ 953    0    1    1    1    5   13    1    5    0]\n",
            " [   0 1112    4    4    0    0    3    2    9    1]\n",
            " [  12    8  930   14    3    0   12   12   30   11]\n",
            " [   2    3   24  923    1   24    0   13   16    4]\n",
            " [   1    3    2    0  276    0   15    0    5  680]\n",
            " [  10    1    2   35    3  776   16    4   31   14]\n",
            " [  11    4    2    0    2   14  918    0    6    1]\n",
            " [   2   12   20    3    5    0    0  942    2   42]\n",
            " [   7    8   13   17    4   24   13   13  865   10]\n",
            " [   7    5    0   13    0    6    1   20    5  952]]\n",
            "680\n",
            "0\n",
            "235/235 - 4s - loss: 1.0509 - categorical_accuracy: 0.8168 - val_loss: 0.3387 - val_categorical_accuracy: 0.8647 - 4s/epoch - 16ms/step\n",
            "Epoch 4/11\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "[[ 960    0    1    1    0    3    7    1    5    2]\n",
            " [   0 1111    4    5    0    0    3    1   10    1]\n",
            " [  13    3  947   11    3    0    8   12   26    9]\n",
            " [   2    3   20  934    0   18    1   15   14    3]\n",
            " [   2    4    4    0  224    0    9    1    4  734]\n",
            " [   8    1    2   35    2  787   11    3   29   14]\n",
            " [  17    4    2    0    3   14  907    0    7    4]\n",
            " [   1    9   19    6    1    0    0  959    0   33]\n",
            " [   8    4    9   13    2   21    9   16  874   18]\n",
            " [   6    3    0   15    0    4    0   15    5  961]]\n",
            "734\n",
            "0\n",
            "235/235 - 4s - loss: 0.9591 - categorical_accuracy: 0.8411 - val_loss: 0.3297 - val_categorical_accuracy: 0.8664 - 4s/epoch - 18ms/step\n",
            "Epoch 5/11\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "[[ 956    0    0    1    2    5   12    2    2    0]\n",
            " [   0 1114    4    3    0    1    3    2    7    1]\n",
            " [   8    4  960    9    5    0    7    7   22   10]\n",
            " [   1    3   26  936    2   17    0   12   10    3]\n",
            " [   1    3    6    0  249    0   14    0    4  705]\n",
            " [   6    1    2   32    2  802   11    2   21   13]\n",
            " [  10    4    2    0    4   13  919    0    3    3]\n",
            " [   3    8   22    3    3    0    0  953    0   36]\n",
            " [   6    6   11   11    7   23    9   14  872   15]\n",
            " [   9    5    0   14    0    5    0   16    4  956]]\n",
            "705\n",
            "0\n",
            "235/235 - 3s - loss: 0.8238 - categorical_accuracy: 0.8573 - val_loss: 0.3057 - val_categorical_accuracy: 0.8717 - 3s/epoch - 15ms/step\n",
            "Epoch 6/11\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 953    0    0    1    4    5   10    2    5    0]\n",
            " [   0 1103    4    4    1    0    3    1   18    1]\n",
            " [   6    4  946   15    6    1    5    9   33    7]\n",
            " [   0    1   11  955    1   12    0   12   15    3]\n",
            " [   1    1    4    0  476    0   11    1    7  481]\n",
            " [   5    1    0   23    4  814   11    0   23   11]\n",
            " [   9    4    1    0    6   22  910    0    5    1]\n",
            " [   1   10   18    7    2    1    1  960    1   27]\n",
            " [   4    5    6   12    7   17    6   10  901    6]\n",
            " [   4    4    0   16    0    8    1    9    4  963]]\n",
            "481\n",
            "0\n",
            "235/235 - 3s - loss: 0.7809 - categorical_accuracy: 0.8693 - val_loss: 0.2631 - val_categorical_accuracy: 0.8981 - 3s/epoch - 11ms/step\n",
            "Epoch 7/11\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 950    0    0    1    4    5   11    2    5    2]\n",
            " [   0 1111    4    3    0    0    3    1   12    1]\n",
            " [   5    3  959   13    1    1    5   13   24    8]\n",
            " [   0    2   18  954    1    9    0   12   10    4]\n",
            " [   1    3    3    0  247    0   10    1    4  713]\n",
            " [   5    1    2   33    3  805   12    1   19   11]\n",
            " [  10    4    2    0    4    7  924    0    4    3]\n",
            " [   1   11   15    8    2    0    0  966    1   24]\n",
            " [   4    4    9   12    4   16    9    9  893   14]\n",
            " [   5    5    0   17    0    5    0    9    4  964]]\n",
            "713\n",
            "0\n",
            "235/235 - 2s - loss: 0.8232 - categorical_accuracy: 0.8663 - val_loss: 0.2808 - val_categorical_accuracy: 0.8773 - 2s/epoch - 9ms/step\n",
            "Epoch 8/11\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[ 958    0    0    1    2    5    9    1    2    2]\n",
            " [   0 1117    4    4    0    0    3    1    5    1]\n",
            " [   7    3  955   12    2    1    5   13   25    9]\n",
            " [   0    2   14  953    1   11    0   12   11    6]\n",
            " [   2    2    4    0  345    0   10    1    3  615]\n",
            " [   6    1    2   23    3  817   10    2   14   14]\n",
            " [  11    4    1    0    3   11  921    0    4    3]\n",
            " [   1   11   15    6    2    0    0  970    0   23]\n",
            " [   6    7    9   11    6   12   10   11  888   14]\n",
            " [   8    5    1   12    0    7    0    8    3  965]]\n",
            "615\n",
            "0\n",
            "235/235 - 2s - loss: 0.8240 - categorical_accuracy: 0.8740 - val_loss: 0.2651 - val_categorical_accuracy: 0.8889 - 2s/epoch - 9ms/step\n",
            "Epoch 9/11\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "[[ 960    0    0    1    1    4   10    1    2    1]\n",
            " [   0 1118    3    3    0    0    4    1    5    1]\n",
            " [   8    3  961    8    2    1    5   15   21    8]\n",
            " [   0    2   17  944    1   17    0   12   15    2]\n",
            " [   1    1    3    0  363    0   15    1    3  595]\n",
            " [   6    1    1   14    3  823   14    2   16   12]\n",
            " [  10    4    0    0    4    7  930    0    2    1]\n",
            " [   3   10   15    7    0    0    0  974    0   19]\n",
            " [   9    6    5    7    5   10   14    8  899   11]\n",
            " [   9    6    0   11    0    6    0    8    3  966]]\n",
            "595\n",
            "0\n",
            "235/235 - 3s - loss: 0.6635 - categorical_accuracy: 0.8807 - val_loss: 0.2521 - val_categorical_accuracy: 0.8938 - 3s/epoch - 12ms/step\n",
            "Epoch 10/11\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "[[ 964    0    0    1    1    4    7    1    2    0]\n",
            " [   0 1115    4    4    0    1    3    1    7    0]\n",
            " [   7    2  976    9    2    1    5    8   18    4]\n",
            " [   0    1   20  947    1   19    0   10   10    2]\n",
            " [   2    1    6    0  623    0   12    0    6  332]\n",
            " [   5    0    1   16    3  838   11    2   12    4]\n",
            " [  12    3    1    0    6   11  920    0    5    0]\n",
            " [   4    8   25    3    2    0    0  972    0   14]\n",
            " [   7    4    9    9    5   12    9    8  907    4]\n",
            " [   9    4    0   14    2    7    0    9    3  961]]\n",
            "332\n",
            "2\n",
            "235/235 - 3s - loss: 0.7127 - categorical_accuracy: 0.8880 - val_loss: 0.4212 - val_categorical_accuracy: 0.9223 - 3s/epoch - 12ms/step\n",
            "Epoch 11/11\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "[[ 962    0    2    0    1    4    7    1    3    0]\n",
            " [   0 1114    3    4    0    1    3    2    8    0]\n",
            " [   7    2  974    8    1    1    5    9   19    6]\n",
            " [   0    1   16  943    1   24    0   11   12    2]\n",
            " [   1    1    5    0  675    0   18    0    3  279]\n",
            " [   4    0    1   12    1  850   12    2    5    5]\n",
            " [   9    3    0    0    4   11  928    0    3    0]\n",
            " [   4    8   17    2    0    0    0  982    1   14]\n",
            " [   5    5    8    7    5   21    9    6  901    7]\n",
            " [   8    4    0   13    3    9    0   12    3  957]]\n",
            "279\n",
            "3\n",
            "235/235 - 2s - loss: 0.7093 - categorical_accuracy: 0.8897 - val_loss: 0.5051 - val_categorical_accuracy: 0.9286 - 2s/epoch - 8ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Total Epochs:  11\n",
            "Restored weights at  1\n",
            "Label:  1 Val_Cat_Acc Value:  0.8355000019073486\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After first stage CM: \n",
            "      0     1    2    3    4    5    6    7    8    9\n",
            "0  962     0    2    0    1    4    7    1    3    0\n",
            "1    0  1114    3    4    0    1    3    2    8    0\n",
            "2    7     2  974    8    1    1    5    9   19    6\n",
            "3    0     1   16  943    1   24    0   11   12    2\n",
            "4    1     1    5    0  675    0   18    0    3  279\n",
            "5    4     0    1   12    1  850   12    2    5    5\n",
            "6    9     3    0    0    4   11  928    0    3    0\n",
            "7    4     8   17    2    0    0    0  982    1   14\n",
            "8    5     5    8    7    5   21    9    6  901    7\n",
            "9    8     4    0   13    3    9    0   12    3  957\n",
            "After first stage CM[9,4]: \n",
            " 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dir(history) and # print(history.__dict__)  are useful for digging into what variables are inside a variable"
      ],
      "metadata": {
        "id": "s6HsboVWsimi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_history_dictionary[1].history['loss'] #inside each combined_history_dictionary is a list\n",
        "# combined_history_dictionary[1].history['val_loss']\n",
        "# combined_history_dictionary[1].history['categorical_accuracy']\n",
        "# combined_history_dictionary[1].history['val_categorical_accuracy']\n",
        "# combined_history_dictionary[1].epoch\n",
        "\n",
        "# len(combined_history_dictionary)  # the length is 1, but the dictionary starts at 1\n",
        "# # len(combined_history_list)      # the length is 1, but the list starts at 0\n",
        "# combined_history_list[0].history['loss'][17:19]\n",
        "# combined_history_list[0].history['val_loss'][18-1]  #epoch 18 is where my first run stopped aand restored weights.  Epoch 18 is #17 with base 0 counting.\n",
        "\n",
        "\n",
        "(combined_history_dictionary[1].history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMQNfNee3vWl",
        "outputId": "f84d8a5c-2d4e-45cc-f2a7-195c6691d13f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'categorical_accuracy', 'val_loss', 'val_categorical_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fxIL-2WZ6oBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fYeMRVha6oEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I need to remove the first placeholder row of zeros\n",
        "combined_cms = combined_cms[1:(runs+1)]"
      ],
      "metadata": {
        "id": "Z7qMXMuN4kS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save the 30/X confusion matrices"
      ],
      "metadata": {
        "id": "u-MSCXKC48ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save 30 confusion matrices\n",
        "\n",
        "import pickle\n",
        "\n",
        "str_runs = str(runs)\n",
        "\n",
        "\n",
        "from datetime import date\n",
        "today = date.today()\n",
        "file_date = today.strftime(\"%Y_%m_%d\")\n",
        "now = datetime.now() # current date and time\n",
        "file_time = now.strftime(\"%H%M\")\n",
        "print(\"time:\", file_time)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "file_name = str_runs + \"CM_\" + file_extension + \"_\" + file_date + \"_\" + file_time +  \"_.pkl\"\n",
        "print(file_name, \" will be saved with \", combined_cms.shape)\n",
        "\n",
        "with open(file_name, 'wb') as file_write:\n",
        "      \n",
        "    # A new file will be created\n",
        "    pickle.dump(combined_cms, file_write)\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "# Open the file in binary mode\n",
        "with open(file_name, 'rb') as file:\n",
        "      \n",
        "    # Call load method to deserialze\n",
        "    var = pickle.load(file)\n",
        "  \n",
        "    print(var)\n",
        "    \n",
        "print(file_name, \" was opened with \", var.shape)\n",
        "\n",
        "from google.colab import files\n",
        "files.download( file_name )  \n",
        "\n",
        "print(file_name, \".pkl was saved to Downloads \")\n"
      ],
      "metadata": {
        "id": "9purX_onqXGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many categories are there in the test set?\n",
        "\n",
        "truth_num_per_category = Y_test.sum(axis=0)\n",
        "print(truth_num_per_category)"
      ],
      "metadata": {
        "id": "id_ythTutuo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze \n",
        "\n",
        "I am now going to load the Average CM and try to get it in a format where I can make it a 1x100 and load all 30 CMs so that we can visualize their distributions in a a big histogram_matrix. At this point the Google Colab variables are gone and I have to reoad them "
      ],
      "metadata": {
        "id": "NP_kxNkhn6Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "empty_cm = np.zeros((10,10))  \n",
        "empty_cm=pd.DataFrame(empty_cm)\n",
        "\n",
        "empty_cm.columns = ['0p', '1p', '2p', '3p', '4p', '5p', '6p', '7p', '8p', '9p']\n",
        "empty_cm.index = ['0t', '1t', '2t', '3t', '4t', '5t', '6t', '7t', '8t', '9t']\n",
        "\n",
        "# print(myvar_cm_average)\n",
        "\n",
        "empty_cm_array = np.asarray(empty_cm)\n",
        "empty_cm_array_1_100 = np.reshape(empty_cm_array,(1,100))\n",
        "# print(cm_average_array)\n",
        "\n",
        "df = empty_cm\n",
        "df_new = pd.DataFrame(empty_cm_array_1_100,  columns=pd.MultiIndex.from_product([ df.index,df.columns]))\n",
        "df_new.columns.to_flat_index()\n",
        "df_new.columns   = ['_'.join(col) for col in df_new.columns.values]\n",
        "\n",
        "# Now convert combined_cms of size 30x100 to a panda dataframe\n",
        "combined_cms_df = pd.DataFrame(combined_cms, columns=[df_new.columns])\n",
        "\n",
        "combined_cms_df"
      ],
      "metadata": {
        "id": "kLrNJE0s53pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_cms_df[\"9t_4p\"]"
      ],
      "metadata": {
        "id": "HgPClcrAUdxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.average(combined_cms_df[\"9t_4p\"])"
      ],
      "metadata": {
        "id": "TY59hUTadVyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_filename = file_name[:-4] + \".csv\"\n",
        "\n",
        "combined_cms_df.to_csv(csv_filename)\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.download(csv_filename )\n",
        "\n",
        "print(\"Downloading \", csv_filename , \" of shape \", combined_cms_df.shape)"
      ],
      "metadata": {
        "id": "ceUFAr_z9xsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(sum(var)/len(var), columns=[\"Values\"]) \n",
        "# print(df)\n",
        "\n",
        "df.style.format({\n",
        "  'Values': lambda val: f'{val:,.2f}',\n",
        "})\n",
        "\n",
        "(df.sort_values(by=\"Values\", ascending=False)[0:20])\n",
        "\n",
        "\n",
        "df_sorted = df.sort_values(by=\"Values\", ascending=False)[10:]  #the top 10 are usually diagonal\n",
        "\n",
        "\n",
        "df_sorted.style.format({\n",
        "  'Values': lambda val: f'{val:,.2f}',\n",
        "})\n",
        "\n",
        "import math\n",
        "\n",
        "print(\"On average...\")\n",
        "print(\"Num 1 misclassifications are misclassifying a \", math.floor((df_sorted[\"Values\"].index[0])/10), \" as a \", df_sorted[\"Values\"].index[0]%10, \"  (\", (df_sorted[\"Values\"].values[0]), \" times)\" )\n",
        "print(\"Num 2 misclassifications are misclassifying a \", math.floor((df_sorted[\"Values\"].index[1])/10), \" as a \", df_sorted[\"Values\"].index[1]%10, \"  (\", (df_sorted[\"Values\"].values[1]), \" times)\" )\n",
        "print(\"Num 3 misclassifications are misclassifying a \", math.floor((df_sorted[\"Values\"].index[2])/10), \" as a \", df_sorted[\"Values\"].index[2]%10, \"  (\", (df_sorted[\"Values\"].values[2]), \" times)\" )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-pGNLuE8gNrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_percents = pd.DataFrame( ((sum(var)*100/len(var)).reshape((10,10))/truth_num_per_category).reshape((100)), columns = [\"Values\"])\n",
        "\n",
        "\n",
        "df_sorted_percents = df_percents.sort_values(by=\"Values\", ascending=False)[10:]  #the top 10 are usually diagonal\n",
        "\n",
        "df_sorted_percents.style.format({\n",
        "  'Values': lambda val: f'{val:,.2f}',\n",
        "})\n",
        "\n",
        "print(\"On average .. \")\n",
        "print(\"Num 1 percent misclassifications\", math.floor((df_sorted_percents[\"Values\"].index[0])/10), \" as \", df_sorted_percents[\"Values\"].index[0]%10, (df_sorted_percents[\"Values\"].values[0]), \" percent\" )\n",
        "print(\"Num 2 percent misclassifications\", math.floor((df_sorted_percents[\"Values\"].index[1])/10), \" as \", df_sorted_percents[\"Values\"].index[1]%10,  (df_sorted_percents[\"Values\"].values[1]), \" percent\" )\n",
        "print(\"Num 3 percent misclassifications\", math.floor((df_sorted_percents[\"Values\"].index[2])/10), \" as \", df_sorted_percents[\"Values\"].index[2]%10, (df_sorted_percents[\"Values\"].values[2]), \" percent\" )\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AKYclir2p8wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FrT9iz3dp8rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraneous"
      ],
      "metadata": {
        "id": "GZfPCKu_oqrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To reference later: \n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#scrollTo=UJ589fn8ST3x\n",
        "\n",
        "To train a model with class weights:\n",
        "\n",
        "```\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "weighted_model = make_model()\n",
        "weighted_model.load_weights(initial_weights)\n",
        "\n",
        "weighted_history = weighted_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stopping],\n",
        "    validation_data=(val_features, val_labels),\n",
        "\n",
        "    # The class weights go here\n",
        "    class_weight=class_weight)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "iLEt0OL5ziEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraneous information I am not using at the moment\n",
        "\n",
        "# model.compile(\n",
        "#      optimizer='adam',\n",
        "#      loss=WeightedCategoricalCrossentropy(cost_matrix)\n",
        "#      )\n",
        "\n",
        "## Model Saving\n",
        "\n",
        "# model.save(save_version_dir,save_format='tf')\n",
        "\n",
        "## Model Loading\n",
        "\n",
        "# model = tf.keras.models.load_model(\n",
        "#     save_version_dir,\n",
        "#     compile=True,\n",
        "#     custom_objects={\n",
        "#         'WeightedCategoricalCrossentropy': WeightedCategoricalCrossentropy(cost_matrix)\n",
        "#         }\n",
        "#     )\n",
        " "
      ],
      "metadata": {
        "id": "WRzuOuZeKVpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "starting to think about how i would shape the initial, middle and late training experiments.  "
      ],
      "metadata": {
        "id": "GH-yoluLM0sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "\n",
        "\n",
        "print(\"     | --- Init --- | | --- Mid --- | | --- Late --- | \")\n",
        "for i in [\"   1\",\" 100\", \"1000\"]:\n",
        "  for j in  [\"   1\",\" 100\", \"1000\"]:\n",
        "    for k in   [\"   1\",\" 100\", \"1000\"]:\n",
        "      count+=1\n",
        "      print(f\"{count}    |     {i}     ,     {j}    ,    {k}     | \")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EisEf8F6MzFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xVGDsrmmNLed"
      }
    }
  ]
}