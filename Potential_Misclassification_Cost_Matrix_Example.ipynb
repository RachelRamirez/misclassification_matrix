{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORnfvb6KVkS9pYSxsSw3vC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachelRamirez/misclassification_matrix/blob/main/Potential_Misclassification_Cost_Matrix_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that I've shown the TB and ISantaro methods are equivalent when seeded properly, I believe what I need to do is train a \"good\" neural network with the same seed 30 times to get an idea of what the typical confusion matrix looks like.  I will run the code within Colab 30 times without restarting because from previous reproducibility studies if I restart and run-all I will get the same results.  This time, I'm interested in the typical variety you can get on a confusion matrix when the neural network is seeded the same way each time, that way when I gve it another cost-matrix to train on, and run that 30 times I can do a more informative comparison of the results.  Since the Isantaro and TB methods were identical I went with the Isantaro method because it was simpler, more efficient, and seemed less time consuming. "
      ],
      "metadata": {
        "id": "xW_9TgRZB0s6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changes from previous Reproducibility notebook:\n",
        "1. Dropout is back in.\n",
        "2. Batch Size is not as large to help with variety.\n",
        "3. Num of Epochs is more than 4 now that I care about achieving good overall accuracy\n",
        "4. Callback for EarlyStop added\n",
        "5. Model Shuffle during Fit is still False (I'm calling it out to see if I need to change that)\n",
        "6. but Model.Fit(use multiprocessors = True)\n",
        "7. Still Cost Matrix of all 1's"
      ],
      "metadata": {
        "id": "C0WLMX5eC-Ke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reproducible Seeds"
      ],
      "metadata": {
        "id": "Wn15dbArlsIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For Reproducibility\n",
        "import numpy as np\n",
        "# np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "import tensorflow as tf\n",
        "# tf.random.set_seed(33)\n",
        "\n",
        "import random as python_random\n",
        "# python_random.seed(4)\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed\n",
        "tf.keras.utils.set_random_seed(342) #Possibly use next iteration if the above doesn't work\n",
        "\n",
        "\n",
        "# Running more than once causes variation.  try adding this:\n",
        "# Set seed value\n",
        "seed_value = 56\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "print(\"TF version: \" , tf.__version__ )\n",
        "print(\"Keras version: \" , tf.keras.__version__ )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcjDfFIIbmbo",
        "outputId": "7138c43a-3135-410a-a45e-87b515467954"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version:  2.9.2\n",
            "Keras version:  2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import rest of Library"
      ],
      "metadata": {
        "id": "mTW-hEgnlp44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from https://github.com/keras-team/keras/issues/2115#issuecomment-204060456\n",
        "# witha correction on the weighted function in the middle \n",
        "\n",
        "'''Train a simple deep NN on the MNIST dataset.\n",
        "Get to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function  #do i still need this?\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.utils import np_utils\n",
        "import keras.backend as K\n",
        "from itertools import product\n",
        "import functools\n",
        "from functools import partial\n",
        "from time import ctime\n",
        "from time import sleep\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "## MORE REPEATABILITY STUFF NEEDED - If theres a way to update this to V2 of Tensorflow great, otherwise I had to use TF 1.0 code\n",
        "# 5. Configure a new global `tensorflow` session (https://stackoverflow.com/questions/50659482/why-cant-i-get-reproducible-results-in-keras-even-though-i-set-the-random-seeds)\n",
        "# from keras import backend as K\n",
        "\n",
        "\n",
        "#I believe thecode below is to help things be repeatable each time different sections in my google colab notebook execute\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)"
      ],
      "metadata": {
        "id": "idfYNyyAgMsO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define batch, epochs, and format data"
      ],
      "metadata": {
        "id": "otcbfKF7mY9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256 # I originally had it very  high batch size to reduce the variation in the data each batch and hope it makes the model training more nearly identical which it did, then i bring it back down to something reasonable to get better results training the NN\n",
        "nb_classes = 10\n",
        "nb_epoch = 15\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B59UXDb8i8W5",
        "outputId": "056afa25-e8a9-4844-d58e-bbfeca56e9e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define weighted_categorical_crossentropy()"
      ],
      "metadata": {
        "id": "Y102hWcfvFyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # https://github.com/keras-team/keras/issues/2115#issuecomment-207765342\n",
        "\n",
        "# def w_categorical_crossentropy(y_true, y_pred, weights):\n",
        "#     nb_cl = len(weights)\n",
        "#     final_mask = K.zeros_like(y_pred[:, 0])\n",
        "#     y_pred_max = K.max(y_pred, axis=1)\n",
        "#     y_pred_max = K.expand_dims(y_pred_max, 1)\n",
        "#     y_pred_max_mat = K.equal(y_pred, y_pred_max)\n",
        " \n",
        "#     for c_t, c_p in product(range(nb_cl), range(nb_cl)):\n",
        "#         final_mask += (K.cast(weights[c_t, c_p],K.floatx()) * K.cast(y_pred_max_mat[:, c_p] ,K.floatx())* K.cast(y_true[:, c_t],K.floatx()))\n",
        "    \n",
        "#     # result = K.categorical_crossentropy(y_true, y_pred)*final_mask\n",
        "#     # tf.print(result, \"Show Result of CE * Final_Mask\")  #this was basically useless to display, and it showed like, 500 lines of print statements each epoch\n",
        "\n",
        "#     return K.categorical_crossentropy(y_true, y_pred)*final_mask   #I changed the order of y_true and y_pred\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fNienjOxgQVq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Same Model but use normal Categorical CrossEntropy with no extra cost-matrix of Weights"
      ],
      "metadata": {
        "id": "HtojTVZBvLEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normal_method():\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(512, input_shape=(784,) ,kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(512, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(10, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  rms = RMSprop()\n",
        "  # model.compile(loss=ncce, optimizer=rms)\n",
        "  model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=rms, metrics='categorical_accuracy', )\n",
        "\n",
        "  #add early_stop to prevent overfittings\n",
        "  # callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "  model_history = model.fit(X_train, Y_train,\n",
        "            batch_size=batch_size, epochs=nb_epoch, verbose=2,\n",
        "            validation_data=(X_test, Y_test),shuffle=False, use_multiprocessing=True\n",
        "            , callbacks = [callback])\n",
        "\n",
        "  \n",
        "  # model.evaluate(X_test, Y_test, verbose=1)  # I know this isn't the typical use of train/val/test sets, please dont' comment on that\n",
        "  \n",
        "  #Predict\n",
        "  y_prediction = model.predict(X_test)\n",
        "  y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "  # Y_prediction = np_utils.to_categorical(y_prediction, nb_classes) #If I want to do SparseCategoricalAccuracy\n",
        "\n",
        "  #Create confusion matrix and normalizes it over predicted (columns)\n",
        "  # result = confusion_matrix(y_test, y_prediction , normalize='pred')  #if I want percentages instead of raw counts\n",
        "\n",
        "  \n",
        "  cm = confusion_matrix(y_test, y_prediction)\n",
        "  cm = pd.DataFrame(cm, range(10),range(10))\n",
        "\n",
        "  #This shows a pretty confusion matrix which I don't neeed to show right now\n",
        "  # plt.figure(figsize = (10,10))\n",
        "  # sns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) # font size\n",
        "  # plt.show()\n",
        "  # cm_normal = cm\n",
        "\n",
        "  return cm\n"
      ],
      "metadata": {
        "id": "InYvpv3kaCxb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cw2zBqpvvzi0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weighted Categorical Cross Entropy Function"
      ],
      "metadata": {
        "id": "3fHQHrz8MwXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from https://github.com/keras-team/keras/issues/2115#issuecomment-815825633 from Isaranto\n",
        "\n",
        "def weighted_categorical_crossentropy_new(y_true, y_pred, weights):\n",
        "          idx1 = K.argmax(y_pred, axis=1)\n",
        "          idx2 = K.argmax(y_true, axis=1)\n",
        "          mask = tf.gather_nd(weights, tf.stack((idx1, idx2), -1))\n",
        "          return K.categorical_crossentropy(y_true, y_pred) * mask"
      ],
      "metadata": {
        "id": "pUR1sLQ7MvVa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #what does ncce stand for?\n",
        "\n",
        " \n",
        "def isaranto_method():\n",
        "  w_array = np.ones((10,10))\n",
        "  # w_array[9, 7] = 1.5\n",
        "  # w_array = w_array - np.eye(10)\n",
        "  # print(\"W_array:  \", w_array)\n",
        "\n",
        "  weighted_list = w_array.tolist()\n",
        "\n",
        "  wcce = partial(weighted_categorical_crossentropy_new, weights=weighted_list)\n",
        "  wcce.__name__ ='w_categorical_crossentropy'\n",
        "\n",
        "  model3 = Sequential()\n",
        "  model3.add(Dense(512, input_shape=(784,), kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model3.add(Activation('relu'))\n",
        "  model3.add(Dropout(0.2))\n",
        "  model3.add(Dense(512, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model3.add(Activation('relu'))\n",
        "  model3.add(Dropout(0.2))\n",
        "  model3.add(Dense(10,kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model3.add(Activation('softmax'))\n",
        "\n",
        "  rms = RMSprop()\n",
        "\n",
        "  model3.compile(loss=wcce, optimizer=rms,  metrics='categorical_accuracy',)\n",
        "  callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "  model3_history = model3.fit(X_train, Y_train,\n",
        "            batch_size=batch_size, epochs=nb_epoch, verbose=2,\n",
        "            validation_data=(X_test, Y_test), shuffle=False, use_multiprocessing=True\n",
        "            ,callbacks = [callback]\n",
        "            )\n",
        "\n",
        " \n",
        "\n",
        "  #Predict\n",
        "  y_prediction = model3.predict(X_test)\n",
        "  y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "  # Y_prediction = np_utils.to_categorical(y_prediction, nb_classes)\n",
        "\n",
        "  #Create confusion matrix and normalizes it over predicted (columns)\n",
        "  # result = confusion_matrix(y_test, y_prediction , normalize='pred')\n",
        "\n",
        "  \n",
        "\n",
        "  cm3 = confusion_matrix(y_test, y_prediction)\n",
        "  cm3 = pd.DataFrame(cm3, range(10),range(10))\n",
        "  # plt.figure(figsize = (10,10))\n",
        "  # cm3\n",
        "  # sns.heatmap(cm2, annot=True, annot_kws={\"size\": 12}) # font size\n",
        "  # plt.show()\n",
        "\n",
        "  # cm_using_weighted_new = cm3\n",
        "\n",
        "  return cm3"
      ],
      "metadata": {
        "id": "3UWVdmRHNBhP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = np.zeros([10,10])\n",
        "\n",
        "\n",
        "for i in range(0,30):\n",
        "  print(i)\n",
        "  cm2 =  isaranto_method()\n",
        "  print(\"CM: \\n\", cm2)\n",
        "  cm += cm2\n",
        "\n",
        "cm_new = cm/30"
      ],
      "metadata": {
        "id": "OSq7jMYUOF4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a72b10-7e70-43ca-b8b2-f4c53a6692cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch 1/15\n",
            "235/235 - 16s - loss: 0.3032 - categorical_accuracy: 0.9058 - val_loss: 0.2383 - val_categorical_accuracy: 0.9259 - 16s/epoch - 70ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 10s - loss: 0.1173 - categorical_accuracy: 0.9645 - val_loss: 0.1106 - val_categorical_accuracy: 0.9666 - 10s/epoch - 41ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0788 - categorical_accuracy: 0.9756 - val_loss: 0.0989 - val_categorical_accuracy: 0.9701 - 7s/epoch - 32ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 8s - loss: 0.0593 - categorical_accuracy: 0.9825 - val_loss: 0.1007 - val_categorical_accuracy: 0.9699 - 8s/epoch - 35ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 7s - loss: 0.0480 - categorical_accuracy: 0.9842 - val_loss: 0.0817 - val_categorical_accuracy: 0.9772 - 7s/epoch - 28ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 9s - loss: 0.0393 - categorical_accuracy: 0.9876 - val_loss: 0.0869 - val_categorical_accuracy: 0.9751 - 9s/epoch - 37ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0325 - categorical_accuracy: 0.9897 - val_loss: 0.0983 - val_categorical_accuracy: 0.9751 - 7s/epoch - 29ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 7s - loss: 0.0282 - categorical_accuracy: 0.9908 - val_loss: 0.0833 - val_categorical_accuracy: 0.9787 - 7s/epoch - 30ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  971     1     1    0    1    2    1    0    2    1\n",
            "1    0  1127     1    1    0    0    2    0    4    0\n",
            "2    3     3  1013    2    2    0    2    3    4    0\n",
            "3    0     0     3  986    0   11    0    4    3    3\n",
            "4    1     0     4    0  964    0    3    1    1    8\n",
            "5    2     0     0    3    1  883    1    0    1    1\n",
            "6    7     2     1    1    5   20  920    0    2    0\n",
            "7    2     4    12    1    2    0    0  989    5   13\n",
            "8    4     0     3    3    3    8    0    2  945    6\n",
            "9    0     2     0    2    8    5    1    1    1  989\n",
            "1\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3030 - categorical_accuracy: 0.9058 - val_loss: 0.2266 - val_categorical_accuracy: 0.9323 - 9s/epoch - 37ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1173 - categorical_accuracy: 0.9644 - val_loss: 0.1485 - val_categorical_accuracy: 0.9545 - 7s/epoch - 32ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0800 - categorical_accuracy: 0.9759 - val_loss: 0.1004 - val_categorical_accuracy: 0.9692 - 7s/epoch - 28ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0613 - categorical_accuracy: 0.9811 - val_loss: 0.0846 - val_categorical_accuracy: 0.9761 - 7s/epoch - 32ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 6s - loss: 0.0478 - categorical_accuracy: 0.9847 - val_loss: 0.0852 - val_categorical_accuracy: 0.9773 - 6s/epoch - 27ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0401 - categorical_accuracy: 0.9875 - val_loss: 0.0884 - val_categorical_accuracy: 0.9774 - 8s/epoch - 33ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0335 - categorical_accuracy: 0.9894 - val_loss: 0.0940 - val_categorical_accuracy: 0.9772 - 7s/epoch - 29ms/step\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  973     1     0    1    0    2    1    0    1    1\n",
            "1    0  1131     1    1    0    0    1    0    1    0\n",
            "2    1     0  1018    3    2    1    1    2    4    0\n",
            "3    0     0     2  992    0    4    0    3    3    6\n",
            "4    1     0     4    0  958    0    3    1    0   15\n",
            "5    2     0     0    8    1  872    1    0    5    3\n",
            "6    4     3     0    0    5   31  911    0    4    0\n",
            "7    0     4     9    2    2    0    0  969    5   37\n",
            "8    1     2     2    2    0    6    0    3  950    8\n",
            "9    0     2     0    2    2    4    1    0    0  998\n",
            "2\n",
            "Epoch 1/15\n",
            "235/235 - 10s - loss: 0.3098 - categorical_accuracy: 0.9035 - val_loss: 0.2193 - val_categorical_accuracy: 0.9307 - 10s/epoch - 42ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1191 - categorical_accuracy: 0.9634 - val_loss: 0.1586 - val_categorical_accuracy: 0.9504 - 7s/epoch - 29ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0802 - categorical_accuracy: 0.9752 - val_loss: 0.1182 - val_categorical_accuracy: 0.9653 - 8s/epoch - 34ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0612 - categorical_accuracy: 0.9812 - val_loss: 0.1038 - val_categorical_accuracy: 0.9700 - 7s/epoch - 29ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0483 - categorical_accuracy: 0.9844 - val_loss: 0.0761 - val_categorical_accuracy: 0.9782 - 8s/epoch - 33ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 7s - loss: 0.0403 - categorical_accuracy: 0.9875 - val_loss: 0.0756 - val_categorical_accuracy: 0.9778 - 7s/epoch - 30ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0338 - categorical_accuracy: 0.9891 - val_loss: 0.0772 - val_categorical_accuracy: 0.9795 - 7s/epoch - 30ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0290 - categorical_accuracy: 0.9907 - val_loss: 0.1032 - val_categorical_accuracy: 0.9751 - 8s/epoch - 33ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 7s - loss: 0.0258 - categorical_accuracy: 0.9912 - val_loss: 0.0749 - val_categorical_accuracy: 0.9824 - 7s/epoch - 29ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 8s - loss: 0.0228 - categorical_accuracy: 0.9924 - val_loss: 0.0759 - val_categorical_accuracy: 0.9815 - 8s/epoch - 33ms/step\n",
            "Epoch 11/15\n",
            "235/235 - 7s - loss: 0.0187 - categorical_accuracy: 0.9938 - val_loss: 0.0928 - val_categorical_accuracy: 0.9812 - 7s/epoch - 29ms/step\n",
            "Epoch 12/15\n",
            "235/235 - 8s - loss: 0.0194 - categorical_accuracy: 0.9935 - val_loss: 0.0965 - val_categorical_accuracy: 0.9792 - 8s/epoch - 33ms/step\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  973     1     0    2    0    1    1    0    1    1\n",
            "1    0  1128     1    1    0    1    2    0    2    0\n",
            "2    4     4  1010    2    1    0    2    4    4    1\n",
            "3    0     0     3  987    0   10    0    2    3    5\n",
            "4    2     0     2    0  952    1    4    1    2   18\n",
            "5    2     0     0    4    1  880    1    1    2    1\n",
            "6    8     3     0    1    4   16  925    0    1    0\n",
            "7    1     3     7    0    0    1    0  998    6   12\n",
            "8    6     0     1    8    2    5    0    2  946    4\n",
            "9    0     2     0    2    7    2    0    2    1  993\n",
            "3\n",
            "Epoch 1/15\n",
            "235/235 - 8s - loss: 0.3017 - categorical_accuracy: 0.9067 - val_loss: 0.2190 - val_categorical_accuracy: 0.9320 - 8s/epoch - 35ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 8s - loss: 0.1192 - categorical_accuracy: 0.9644 - val_loss: 0.1423 - val_categorical_accuracy: 0.9560 - 8s/epoch - 33ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0786 - categorical_accuracy: 0.9762 - val_loss: 0.1083 - val_categorical_accuracy: 0.9672 - 7s/epoch - 28ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 8s - loss: 0.0595 - categorical_accuracy: 0.9812 - val_loss: 0.0924 - val_categorical_accuracy: 0.9720 - 8s/epoch - 34ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0482 - categorical_accuracy: 0.9851 - val_loss: 0.0850 - val_categorical_accuracy: 0.9776 - 8s/epoch - 33ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 7s - loss: 0.0392 - categorical_accuracy: 0.9873 - val_loss: 0.1063 - val_categorical_accuracy: 0.9716 - 7s/epoch - 28ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 8s - loss: 0.0335 - categorical_accuracy: 0.9891 - val_loss: 0.0841 - val_categorical_accuracy: 0.9785 - 8s/epoch - 32ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 7s - loss: 0.0284 - categorical_accuracy: 0.9905 - val_loss: 0.0810 - val_categorical_accuracy: 0.9801 - 7s/epoch - 29ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 8s - loss: 0.0253 - categorical_accuracy: 0.9915 - val_loss: 0.0932 - val_categorical_accuracy: 0.9787 - 8s/epoch - 33ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 7s - loss: 0.0228 - categorical_accuracy: 0.9930 - val_loss: 0.1007 - val_categorical_accuracy: 0.9770 - 7s/epoch - 29ms/step\n",
            "Epoch 11/15\n",
            "235/235 - 7s - loss: 0.0196 - categorical_accuracy: 0.9936 - val_loss: 0.1006 - val_categorical_accuracy: 0.9797 - 7s/epoch - 30ms/step\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  972     1     1    0    1    1    2    0    0    2\n",
            "1    0  1129     2    0    1    1    1    0    1    0\n",
            "2    0     2  1020    0    1    0    1    4    3    1\n",
            "3    0     0     3  995    0    2    0    3    2    5\n",
            "4    0     0     4    0  968    0    2    1    0    7\n",
            "5    2     0     0    4    1  882    1    0    0    2\n",
            "6    3     3     0    1    7    9  934    0    1    0\n",
            "7    1     0    11    2    7    0    0  981    2   24\n",
            "8    4     1     6    4    8   12    0    3  925   11\n",
            "9    1     2     0    2   10    2    0    1    0  991\n",
            "4\n",
            "Epoch 1/15\n",
            "235/235 - 12s - loss: 0.3086 - categorical_accuracy: 0.9043 - val_loss: 0.2119 - val_categorical_accuracy: 0.9346 - 12s/epoch - 51ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1187 - categorical_accuracy: 0.9643 - val_loss: 0.1296 - val_categorical_accuracy: 0.9600 - 7s/epoch - 31ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0812 - categorical_accuracy: 0.9759 - val_loss: 0.1146 - val_categorical_accuracy: 0.9647 - 8s/epoch - 33ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0607 - categorical_accuracy: 0.9818 - val_loss: 0.0780 - val_categorical_accuracy: 0.9759 - 7s/epoch - 28ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0479 - categorical_accuracy: 0.9848 - val_loss: 0.0771 - val_categorical_accuracy: 0.9776 - 8s/epoch - 34ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 7s - loss: 0.0397 - categorical_accuracy: 0.9876 - val_loss: 0.0800 - val_categorical_accuracy: 0.9775 - 7s/epoch - 28ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 8s - loss: 0.0330 - categorical_accuracy: 0.9893 - val_loss: 0.0891 - val_categorical_accuracy: 0.9764 - 8s/epoch - 34ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0309 - categorical_accuracy: 0.9904 - val_loss: 0.0776 - val_categorical_accuracy: 0.9797 - 8s/epoch - 33ms/step\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  974     1     0    2    0    0    1    1    1    0\n",
            "1    1  1128     1    2    0    0    1    0    2    0\n",
            "2    6     2  1012    1    1    0    2    3    4    1\n",
            "3    0     0     4  996    0    2    0    3    3    2\n",
            "4    2     0     4    0  968    0    2    0    1    5\n",
            "5    3     0     0    6    1  873    2    1    5    1\n",
            "6    4     3     0    1    8   21  919    0    2    0\n",
            "7    1     2     9    1    5    0    0  995    2   13\n",
            "8    2     0     2    4    6    7    0    3  944    6\n",
            "9    2     2     0    3   12    1    0    1    0  988\n",
            "5\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3023 - categorical_accuracy: 0.9064 - val_loss: 0.2363 - val_categorical_accuracy: 0.9263 - 9s/epoch - 39ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1192 - categorical_accuracy: 0.9642 - val_loss: 0.1442 - val_categorical_accuracy: 0.9557 - 7s/epoch - 30ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0805 - categorical_accuracy: 0.9755 - val_loss: 0.1028 - val_categorical_accuracy: 0.9702 - 8s/epoch - 34ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 8s - loss: 0.0605 - categorical_accuracy: 0.9813 - val_loss: 0.0934 - val_categorical_accuracy: 0.9728 - 8s/epoch - 32ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 7s - loss: 0.0496 - categorical_accuracy: 0.9840 - val_loss: 0.0856 - val_categorical_accuracy: 0.9761 - 7s/epoch - 29ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0394 - categorical_accuracy: 0.9877 - val_loss: 0.0915 - val_categorical_accuracy: 0.9753 - 8s/epoch - 34ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0344 - categorical_accuracy: 0.9892 - val_loss: 0.0788 - val_categorical_accuracy: 0.9799 - 7s/epoch - 29ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0286 - categorical_accuracy: 0.9911 - val_loss: 0.0798 - val_categorical_accuracy: 0.9799 - 8s/epoch - 34ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 7s - loss: 0.0250 - categorical_accuracy: 0.9921 - val_loss: 0.0859 - val_categorical_accuracy: 0.9789 - 7s/epoch - 31ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 7s - loss: 0.0223 - categorical_accuracy: 0.9928 - val_loss: 0.0846 - val_categorical_accuracy: 0.9794 - 7s/epoch - 29ms/step\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  973     1     1    0    0    2    1    1    1    0\n",
            "1    0  1130     1    0    0    0    2    0    2    0\n",
            "2    0     2  1018    3    1    0    2    4    2    0\n",
            "3    0     0     9  988    0    4    0    2    1    6\n",
            "4    1     0     3    0  968    0    3    1    1    5\n",
            "5    3     0     0    6    1  878    1    1    1    1\n",
            "6    6     3     0    1    7   16  925    0    0    0\n",
            "7    0     5    10    1    0    0    0  995    5   12\n",
            "8    8     1     3    8    4    9    0    2  931    8\n",
            "9    2     2     0    3   10    2    0    2    0  988\n",
            "6\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3044 - categorical_accuracy: 0.9068 - val_loss: 0.1794 - val_categorical_accuracy: 0.9431 - 9s/epoch - 37ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1178 - categorical_accuracy: 0.9644 - val_loss: 0.1289 - val_categorical_accuracy: 0.9612 - 7s/epoch - 28ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0785 - categorical_accuracy: 0.9758 - val_loss: 0.0895 - val_categorical_accuracy: 0.9730 - 8s/epoch - 33ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0596 - categorical_accuracy: 0.9817 - val_loss: 0.1022 - val_categorical_accuracy: 0.9713 - 7s/epoch - 31ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0470 - categorical_accuracy: 0.9853 - val_loss: 0.0888 - val_categorical_accuracy: 0.9760 - 8s/epoch - 33ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0396 - categorical_accuracy: 0.9874 - val_loss: 0.0962 - val_categorical_accuracy: 0.9753 - 8s/epoch - 34ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0329 - categorical_accuracy: 0.9897 - val_loss: 0.0884 - val_categorical_accuracy: 0.9778 - 7s/epoch - 29ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0275 - categorical_accuracy: 0.9911 - val_loss: 0.0910 - val_categorical_accuracy: 0.9767 - 8s/epoch - 34ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 7s - loss: 0.0243 - categorical_accuracy: 0.9922 - val_loss: 0.0932 - val_categorical_accuracy: 0.9776 - 7s/epoch - 31ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 7s - loss: 0.0212 - categorical_accuracy: 0.9928 - val_loss: 0.0892 - val_categorical_accuracy: 0.9795 - 7s/epoch - 29ms/step\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  975     1     1    0    0    1    1    1    0    0\n",
            "1    0  1130     1    1    0    0    2    0    1    0\n",
            "2    2     1  1019    0    2    0    0    4    4    0\n",
            "3    0     0     5  977    0   16    0    5    1    6\n",
            "4    3     0     3    0  967    0    3    1    0    5\n",
            "5    2     0     0    3    1  880    1    0    4    1\n",
            "6    9     3     1    1    4    9  931    0    0    0\n",
            "7    3     4    11    0    1    0    0  998    4    7\n",
            "8    8     2     5    4    2   13    0    2  931    7\n",
            "9    5     2     0    1   10    1    0    3    0  987\n",
            "7\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3043 - categorical_accuracy: 0.9053 - val_loss: 0.2521 - val_categorical_accuracy: 0.9228 - 9s/epoch - 38ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1178 - categorical_accuracy: 0.9645 - val_loss: 0.1726 - val_categorical_accuracy: 0.9476 - 7s/epoch - 28ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0809 - categorical_accuracy: 0.9753 - val_loss: 0.1228 - val_categorical_accuracy: 0.9629 - 8s/epoch - 34ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0613 - categorical_accuracy: 0.9806 - val_loss: 0.1213 - val_categorical_accuracy: 0.9650 - 7s/epoch - 30ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 7s - loss: 0.0477 - categorical_accuracy: 0.9851 - val_loss: 0.0898 - val_categorical_accuracy: 0.9745 - 7s/epoch - 29ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0398 - categorical_accuracy: 0.9873 - val_loss: 0.0920 - val_categorical_accuracy: 0.9762 - 8s/epoch - 34ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0334 - categorical_accuracy: 0.9894 - val_loss: 0.0831 - val_categorical_accuracy: 0.9784 - 7s/epoch - 28ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0298 - categorical_accuracy: 0.9907 - val_loss: 0.0897 - val_categorical_accuracy: 0.9768 - 8s/epoch - 34ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 7s - loss: 0.0252 - categorical_accuracy: 0.9921 - val_loss: 0.0805 - val_categorical_accuracy: 0.9800 - 7s/epoch - 29ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 8s - loss: 0.0236 - categorical_accuracy: 0.9924 - val_loss: 0.0900 - val_categorical_accuracy: 0.9769 - 8s/epoch - 32ms/step\n",
            "Epoch 11/15\n",
            "235/235 - 8s - loss: 0.0205 - categorical_accuracy: 0.9936 - val_loss: 0.0905 - val_categorical_accuracy: 0.9803 - 8s/epoch - 33ms/step\n",
            "Epoch 12/15\n",
            "235/235 - 7s - loss: 0.0189 - categorical_accuracy: 0.9940 - val_loss: 0.0859 - val_categorical_accuracy: 0.9801 - 7s/epoch - 29ms/step\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  974     1     1    0    0    0    1    0    2    1\n",
            "1    0  1127     2    1    0    1    2    0    2    0\n",
            "2    3     1  1015    2    2    0    2    3    3    1\n",
            "3    0     0     5  989    1    3    1    4    4    3\n",
            "4    0     0     3    0  973    0    3    0    0    3\n",
            "5    1     0     0    2    1  884    2    0    1    1\n",
            "6    1     2     0    0    6   14  935    0    0    0\n",
            "7    2     3    11    0    6    0    0  992    3   11\n",
            "8    0     1     4    7    9    5    1    3  939    5\n",
            "9    1     3     1    2   24    2    1    2    0  973\n",
            "8\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3034 - categorical_accuracy: 0.9068 - val_loss: 0.2623 - val_categorical_accuracy: 0.9186 - 9s/epoch - 39ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1199 - categorical_accuracy: 0.9632 - val_loss: 0.1439 - val_categorical_accuracy: 0.9547 - 7s/epoch - 29ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0796 - categorical_accuracy: 0.9750 - val_loss: 0.0810 - val_categorical_accuracy: 0.9745 - 8s/epoch - 33ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0612 - categorical_accuracy: 0.9817 - val_loss: 0.0891 - val_categorical_accuracy: 0.9731 - 7s/epoch - 28ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0477 - categorical_accuracy: 0.9855 - val_loss: 0.0849 - val_categorical_accuracy: 0.9749 - 8s/epoch - 33ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 7s - loss: 0.0391 - categorical_accuracy: 0.9873 - val_loss: 0.0730 - val_categorical_accuracy: 0.9802 - 7s/epoch - 29ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0340 - categorical_accuracy: 0.9892 - val_loss: 0.1088 - val_categorical_accuracy: 0.9691 - 7s/epoch - 31ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0287 - categorical_accuracy: 0.9911 - val_loss: 0.0966 - val_categorical_accuracy: 0.9779 - 8s/epoch - 34ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 7s - loss: 0.0249 - categorical_accuracy: 0.9921 - val_loss: 0.0798 - val_categorical_accuracy: 0.9812 - 7s/epoch - 28ms/step\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  975     0     1    0    0    0    2    1    1    0\n",
            "1    0  1126     1    1    0    0    2    0    5    0\n",
            "2    5     2  1005    5    1    0    1    3   10    0\n",
            "3    0     0     3  995    0    5    0    3    2    2\n",
            "4    1     0     1    0  969    0    4    0    1    6\n",
            "5    2     0     0    3    1  882    0    1    2    1\n",
            "6    2     2     0    0    4   22  927    0    1    0\n",
            "7    1     3    10    1    1    0    0  996    5   11\n",
            "8    3     0     2    3    2    6    0    2  950    6\n",
            "9    1     2     0    2   10    4    1    1    1  987\n",
            "9\n",
            "Epoch 1/15\n",
            "235/235 - 10s - loss: 0.3041 - categorical_accuracy: 0.9061 - val_loss: 0.2268 - val_categorical_accuracy: 0.9298 - 10s/epoch - 41ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1177 - categorical_accuracy: 0.9649 - val_loss: 0.1514 - val_categorical_accuracy: 0.9558 - 7s/epoch - 30ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0809 - categorical_accuracy: 0.9757 - val_loss: 0.1274 - val_categorical_accuracy: 0.9617 - 8s/epoch - 33ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0610 - categorical_accuracy: 0.9815 - val_loss: 0.1038 - val_categorical_accuracy: 0.9704 - 7s/epoch - 30ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 7s - loss: 0.0485 - categorical_accuracy: 0.9857 - val_loss: 0.0803 - val_categorical_accuracy: 0.9780 - 7s/epoch - 31ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0391 - categorical_accuracy: 0.9876 - val_loss: 0.0807 - val_categorical_accuracy: 0.9783 - 8s/epoch - 34ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0325 - categorical_accuracy: 0.9898 - val_loss: 0.0780 - val_categorical_accuracy: 0.9801 - 7s/epoch - 28ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0291 - categorical_accuracy: 0.9904 - val_loss: 0.0818 - val_categorical_accuracy: 0.9790 - 8s/epoch - 34ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 7s - loss: 0.0264 - categorical_accuracy: 0.9914 - val_loss: 0.0806 - val_categorical_accuracy: 0.9804 - 7s/epoch - 29ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 8s - loss: 0.0217 - categorical_accuracy: 0.9927 - val_loss: 0.0848 - val_categorical_accuracy: 0.9809 - 8s/epoch - 32ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6     7    8    9\n",
            "0  971     1     0    0    1    3    1     0    2    1\n",
            "1    0  1129     1    1    0    1    1     0    2    0\n",
            "2    3     1  1014    1    1    2    1     3    6    0\n",
            "3    0     0     3  993    0    7    0     4    2    1\n",
            "4    1     0     6    0  963    0    2     2    2    6\n",
            "5    2     0     0    4    1  884    0     0    0    1\n",
            "6    7     2     0    1    3   20  925     0    0    0\n",
            "7    2     1    10    0    2    1    0  1002    4    6\n",
            "8    4     1     2    4    0   11    1     2  945    4\n",
            "9    1     2     0    4    8    4    1     4    2  983\n",
            "10\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3031 - categorical_accuracy: 0.9057 - val_loss: 0.2092 - val_categorical_accuracy: 0.9334 - 9s/epoch - 38ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 8s - loss: 0.1192 - categorical_accuracy: 0.9634 - val_loss: 0.1335 - val_categorical_accuracy: 0.9579 - 8s/epoch - 33ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0806 - categorical_accuracy: 0.9749 - val_loss: 0.1043 - val_categorical_accuracy: 0.9692 - 7s/epoch - 28ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 8s - loss: 0.0600 - categorical_accuracy: 0.9814 - val_loss: 0.0872 - val_categorical_accuracy: 0.9723 - 8s/epoch - 34ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 7s - loss: 0.0476 - categorical_accuracy: 0.9855 - val_loss: 0.0927 - val_categorical_accuracy: 0.9725 - 7s/epoch - 30ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0411 - categorical_accuracy: 0.9871 - val_loss: 0.1056 - val_categorical_accuracy: 0.9703 - 8s/epoch - 33ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 11s - loss: 0.0336 - categorical_accuracy: 0.9896 - val_loss: 0.0826 - val_categorical_accuracy: 0.9791 - 11s/epoch - 48ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 7s - loss: 0.0284 - categorical_accuracy: 0.9906 - val_loss: 0.0895 - val_categorical_accuracy: 0.9778 - 7s/epoch - 29ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 8s - loss: 0.0252 - categorical_accuracy: 0.9919 - val_loss: 0.0978 - val_categorical_accuracy: 0.9775 - 8s/epoch - 33ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 7s - loss: 0.0217 - categorical_accuracy: 0.9926 - val_loss: 0.0977 - val_categorical_accuracy: 0.9787 - 7s/epoch - 29ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  972     0     0    0    1    1    1    0    3    2\n",
            "1    0  1129     1    1    0    0    0    0    4    0\n",
            "2    4     2  1000    4    2    0    1    3   16    0\n",
            "3    0     0     7  985    0    4    0    2    3    9\n",
            "4    0     0     4    0  970    0    3    0    2    3\n",
            "5    2     0     0    4    1  877    1    0    5    2\n",
            "6    4     3     0    0    6   11  928    0    5    1\n",
            "7    1     2     9    1    7    0    0  983   10   15\n",
            "8    2     0     1    3    2    1    0    2  959    4\n",
            "9    0     2     0    0   15    2    0    3    3  984\n",
            "11\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3055 - categorical_accuracy: 0.9059 - val_loss: 0.2119 - val_categorical_accuracy: 0.9345 - 9s/epoch - 38ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 8s - loss: 0.1195 - categorical_accuracy: 0.9640 - val_loss: 0.1492 - val_categorical_accuracy: 0.9545 - 8s/epoch - 34ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0812 - categorical_accuracy: 0.9751 - val_loss: 0.1047 - val_categorical_accuracy: 0.9702 - 7s/epoch - 30ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0615 - categorical_accuracy: 0.9813 - val_loss: 0.0829 - val_categorical_accuracy: 0.9769 - 7s/epoch - 31ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0485 - categorical_accuracy: 0.9848 - val_loss: 0.0842 - val_categorical_accuracy: 0.9772 - 8s/epoch - 33ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 7s - loss: 0.0410 - categorical_accuracy: 0.9871 - val_loss: 0.1052 - val_categorical_accuracy: 0.9710 - 7s/epoch - 30ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 8s - loss: 0.0337 - categorical_accuracy: 0.9888 - val_loss: 0.0947 - val_categorical_accuracy: 0.9774 - 8s/epoch - 34ms/step\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  972     1     0    0    0    1    2    0    3    1\n",
            "1    0  1131     1    1    0    0    0    0    2    0\n",
            "2    2     3  1013    1    1    0    2    3    6    1\n",
            "3    0     0     5  981    0   11    0    3    7    3\n",
            "4    1     0     4    0  961    0    2    0    1   13\n",
            "5    2     0     0    2    1  881    1    0    3    2\n",
            "6    3     3     0    1    5   22  921    0    3    0\n",
            "7    2     4    10    2    8    0    0  968    9   25\n",
            "8    1     1     2    2    2    7    0    2  953    4\n",
            "9    0     2     0    1    9    4    0    0    0  993\n",
            "12\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3069 - categorical_accuracy: 0.9059 - val_loss: 0.2224 - val_categorical_accuracy: 0.9321 - 9s/epoch - 40ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1186 - categorical_accuracy: 0.9645 - val_loss: 0.1535 - val_categorical_accuracy: 0.9524 - 7s/epoch - 30ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0811 - categorical_accuracy: 0.9758 - val_loss: 0.1112 - val_categorical_accuracy: 0.9665 - 8s/epoch - 32ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 8s - loss: 0.0604 - categorical_accuracy: 0.9818 - val_loss: 0.1001 - val_categorical_accuracy: 0.9705 - 8s/epoch - 33ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 7s - loss: 0.0481 - categorical_accuracy: 0.9853 - val_loss: 0.0844 - val_categorical_accuracy: 0.9784 - 7s/epoch - 30ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0404 - categorical_accuracy: 0.9877 - val_loss: 0.0869 - val_categorical_accuracy: 0.9785 - 8s/epoch - 35ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0355 - categorical_accuracy: 0.9888 - val_loss: 0.0811 - val_categorical_accuracy: 0.9783 - 7s/epoch - 30ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 7s - loss: 0.0288 - categorical_accuracy: 0.9911 - val_loss: 0.0890 - val_categorical_accuracy: 0.9783 - 7s/epoch - 32ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 8s - loss: 0.0250 - categorical_accuracy: 0.9916 - val_loss: 0.0895 - val_categorical_accuracy: 0.9787 - 8s/epoch - 34ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 7s - loss: 0.0220 - categorical_accuracy: 0.9931 - val_loss: 0.0831 - val_categorical_accuracy: 0.9813 - 7s/epoch - 28ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  969     1     1    1    0    1    5    1    1    0\n",
            "1    0  1131     1    0    0    0    1    0    2    0\n",
            "2    0     3  1015    1    4    0    2    2    5    0\n",
            "3    0     0     4  994    0    1    0    2    1    8\n",
            "4    0     0     4    0  966    0    3    0    0    9\n",
            "5    2     0     0    9    2  868    4    0    3    4\n",
            "6    1     3     0    1    3    6  942    0    2    0\n",
            "7    1     5     9    0    5    0    0  984    4   20\n",
            "8    1     2     3    7    1    2    0    1  952    5\n",
            "9    0     2     0    6    7    1    0    1    0  992\n",
            "13\n",
            "Epoch 1/15\n",
            "235/235 - 8s - loss: 0.3082 - categorical_accuracy: 0.9041 - val_loss: 0.2282 - val_categorical_accuracy: 0.9264 - 8s/epoch - 36ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 8s - loss: 0.1194 - categorical_accuracy: 0.9637 - val_loss: 0.1418 - val_categorical_accuracy: 0.9572 - 8s/epoch - 34ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0800 - categorical_accuracy: 0.9756 - val_loss: 0.1084 - val_categorical_accuracy: 0.9661 - 7s/epoch - 29ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0599 - categorical_accuracy: 0.9816 - val_loss: 0.0878 - val_categorical_accuracy: 0.9739 - 7s/epoch - 31ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0467 - categorical_accuracy: 0.9856 - val_loss: 0.0806 - val_categorical_accuracy: 0.9776 - 8s/epoch - 32ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 6s - loss: 0.0390 - categorical_accuracy: 0.9878 - val_loss: 0.0951 - val_categorical_accuracy: 0.9752 - 6s/epoch - 28ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 8s - loss: 0.0332 - categorical_accuracy: 0.9893 - val_loss: 0.0839 - val_categorical_accuracy: 0.9782 - 8s/epoch - 34ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 7s - loss: 0.0295 - categorical_accuracy: 0.9901 - val_loss: 0.0776 - val_categorical_accuracy: 0.9797 - 7s/epoch - 29ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 8s - loss: 0.0253 - categorical_accuracy: 0.9916 - val_loss: 0.0891 - val_categorical_accuracy: 0.9798 - 8s/epoch - 34ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 7s - loss: 0.0231 - categorical_accuracy: 0.9925 - val_loss: 0.0920 - val_categorical_accuracy: 0.9800 - 7s/epoch - 29ms/step\n",
            "Epoch 11/15\n",
            "235/235 - 8s - loss: 0.0203 - categorical_accuracy: 0.9933 - val_loss: 0.0882 - val_categorical_accuracy: 0.9818 - 8s/epoch - 33ms/step\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6     7    8    9\n",
            "0  971     1     0    1    0    2    2     1    2    0\n",
            "1    0  1130     2    0    0    1    1     0    1    0\n",
            "2    0     4  1015    3    1    0    1     5    3    0\n",
            "3    0     0     6  984    0    8    0     6    2    4\n",
            "4    0     0     4    0  971    0    3     1    0    3\n",
            "5    2     0     0    3    0  885    0     0    1    1\n",
            "6    3     3     0    1    4   21  925     0    1    0\n",
            "7    1     3     9    0    3    1    0  1003    2    6\n",
            "8    0     0     1    4    3    6    0     3  954    3\n",
            "9    1     3     0    2   16    5    0     1    1  980\n",
            "14\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3052 - categorical_accuracy: 0.9066 - val_loss: 0.2132 - val_categorical_accuracy: 0.9349 - 9s/epoch - 39ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 8s - loss: 0.1195 - categorical_accuracy: 0.9646 - val_loss: 0.1235 - val_categorical_accuracy: 0.9623 - 8s/epoch - 34ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0805 - categorical_accuracy: 0.9750 - val_loss: 0.1022 - val_categorical_accuracy: 0.9687 - 7s/epoch - 29ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 8s - loss: 0.0613 - categorical_accuracy: 0.9811 - val_loss: 0.0846 - val_categorical_accuracy: 0.9732 - 8s/epoch - 35ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 7s - loss: 0.0463 - categorical_accuracy: 0.9856 - val_loss: 0.0907 - val_categorical_accuracy: 0.9741 - 7s/epoch - 31ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 7s - loss: 0.0384 - categorical_accuracy: 0.9878 - val_loss: 0.0964 - val_categorical_accuracy: 0.9742 - 7s/epoch - 28ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 8s - loss: 0.0344 - categorical_accuracy: 0.9894 - val_loss: 0.0859 - val_categorical_accuracy: 0.9763 - 8s/epoch - 33ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  966     1     1    0    1    4    4    0    1    2\n",
            "1    0  1129     1    1    0    1    1    0    2    0\n",
            "2    2     3  1007    3    1    0    2    1   12    1\n",
            "3    0     0     3  983    0   13    0    2    6    3\n",
            "4    0     0     3    0  968    0    4    1    0    6\n",
            "5    2     0     0    4    2  878    0    0    4    2\n",
            "6    4     3     0    0    6   25  916    0    4    0\n",
            "7    0     3    10    1   10    0    0  973    7   24\n",
            "8    1     0     2    1    3    4    0    2  955    6\n",
            "9    0     3     0    2   10    3    1    0    2  988\n",
            "15\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3050 - categorical_accuracy: 0.9061 - val_loss: 0.2546 - val_categorical_accuracy: 0.9228 - 9s/epoch - 36ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1184 - categorical_accuracy: 0.9644 - val_loss: 0.1290 - val_categorical_accuracy: 0.9601 - 7s/epoch - 30ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0795 - categorical_accuracy: 0.9760 - val_loss: 0.1088 - val_categorical_accuracy: 0.9689 - 8s/epoch - 34ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0597 - categorical_accuracy: 0.9820 - val_loss: 0.0844 - val_categorical_accuracy: 0.9755 - 7s/epoch - 28ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0471 - categorical_accuracy: 0.9856 - val_loss: 0.0983 - val_categorical_accuracy: 0.9730 - 8s/epoch - 34ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0405 - categorical_accuracy: 0.9874 - val_loss: 0.0735 - val_categorical_accuracy: 0.9801 - 8s/epoch - 33ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0333 - categorical_accuracy: 0.9896 - val_loss: 0.0885 - val_categorical_accuracy: 0.9774 - 7s/epoch - 28ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0287 - categorical_accuracy: 0.9906 - val_loss: 0.0955 - val_categorical_accuracy: 0.9768 - 8s/epoch - 33ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 7s - loss: 0.0248 - categorical_accuracy: 0.9920 - val_loss: 0.0951 - val_categorical_accuracy: 0.9787 - 7s/epoch - 28ms/step\n",
            "313/313 [==============================] - 3s 11ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  975     1     0    1    0    0    1    1    1    0\n",
            "1    0  1129     1    1    0    0    2    0    2    0\n",
            "2    4     3  1012    2    1    0    2    4    4    0\n",
            "3    0     0     8  988    0    5    0    3    1    5\n",
            "4    1     0     4    0  960    0    3    2    1   11\n",
            "5    2     0     0    3    1  882    1    1    1    1\n",
            "6    5     2     0    0    4   14  933    0    0    0\n",
            "7    2     3    14    0    3    0    0  980    6   20\n",
            "8    7     1     5    3    3    9    1    3  934    8\n",
            "9    3     2     0    2    5    2    0    0    1  994\n",
            "16\n",
            "Epoch 1/15\n",
            "235/235 - 7s - loss: 0.3076 - categorical_accuracy: 0.9046 - val_loss: 0.2480 - val_categorical_accuracy: 0.9269 - 7s/epoch - 32ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 8s - loss: 0.1215 - categorical_accuracy: 0.9629 - val_loss: 0.1599 - val_categorical_accuracy: 0.9536 - 8s/epoch - 33ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0819 - categorical_accuracy: 0.9755 - val_loss: 0.1002 - val_categorical_accuracy: 0.9693 - 7s/epoch - 31ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0613 - categorical_accuracy: 0.9811 - val_loss: 0.0977 - val_categorical_accuracy: 0.9730 - 7s/epoch - 28ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0492 - categorical_accuracy: 0.9848 - val_loss: 0.0856 - val_categorical_accuracy: 0.9762 - 8s/epoch - 33ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 7s - loss: 0.0413 - categorical_accuracy: 0.9868 - val_loss: 0.1082 - val_categorical_accuracy: 0.9707 - 7s/epoch - 28ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 8s - loss: 0.0343 - categorical_accuracy: 0.9892 - val_loss: 0.0757 - val_categorical_accuracy: 0.9785 - 8s/epoch - 33ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0294 - categorical_accuracy: 0.9903 - val_loss: 0.0873 - val_categorical_accuracy: 0.9797 - 8s/epoch - 34ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 7s - loss: 0.0266 - categorical_accuracy: 0.9911 - val_loss: 0.0902 - val_categorical_accuracy: 0.9783 - 7s/epoch - 29ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 8s - loss: 0.0234 - categorical_accuracy: 0.9924 - val_loss: 0.0868 - val_categorical_accuracy: 0.9809 - 8s/epoch - 33ms/step\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6     7    8    9\n",
            "0  969     1     1    1    1    3    1     2    0    1\n",
            "1    0  1131     1    1    0    1    1     0    0    0\n",
            "2    1     1  1014    2    1    0    2     5    5    1\n",
            "3    0     0     3  992    0    4    0     5    2    4\n",
            "4    0     0     5    0  965    0    3     0    0    9\n",
            "5    2     0     0    5    1  881    2     0    0    1\n",
            "6    2     4     1    1    7   16  925     0    2    0\n",
            "7    1     3     7    1    1    0    0  1006    2    7\n",
            "8    0     2     3    5    6   10    0     2  935   11\n",
            "9    0     3     0    1    8    4    0     1    1  991\n",
            "17\n",
            "Epoch 1/15\n",
            "235/235 - 8s - loss: 0.3069 - categorical_accuracy: 0.9053 - val_loss: 0.2350 - val_categorical_accuracy: 0.9275 - 8s/epoch - 34ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 8s - loss: 0.1197 - categorical_accuracy: 0.9638 - val_loss: 0.1701 - val_categorical_accuracy: 0.9483 - 8s/epoch - 34ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0798 - categorical_accuracy: 0.9752 - val_loss: 0.1328 - val_categorical_accuracy: 0.9594 - 7s/epoch - 31ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0614 - categorical_accuracy: 0.9813 - val_loss: 0.0929 - val_categorical_accuracy: 0.9727 - 7s/epoch - 30ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0487 - categorical_accuracy: 0.9845 - val_loss: 0.0906 - val_categorical_accuracy: 0.9768 - 8s/epoch - 34ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 7s - loss: 0.0393 - categorical_accuracy: 0.9880 - val_loss: 0.0787 - val_categorical_accuracy: 0.9799 - 7s/epoch - 29ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 8s - loss: 0.0333 - categorical_accuracy: 0.9889 - val_loss: 0.0791 - val_categorical_accuracy: 0.9796 - 8s/epoch - 34ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 7s - loss: 0.0300 - categorical_accuracy: 0.9904 - val_loss: 0.0812 - val_categorical_accuracy: 0.9821 - 7s/epoch - 29ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 8s - loss: 0.0246 - categorical_accuracy: 0.9920 - val_loss: 0.0834 - val_categorical_accuracy: 0.9792 - 8s/epoch - 32ms/step\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  974     1     0    2    0    0    1    0    1    1\n",
            "1    0  1130     1    1    0    0    2    0    1    0\n",
            "2    3     4  1010    2    1    0    1    3    8    0\n",
            "3    1     0     3  991    0    6    0    6    1    2\n",
            "4    0     0     5    0  971    0    2    0    0    4\n",
            "5    2     0     0    2    2  881    1    0    3    1\n",
            "6    3     3     0    0    9   20  922    0    1    0\n",
            "7    1     3    10    1    3    0    0  997    3   10\n",
            "8    4     1     4    7    3   14    0    2  933    6\n",
            "9    1     2     0    4   16    3    0    0    0  983\n",
            "18\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3035 - categorical_accuracy: 0.9062 - val_loss: 0.2454 - val_categorical_accuracy: 0.9265 - 9s/epoch - 37ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 8s - loss: 0.1185 - categorical_accuracy: 0.9642 - val_loss: 0.1079 - val_categorical_accuracy: 0.9662 - 8s/epoch - 33ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0812 - categorical_accuracy: 0.9760 - val_loss: 0.0989 - val_categorical_accuracy: 0.9702 - 7s/epoch - 28ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 8s - loss: 0.0612 - categorical_accuracy: 0.9812 - val_loss: 0.0857 - val_categorical_accuracy: 0.9739 - 8s/epoch - 33ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 7s - loss: 0.0486 - categorical_accuracy: 0.9844 - val_loss: 0.1030 - val_categorical_accuracy: 0.9703 - 7s/epoch - 30ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0393 - categorical_accuracy: 0.9876 - val_loss: 0.0762 - val_categorical_accuracy: 0.9795 - 8s/epoch - 34ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 8s - loss: 0.0312 - categorical_accuracy: 0.9901 - val_loss: 0.0846 - val_categorical_accuracy: 0.9781 - 8s/epoch - 32ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 7s - loss: 0.0288 - categorical_accuracy: 0.9906 - val_loss: 0.0807 - val_categorical_accuracy: 0.9797 - 7s/epoch - 29ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 8s - loss: 0.0262 - categorical_accuracy: 0.9918 - val_loss: 0.0851 - val_categorical_accuracy: 0.9795 - 8s/epoch - 33ms/step\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  974     1     0    1    0    1    1    0    1    1\n",
            "1    0  1129     1    1    0    0    2    0    2    0\n",
            "2    5     2  1006    6    2    0    1    4    6    0\n",
            "3    0     0     1  992    1    3    0    3    4    6\n",
            "4    1     0     3    0  966    0    3    0    0    9\n",
            "5    2     0     0    6    1  876    2    0    1    4\n",
            "6    5     2     0    1    4    9  936    0    1    0\n",
            "7    2     4     7    1    5    0    0  986    4   19\n",
            "8    4     2     1    5    4    6    1    3  938   10\n",
            "9    2     2     0    2    9    1    0    1    0  992\n",
            "19\n",
            "Epoch 1/15\n",
            "235/235 - 8s - loss: 0.3098 - categorical_accuracy: 0.9046 - val_loss: 0.1980 - val_categorical_accuracy: 0.9374 - 8s/epoch - 36ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 8s - loss: 0.1186 - categorical_accuracy: 0.9643 - val_loss: 0.1441 - val_categorical_accuracy: 0.9554 - 8s/epoch - 32ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0810 - categorical_accuracy: 0.9753 - val_loss: 0.1405 - val_categorical_accuracy: 0.9570 - 7s/epoch - 28ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 8s - loss: 0.0614 - categorical_accuracy: 0.9811 - val_loss: 0.1010 - val_categorical_accuracy: 0.9714 - 8s/epoch - 34ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 7s - loss: 0.0485 - categorical_accuracy: 0.9849 - val_loss: 0.0855 - val_categorical_accuracy: 0.9757 - 7s/epoch - 29ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0390 - categorical_accuracy: 0.9881 - val_loss: 0.0850 - val_categorical_accuracy: 0.9778 - 8s/epoch - 32ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0340 - categorical_accuracy: 0.9889 - val_loss: 0.0910 - val_categorical_accuracy: 0.9778 - 7s/epoch - 32ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 7s - loss: 0.0299 - categorical_accuracy: 0.9901 - val_loss: 0.0995 - val_categorical_accuracy: 0.9755 - 7s/epoch - 29ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 8s - loss: 0.0257 - categorical_accuracy: 0.9916 - val_loss: 0.0903 - val_categorical_accuracy: 0.9782 - 8s/epoch - 33ms/step\n",
            "313/313 [==============================] - 3s 10ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  975     1     1    0    0    1    1    1    0    0\n",
            "1    0  1129     2    0    0    0    2    0    2    0\n",
            "2    9     1  1011    0    3    0    2    3    3    0\n",
            "3    1     0     5  992    0    1    0    5    1    5\n",
            "4    1     0     3    0  968    0    2    0    0    8\n",
            "5    3     0     0    6    2  873    3    0    2    3\n",
            "6    6     2     0    1    4    7  937    0    1    0\n",
            "7    4     8     7    1    6    0    0  987    4   11\n",
            "8   12     1     3    3    6    7    3    2  926   11\n",
            "9    4     2     0    2   16    1    0    0    0  984\n",
            "20\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3040 - categorical_accuracy: 0.9068 - val_loss: 0.2175 - val_categorical_accuracy: 0.9322 - 9s/epoch - 37ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1187 - categorical_accuracy: 0.9641 - val_loss: 0.1304 - val_categorical_accuracy: 0.9581 - 7s/epoch - 28ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0783 - categorical_accuracy: 0.9765 - val_loss: 0.1043 - val_categorical_accuracy: 0.9679 - 8s/epoch - 32ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 8s - loss: 0.0609 - categorical_accuracy: 0.9818 - val_loss: 0.0824 - val_categorical_accuracy: 0.9761 - 8s/epoch - 34ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 7s - loss: 0.0480 - categorical_accuracy: 0.9853 - val_loss: 0.0874 - val_categorical_accuracy: 0.9747 - 7s/epoch - 30ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0394 - categorical_accuracy: 0.9874 - val_loss: 0.0824 - val_categorical_accuracy: 0.9766 - 8s/epoch - 33ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0326 - categorical_accuracy: 0.9899 - val_loss: 0.0887 - val_categorical_accuracy: 0.9768 - 7s/epoch - 29ms/step\n",
            "313/313 [==============================] - 4s 12ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  970     1     1    0    1    0    2    0    2    3\n",
            "1    0  1127     1    1    0    0    2    0    3    1\n",
            "2    3     1  1010    2    4    0    2    4    6    0\n",
            "3    0     0     4  996    0    2    0    2    1    5\n",
            "4    0     0     3    0  967    0    4    1    1    6\n",
            "5    2     0     0    9    3  871    3    0    2    2\n",
            "6    3     2     0    1    7   16  929    0    0    0\n",
            "7    0     3    11    1    7    0    0  986    5   15\n",
            "8    1     1     4   15    6    6    1    2  929    9\n",
            "9    0     2     0    3   18    1    1    1    0  983\n",
            "21\n",
            "Epoch 1/15\n",
            "235/235 - 7s - loss: 0.3069 - categorical_accuracy: 0.9051 - val_loss: 0.2784 - val_categorical_accuracy: 0.9173 - 7s/epoch - 31ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 8s - loss: 0.1206 - categorical_accuracy: 0.9639 - val_loss: 0.1637 - val_categorical_accuracy: 0.9506 - 8s/epoch - 32ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0801 - categorical_accuracy: 0.9755 - val_loss: 0.0913 - val_categorical_accuracy: 0.9731 - 8s/epoch - 34ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0616 - categorical_accuracy: 0.9812 - val_loss: 0.0909 - val_categorical_accuracy: 0.9732 - 7s/epoch - 29ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0476 - categorical_accuracy: 0.9851 - val_loss: 0.0790 - val_categorical_accuracy: 0.9793 - 8s/epoch - 33ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 7s - loss: 0.0408 - categorical_accuracy: 0.9870 - val_loss: 0.0770 - val_categorical_accuracy: 0.9798 - 7s/epoch - 29ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 8s - loss: 0.0335 - categorical_accuracy: 0.9895 - val_loss: 0.0752 - val_categorical_accuracy: 0.9804 - 8s/epoch - 34ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0290 - categorical_accuracy: 0.9906 - val_loss: 0.0898 - val_categorical_accuracy: 0.9771 - 8s/epoch - 32ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 7s - loss: 0.0274 - categorical_accuracy: 0.9916 - val_loss: 0.0884 - val_categorical_accuracy: 0.9784 - 7s/epoch - 29ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 8s - loss: 0.0239 - categorical_accuracy: 0.9921 - val_loss: 0.0891 - val_categorical_accuracy: 0.9796 - 8s/epoch - 34ms/step\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6     7    8    9\n",
            "0  975     1     0    0    0    1    1     0    1    1\n",
            "1    0  1128     1    1    0    0    1     0    4    0\n",
            "2    2     2  1003   10    2    0    1     4    8    0\n",
            "3    0     0     2  999    0    1    0     2    2    4\n",
            "4    0     0     4    0  965    0    3     1    0    9\n",
            "5    2     0     0   10    2  871    0     0    5    2\n",
            "6    3     3     0    1    5   19  926     0    1    0\n",
            "7    0     2     7    0    3    0    0  1000    5   11\n",
            "8    2     1     2    8    6    6    1     3  937    8\n",
            "9    1     2     0    3    8    0    0     2    1  992\n",
            "22\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3054 - categorical_accuracy: 0.9053 - val_loss: 0.2336 - val_categorical_accuracy: 0.9271 - 9s/epoch - 39ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1205 - categorical_accuracy: 0.9633 - val_loss: 0.1098 - val_categorical_accuracy: 0.9673 - 7s/epoch - 29ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0810 - categorical_accuracy: 0.9757 - val_loss: 0.1000 - val_categorical_accuracy: 0.9717 - 8s/epoch - 34ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0602 - categorical_accuracy: 0.9815 - val_loss: 0.0831 - val_categorical_accuracy: 0.9752 - 7s/epoch - 29ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 7s - loss: 0.0476 - categorical_accuracy: 0.9855 - val_loss: 0.0869 - val_categorical_accuracy: 0.9757 - 7s/epoch - 29ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0408 - categorical_accuracy: 0.9874 - val_loss: 0.0800 - val_categorical_accuracy: 0.9788 - 8s/epoch - 34ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0331 - categorical_accuracy: 0.9895 - val_loss: 0.0894 - val_categorical_accuracy: 0.9777 - 7s/epoch - 29ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0296 - categorical_accuracy: 0.9901 - val_loss: 0.0936 - val_categorical_accuracy: 0.9772 - 8s/epoch - 34ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 7s - loss: 0.0252 - categorical_accuracy: 0.9920 - val_loss: 0.0952 - val_categorical_accuracy: 0.9778 - 7s/epoch - 29ms/step\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  969     1     1    0    2    1    1    0    2    3\n",
            "1    0  1127     2    1    0    1    2    0    2    0\n",
            "2    0     2  1014    1    3    0    2    5    5    0\n",
            "3    0     0     2  986    0    7    0    5    1    9\n",
            "4    1     0     2    0  968    0    4    0    0    7\n",
            "5    2     0     0    3    1  879    1    1    3    2\n",
            "6    3     2     0    1   10   23  916    0    3    0\n",
            "7    3     1    11    2    6    0    0  987    3   15\n",
            "8    1     0     3    5    7    7    0    2  942    7\n",
            "9    0     2     0    1   13    2    0    1    0  990\n",
            "23\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3047 - categorical_accuracy: 0.9063 - val_loss: 0.2185 - val_categorical_accuracy: 0.9304 - 9s/epoch - 40ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1186 - categorical_accuracy: 0.9640 - val_loss: 0.1226 - val_categorical_accuracy: 0.9614 - 7s/epoch - 29ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0795 - categorical_accuracy: 0.9756 - val_loss: 0.1019 - val_categorical_accuracy: 0.9690 - 8s/epoch - 34ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0599 - categorical_accuracy: 0.9811 - val_loss: 0.1002 - val_categorical_accuracy: 0.9718 - 7s/epoch - 28ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0478 - categorical_accuracy: 0.9845 - val_loss: 0.0855 - val_categorical_accuracy: 0.9766 - 8s/epoch - 33ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 7s - loss: 0.0392 - categorical_accuracy: 0.9881 - val_loss: 0.0824 - val_categorical_accuracy: 0.9794 - 7s/epoch - 29ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 8s - loss: 0.0335 - categorical_accuracy: 0.9890 - val_loss: 0.0898 - val_categorical_accuracy: 0.9765 - 8s/epoch - 32ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0295 - categorical_accuracy: 0.9904 - val_loss: 0.0825 - val_categorical_accuracy: 0.9792 - 8s/epoch - 33ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 7s - loss: 0.0242 - categorical_accuracy: 0.9919 - val_loss: 0.0860 - val_categorical_accuracy: 0.9806 - 7s/epoch - 28ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6     7    8    9\n",
            "0  972     1     0    0    0    0    3     1    2    1\n",
            "1    0  1129     1    2    0    0    1     0    2    0\n",
            "2    2     2  1012    5    2    0    2     5    2    0\n",
            "3    0     0     1  994    0    3    0     5    1    6\n",
            "4    0     0     1    0  969    0    5     1    0    6\n",
            "5    2     0     0    7    1  875    2     1    3    1\n",
            "6    2     3     0    1    3   12  937     0    0    0\n",
            "7    1     2     8    1    2    0    0  1008    0    6\n",
            "8    4     3     6   11    6    7    0     5  925    7\n",
            "9    0     3     0    3   13    1    1     3    0  985\n",
            "24\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3009 - categorical_accuracy: 0.9074 - val_loss: 0.2629 - val_categorical_accuracy: 0.9214 - 9s/epoch - 39ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 8s - loss: 0.1178 - categorical_accuracy: 0.9646 - val_loss: 0.1250 - val_categorical_accuracy: 0.9622 - 8s/epoch - 34ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0792 - categorical_accuracy: 0.9762 - val_loss: 0.1085 - val_categorical_accuracy: 0.9670 - 7s/epoch - 28ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 8s - loss: 0.0592 - categorical_accuracy: 0.9815 - val_loss: 0.1035 - val_categorical_accuracy: 0.9705 - 8s/epoch - 34ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0478 - categorical_accuracy: 0.9851 - val_loss: 0.0776 - val_categorical_accuracy: 0.9791 - 8s/epoch - 33ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 7s - loss: 0.0388 - categorical_accuracy: 0.9881 - val_loss: 0.0939 - val_categorical_accuracy: 0.9756 - 7s/epoch - 30ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 8s - loss: 0.0327 - categorical_accuracy: 0.9896 - val_loss: 0.0873 - val_categorical_accuracy: 0.9795 - 8s/epoch - 34ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 7s - loss: 0.0293 - categorical_accuracy: 0.9908 - val_loss: 0.0881 - val_categorical_accuracy: 0.9798 - 7s/epoch - 29ms/step\n",
            "313/313 [==============================] - 4s 14ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6     7    8    9\n",
            "0  974     2     1    0    1    0    0     1    1    0\n",
            "1    0  1133     1    1    0    0    0     0    0    0\n",
            "2    1     2  1017    1    2    0    1     5    3    0\n",
            "3    0     0     1  990    0    6    0     5    0    8\n",
            "4    1     0     2    0  968    0    4     1    0    6\n",
            "5    2     0     0    5    1  880    1     1    0    2\n",
            "6    4     3     0    1    8   23  918     0    1    0\n",
            "7    0     3     7    1    3    0    0  1006    1    7\n",
            "8    4     5     3    7    6    7    1     2  930    9\n",
            "9    3     3     0    2   15    1    0     3    0  982\n",
            "25\n",
            "Epoch 1/15\n",
            "235/235 - 10s - loss: 0.3056 - categorical_accuracy: 0.9056 - val_loss: 0.2168 - val_categorical_accuracy: 0.9316 - 10s/epoch - 41ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1208 - categorical_accuracy: 0.9639 - val_loss: 0.1253 - val_categorical_accuracy: 0.9603 - 7s/epoch - 29ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0824 - categorical_accuracy: 0.9751 - val_loss: 0.0852 - val_categorical_accuracy: 0.9737 - 8s/epoch - 35ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0611 - categorical_accuracy: 0.9810 - val_loss: 0.0758 - val_categorical_accuracy: 0.9774 - 7s/epoch - 30ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 7s - loss: 0.0483 - categorical_accuracy: 0.9847 - val_loss: 0.0855 - val_categorical_accuracy: 0.9765 - 7s/epoch - 31ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0410 - categorical_accuracy: 0.9869 - val_loss: 0.0799 - val_categorical_accuracy: 0.9787 - 8s/epoch - 33ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0345 - categorical_accuracy: 0.9893 - val_loss: 0.0827 - val_categorical_accuracy: 0.9785 - 7s/epoch - 28ms/step\n",
            "313/313 [==============================] - 3s 10ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  973     1     0    1    1    0    1    0    2    1\n",
            "1    0  1130     2    1    0    0    0    0    2    0\n",
            "2    4     3  1009    3    3    0    1    5    4    0\n",
            "3    0     0     2  992    0    2    0    7    2    5\n",
            "4    0     0     4    0  971    0    3    1    0    3\n",
            "5    2     0     0    9    1  873    0    0    3    4\n",
            "6    6     3     1    1    9   18  917    0    3    0\n",
            "7    2     5     7    0    5    0    0  997    4    8\n",
            "8    1     1     4    8    9    4    0    2  938    7\n",
            "9    2     2     0    4   14    0    0    2    0  985\n",
            "26\n",
            "Epoch 1/15\n",
            "235/235 - 10s - loss: 0.3059 - categorical_accuracy: 0.9066 - val_loss: 0.2249 - val_categorical_accuracy: 0.9314 - 10s/epoch - 42ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1167 - categorical_accuracy: 0.9645 - val_loss: 0.1307 - val_categorical_accuracy: 0.9594 - 7s/epoch - 30ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0794 - categorical_accuracy: 0.9758 - val_loss: 0.1112 - val_categorical_accuracy: 0.9664 - 7s/epoch - 30ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 8s - loss: 0.0607 - categorical_accuracy: 0.9815 - val_loss: 0.0892 - val_categorical_accuracy: 0.9746 - 8s/epoch - 34ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 7s - loss: 0.0479 - categorical_accuracy: 0.9847 - val_loss: 0.1021 - val_categorical_accuracy: 0.9722 - 7s/epoch - 29ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0408 - categorical_accuracy: 0.9870 - val_loss: 0.0951 - val_categorical_accuracy: 0.9753 - 8s/epoch - 33ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0333 - categorical_accuracy: 0.9889 - val_loss: 0.0882 - val_categorical_accuracy: 0.9768 - 7s/epoch - 30ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0290 - categorical_accuracy: 0.9903 - val_loss: 0.0862 - val_categorical_accuracy: 0.9786 - 8s/epoch - 33ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 8s - loss: 0.0252 - categorical_accuracy: 0.9917 - val_loss: 0.0834 - val_categorical_accuracy: 0.9806 - 8s/epoch - 33ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 7s - loss: 0.0223 - categorical_accuracy: 0.9926 - val_loss: 0.0991 - val_categorical_accuracy: 0.9774 - 7s/epoch - 29ms/step\n",
            "Epoch 11/15\n",
            "235/235 - 8s - loss: 0.0220 - categorical_accuracy: 0.9926 - val_loss: 0.0869 - val_categorical_accuracy: 0.9802 - 8s/epoch - 33ms/step\n",
            "Epoch 12/15\n",
            "235/235 - 7s - loss: 0.0191 - categorical_accuracy: 0.9937 - val_loss: 0.0959 - val_categorical_accuracy: 0.9809 - 7s/epoch - 28ms/step\n",
            "313/313 [==============================] - 4s 11ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  972     1     0    1    0    1    2    1    1    1\n",
            "1    0  1131     1    1    1    1    0    0    0    0\n",
            "2    1     3  1013    4    1    0    1    5    3    1\n",
            "3    0     0     2  996    0    4    0    4    3    1\n",
            "4    2     0     3    0  960    0    3    1    0   13\n",
            "5    2     0     0    8    1  872    3    0    2    4\n",
            "6    2     3     0    1    5   10  937    0    0    0\n",
            "7    2     2     9    0    1    0    0  998    2   14\n",
            "8    2     2     4    5    4    7    2    2  932   14\n",
            "9    0     2     0    1    5    1    0    2    0  998\n",
            "27\n",
            "Epoch 1/15\n",
            "235/235 - 8s - loss: 0.3026 - categorical_accuracy: 0.9064 - val_loss: 0.2070 - val_categorical_accuracy: 0.9366 - 8s/epoch - 32ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 8s - loss: 0.1187 - categorical_accuracy: 0.9639 - val_loss: 0.1501 - val_categorical_accuracy: 0.9564 - 8s/epoch - 33ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 7s - loss: 0.0803 - categorical_accuracy: 0.9752 - val_loss: 0.1025 - val_categorical_accuracy: 0.9691 - 7s/epoch - 32ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0589 - categorical_accuracy: 0.9818 - val_loss: 0.0864 - val_categorical_accuracy: 0.9752 - 7s/epoch - 30ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0458 - categorical_accuracy: 0.9857 - val_loss: 0.0844 - val_categorical_accuracy: 0.9771 - 8s/epoch - 33ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 7s - loss: 0.0405 - categorical_accuracy: 0.9872 - val_loss: 0.0803 - val_categorical_accuracy: 0.9786 - 7s/epoch - 30ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 8s - loss: 0.0325 - categorical_accuracy: 0.9894 - val_loss: 0.0838 - val_categorical_accuracy: 0.9787 - 8s/epoch - 34ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 7s - loss: 0.0287 - categorical_accuracy: 0.9904 - val_loss: 0.0928 - val_categorical_accuracy: 0.9777 - 7s/epoch - 30ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 8s - loss: 0.0241 - categorical_accuracy: 0.9925 - val_loss: 0.0766 - val_categorical_accuracy: 0.9813 - 8s/epoch - 32ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 8s - loss: 0.0240 - categorical_accuracy: 0.9923 - val_loss: 0.0834 - val_categorical_accuracy: 0.9791 - 8s/epoch - 34ms/step\n",
            "Epoch 11/15\n",
            "235/235 - 7s - loss: 0.0195 - categorical_accuracy: 0.9935 - val_loss: 0.0884 - val_categorical_accuracy: 0.9798 - 7s/epoch - 29ms/step\n",
            "Epoch 12/15\n",
            "235/235 - 8s - loss: 0.0178 - categorical_accuracy: 0.9938 - val_loss: 0.0723 - val_categorical_accuracy: 0.9843 - 8s/epoch - 34ms/step\n",
            "Epoch 13/15\n",
            "235/235 - 7s - loss: 0.0166 - categorical_accuracy: 0.9945 - val_loss: 0.0853 - val_categorical_accuracy: 0.9827 - 7s/epoch - 29ms/step\n",
            "Epoch 14/15\n",
            "235/235 - 7s - loss: 0.0161 - categorical_accuracy: 0.9948 - val_loss: 0.0934 - val_categorical_accuracy: 0.9811 - 7s/epoch - 30ms/step\n",
            "Epoch 15/15\n",
            "235/235 - 8s - loss: 0.0160 - categorical_accuracy: 0.9948 - val_loss: 0.0947 - val_categorical_accuracy: 0.9817 - 8s/epoch - 34ms/step\n",
            "313/313 [==============================] - 3s 11ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  973     0     1    0    0    0    2    0    3    1\n",
            "1    0  1129     1    1    0    0    2    0    2    0\n",
            "2    2     3  1018    1    2    0    0    2    4    0\n",
            "3    1     0     2  993    0    6    0    2    3    3\n",
            "4    0     0     5    0  967    0    1    0    1    8\n",
            "5    1     0     0    6    1  880    0    0    3    1\n",
            "6    3     2     1    1    8   16  924    0    3    0\n",
            "7    1     3    10    1    2    0    0  992    3   16\n",
            "8    1     1     2    4    3    5    1    2  950    5\n",
            "9    1     2     0    1    9    4    0    0    1  991\n",
            "28\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3044 - categorical_accuracy: 0.9062 - val_loss: 0.2542 - val_categorical_accuracy: 0.9230 - 9s/epoch - 38ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1202 - categorical_accuracy: 0.9636 - val_loss: 0.1372 - val_categorical_accuracy: 0.9584 - 7s/epoch - 28ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0824 - categorical_accuracy: 0.9751 - val_loss: 0.1229 - val_categorical_accuracy: 0.9630 - 8s/epoch - 33ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0606 - categorical_accuracy: 0.9814 - val_loss: 0.0828 - val_categorical_accuracy: 0.9760 - 7s/epoch - 30ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0482 - categorical_accuracy: 0.9850 - val_loss: 0.0925 - val_categorical_accuracy: 0.9746 - 8s/epoch - 33ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0408 - categorical_accuracy: 0.9874 - val_loss: 0.0835 - val_categorical_accuracy: 0.9782 - 8s/epoch - 33ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0328 - categorical_accuracy: 0.9894 - val_loss: 0.0783 - val_categorical_accuracy: 0.9801 - 7s/epoch - 29ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0286 - categorical_accuracy: 0.9908 - val_loss: 0.0755 - val_categorical_accuracy: 0.9813 - 8s/epoch - 34ms/step\n",
            "Epoch 9/15\n",
            "235/235 - 7s - loss: 0.0259 - categorical_accuracy: 0.9916 - val_loss: 0.0786 - val_categorical_accuracy: 0.9809 - 7s/epoch - 29ms/step\n",
            "Epoch 10/15\n",
            "235/235 - 8s - loss: 0.0232 - categorical_accuracy: 0.9926 - val_loss: 0.0821 - val_categorical_accuracy: 0.9800 - 8s/epoch - 33ms/step\n",
            "Epoch 11/15\n",
            "235/235 - 8s - loss: 0.0219 - categorical_accuracy: 0.9926 - val_loss: 0.0903 - val_categorical_accuracy: 0.9809 - 8s/epoch - 32ms/step\n",
            "313/313 [==============================] - 3s 10ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  974     1     0    0    0    1    2    0    1    1\n",
            "1    0  1128     1    1    0    0    2    0    3    0\n",
            "2    2     2  1020    1    1    0    0    5    1    0\n",
            "3    0     0     6  986    0    8    0    4    0    6\n",
            "4    1     0     1    0  971    0    4    0    0    5\n",
            "5    2     0     0    4    1  881    1    0    2    1\n",
            "6    4     2     0    0    4   16  932    0    0    0\n",
            "7    2     5    10    0    2    0    0  993    4   12\n",
            "8    1     1     4    7    5   12    2    3  932    7\n",
            "9    0     2     0    2   11    1    0    1    0  992\n",
            "29\n",
            "Epoch 1/15\n",
            "235/235 - 9s - loss: 0.3035 - categorical_accuracy: 0.9064 - val_loss: 0.2945 - val_categorical_accuracy: 0.9143 - 9s/epoch - 39ms/step\n",
            "Epoch 2/15\n",
            "235/235 - 7s - loss: 0.1198 - categorical_accuracy: 0.9638 - val_loss: 0.1689 - val_categorical_accuracy: 0.9473 - 7s/epoch - 29ms/step\n",
            "Epoch 3/15\n",
            "235/235 - 8s - loss: 0.0820 - categorical_accuracy: 0.9756 - val_loss: 0.1402 - val_categorical_accuracy: 0.9571 - 8s/epoch - 33ms/step\n",
            "Epoch 4/15\n",
            "235/235 - 7s - loss: 0.0615 - categorical_accuracy: 0.9813 - val_loss: 0.0903 - val_categorical_accuracy: 0.9729 - 7s/epoch - 29ms/step\n",
            "Epoch 5/15\n",
            "235/235 - 8s - loss: 0.0493 - categorical_accuracy: 0.9849 - val_loss: 0.0780 - val_categorical_accuracy: 0.9777 - 8s/epoch - 33ms/step\n",
            "Epoch 6/15\n",
            "235/235 - 8s - loss: 0.0405 - categorical_accuracy: 0.9869 - val_loss: 0.0855 - val_categorical_accuracy: 0.9762 - 8s/epoch - 34ms/step\n",
            "Epoch 7/15\n",
            "235/235 - 7s - loss: 0.0351 - categorical_accuracy: 0.9887 - val_loss: 0.0946 - val_categorical_accuracy: 0.9750 - 7s/epoch - 28ms/step\n",
            "Epoch 8/15\n",
            "235/235 - 8s - loss: 0.0286 - categorical_accuracy: 0.9908 - val_loss: 0.0795 - val_categorical_accuracy: 0.9805 - 8s/epoch - 33ms/step\n",
            "313/313 [==============================] - 4s 12ms/step\n",
            "CM: \n",
            "      0     1     2    3    4    5    6    7    8    9\n",
            "0  969     1     0    1    1    2    4    1    1    0\n",
            "1    0  1131     1    0    0    1    1    0    1    0\n",
            "2    2     5  1009    2    3    0    1    5    4    1\n",
            "3    0     0     2  992    0    5    0    5    0    6\n",
            "4    0     0     5    0  970    0    2    0    0    5\n",
            "5    1     0     0    5    1  881    1    0    1    2\n",
            "6    3     3     0    1    4   15  930    0    2    0\n",
            "7    2     3    11    0    4    0    0  993    2   13\n",
            "8    1     1     2    4    1   12    0    3  943    7\n",
            "9    0     2     0    3   10    5    1    1    0  987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"This is the average confusion matrix using 30 runs\")\n",
        "round(cm_new,1)"
      ],
      "metadata": {
        "id": "auDUR-MjOIZ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "645ceda7-bdb9-46aa-9905-fb0b6895e18f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the average confusion matrix using 30 runs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0       1       2      3      4      5      6      7      8      9\n",
              "0  972.3     0.9     0.5    0.5    0.4    1.1    1.6    0.5    1.3    0.9\n",
              "1    0.0  1129.2     1.2    0.9    0.1    0.3    1.3    0.0    2.0    0.0\n",
              "2    2.5     2.3  1012.4    2.4    1.8    0.1    1.4    3.7    5.1    0.3\n",
              "3    0.1     0.0     3.6  990.1    0.1    5.5    0.0    3.7    2.2    4.7\n",
              "4    0.7     0.0     3.4    0.0  966.4    0.0    3.0    0.6    0.5    7.4\n",
              "5    2.0     0.0     0.0    5.1    1.2  878.1    1.2    0.3    2.3    1.8\n",
              "6    4.0     2.7     0.2    0.7    5.6   16.6  926.8    0.0    1.5    0.0\n",
              "7    1.4     3.2     9.4    0.7    3.7    0.1    0.0  991.4    4.0   14.0\n",
              "8    3.0     1.1     3.0    5.4    4.1    7.4    0.5    2.4  940.1    7.1\n",
              "9    1.0     2.2     0.0    2.3   10.9    2.3    0.3    1.3    0.5  988.1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c7f3d54-e677-4e97-b140-759ba5dd7820\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>972.3</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1129.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1012.4</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>5.1</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>990.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>5.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>2.2</td>\n",
              "      <td>4.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>966.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>7.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>878.1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.7</td>\n",
              "      <td>5.6</td>\n",
              "      <td>16.6</td>\n",
              "      <td>926.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.7</td>\n",
              "      <td>3.7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>991.4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>7.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>940.1</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>10.9</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>988.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c7f3d54-e677-4e97-b140-759ba5dd7820')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c7f3d54-e677-4e97-b140-759ba5dd7820 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c7f3d54-e677-4e97-b140-759ba5dd7820');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above confusion matrix matches the last saved version exactly!  Therefore the 30 replicates were exactly reproducible.  "
      ],
      "metadata": {
        "id": "PMVwcj1AyFL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "Xj_022l2RUVb",
        "outputId": "f61a7f7e-adf5-4463-c02f-7e3b06e23efd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0            1            2           3           4           5  \\\n",
              "0  972.300000     0.933333     0.466667    0.500000    0.400000    1.066667   \n",
              "1    0.033333  1129.200000     1.200000    0.866667    0.066667    0.333333   \n",
              "2    2.533333     2.300000  1012.400000    2.433333    1.800000    0.100000   \n",
              "3    0.100000     0.000000     3.633333  990.133333    0.066667    5.466667   \n",
              "4    0.700000     0.000000     3.433333    0.000000  966.400000    0.033333   \n",
              "5    2.000000     0.000000     0.000000    5.100000    1.200000  878.100000   \n",
              "6    4.000000     2.666667     0.166667    0.733333    5.600000   16.566667   \n",
              "7    1.366667     3.200000     9.433333    0.733333    3.733333    0.100000   \n",
              "8    3.000000     1.133333     2.966667    5.366667    4.066667    7.366667   \n",
              "9    1.033333     2.200000     0.033333    2.266667   10.933333    2.300000   \n",
              "\n",
              "            6           7           8           9  \n",
              "0    1.633333    0.466667    1.333333    0.900000  \n",
              "1    1.300000    0.000000    1.966667    0.033333  \n",
              "2    1.366667    3.700000    5.066667    0.300000  \n",
              "3    0.033333    3.700000    2.166667    4.700000  \n",
              "4    3.000000    0.600000    0.466667    7.366667  \n",
              "5    1.233333    0.266667    2.266667    1.833333  \n",
              "6  926.766667    0.000000    1.466667    0.033333  \n",
              "7    0.000000  991.400000    4.033333   14.000000  \n",
              "8    0.500000    2.400000  940.100000    7.100000  \n",
              "9    0.300000    1.333333    0.500000  988.100000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c975b52b-2f52-4e6d-9623-13cea7c1dd67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>972.300000</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.066667</td>\n",
              "      <td>1.633333</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.033333</td>\n",
              "      <td>1129.200000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.966667</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.533333</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>1012.400000</td>\n",
              "      <td>2.433333</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.366667</td>\n",
              "      <td>3.700000</td>\n",
              "      <td>5.066667</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.633333</td>\n",
              "      <td>990.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>5.466667</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>3.700000</td>\n",
              "      <td>2.166667</td>\n",
              "      <td>4.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.433333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>966.400000</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>7.366667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>878.100000</td>\n",
              "      <td>1.233333</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>2.266667</td>\n",
              "      <td>1.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>16.566667</td>\n",
              "      <td>926.766667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.466667</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.366667</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>9.433333</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>3.733333</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>991.400000</td>\n",
              "      <td>4.033333</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.133333</td>\n",
              "      <td>2.966667</td>\n",
              "      <td>5.366667</td>\n",
              "      <td>4.066667</td>\n",
              "      <td>7.366667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>940.100000</td>\n",
              "      <td>7.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.033333</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>2.266667</td>\n",
              "      <td>10.933333</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>988.100000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c975b52b-2f52-4e6d-9623-13cea7c1dd67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c975b52b-2f52-4e6d-9623-13cea7c1dd67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c975b52b-2f52-4e6d-9623-13cea7c1dd67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Open a file and use dump()\n",
        "with open('file.pkl', 'wb') as file:\n",
        "      \n",
        "    # A new file will be created\n",
        "    pickle.dump(cm_new, file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Open the file in binary mode\n",
        "with open('file.pkl', 'rb') as file:\n",
        "      \n",
        "    # Call load method to deserialze\n",
        "    myvar_cm = pickle.load(file)\n",
        "  \n",
        "    print(myvar_cm)\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.download( \"file.pkl\" )  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "Tx57LwySh507",
        "outputId": "428017fc-3d58-49ab-806b-742f7d7e064e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            0            1            2           3           4           5  \\\n",
            "0  972.300000     0.933333     0.466667    0.500000    0.400000    1.066667   \n",
            "1    0.033333  1129.200000     1.200000    0.866667    0.066667    0.333333   \n",
            "2    2.533333     2.300000  1012.400000    2.433333    1.800000    0.100000   \n",
            "3    0.100000     0.000000     3.633333  990.133333    0.066667    5.466667   \n",
            "4    0.700000     0.000000     3.433333    0.000000  966.400000    0.033333   \n",
            "5    2.000000     0.000000     0.000000    5.100000    1.200000  878.100000   \n",
            "6    4.000000     2.666667     0.166667    0.733333    5.600000   16.566667   \n",
            "7    1.366667     3.200000     9.433333    0.733333    3.733333    0.100000   \n",
            "8    3.000000     1.133333     2.966667    5.366667    4.066667    7.366667   \n",
            "9    1.033333     2.200000     0.033333    2.266667   10.933333    2.300000   \n",
            "\n",
            "            6           7           8           9  \n",
            "0    1.633333    0.466667    1.333333    0.900000  \n",
            "1    1.300000    0.000000    1.966667    0.033333  \n",
            "2    1.366667    3.700000    5.066667    0.300000  \n",
            "3    0.033333    3.700000    2.166667    4.700000  \n",
            "4    3.000000    0.600000    0.466667    7.366667  \n",
            "5    1.233333    0.266667    2.266667    1.833333  \n",
            "6  926.766667    0.000000    1.466667    0.033333  \n",
            "7    0.000000  991.400000    4.033333   14.000000  \n",
            "8    0.500000    2.400000  940.100000    7.100000  \n",
            "9    0.300000    1.333333    0.500000  988.100000  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_260b7a59-107e-4c95-94ff-7a1b9b3f38a0\", \"file.pkl\", 1427)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Started at 10:43 AM  ended at 11:27 "
      ],
      "metadata": {
        "id": "Fn9dceO1i6w1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ctime()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tCnra4oQi80O",
        "outputId": "f206b204-3e1a-4a49-ece4-f13db19eac05"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tue Feb  7 16:49:05 2023'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many categories are there in the test set?\n",
        "\n",
        "truth_num_per_category = Y_test.sum(axis=0)"
      ],
      "metadata": {
        "id": "id_ythTutuo3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I'm actually surprised this ended up working ( I double checked in excel)\n",
        "cm_percents = cm_new/truth_num_per_category\n",
        "\n",
        "with open('cm_percents.pkl', 'wb') as file:\n",
        "      \n",
        "    # A new file will be created\n",
        "    pickle.dump(cm_percents, file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Open the file in binary mode\n",
        "with open('cm_percents.pkl', 'rb') as file:\n",
        "      \n",
        "    # Call load method to deserialze\n",
        "    myvar_cm_percents = pickle.load(file)\n",
        "  \n",
        "    print(cm_percents)\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.download( \"cm_percents.pkl\" )  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "2gj0l_18uBgm",
        "outputId": "97ac3c66-12a0-4344-e444-aec3eed0e960"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0         1         2         3         4         5         6  \\\n",
            "0  0.992143  0.000822  0.000452  0.000495  0.000407  0.001196  0.001705   \n",
            "1  0.000034  0.994890  0.001163  0.000858  0.000068  0.000374  0.001357   \n",
            "2  0.002585  0.002026  0.981008  0.002409  0.001833  0.000112  0.001427   \n",
            "3  0.000102  0.000000  0.003521  0.980330  0.000068  0.006129  0.000035   \n",
            "4  0.000714  0.000000  0.003327  0.000000  0.984114  0.000037  0.003132   \n",
            "5  0.002041  0.000000  0.000000  0.005050  0.001222  0.984417  0.001287   \n",
            "6  0.004082  0.002349  0.000161  0.000726  0.005703  0.018572  0.967397   \n",
            "7  0.001395  0.002819  0.009141  0.000726  0.003802  0.000112  0.000000   \n",
            "8  0.003061  0.000999  0.002875  0.005314  0.004141  0.008259  0.000522   \n",
            "9  0.001054  0.001938  0.000032  0.002244  0.011134  0.002578  0.000313   \n",
            "\n",
            "          7         8         9  \n",
            "0  0.000454  0.001369  0.000892  \n",
            "1  0.000000  0.002019  0.000033  \n",
            "2  0.003599  0.005202  0.000297  \n",
            "3  0.003599  0.002225  0.004658  \n",
            "4  0.000584  0.000479  0.007301  \n",
            "5  0.000259  0.002327  0.001817  \n",
            "6  0.000000  0.001506  0.000033  \n",
            "7  0.964397  0.004141  0.013875  \n",
            "8  0.002335  0.965195  0.007037  \n",
            "9  0.001297  0.000513  0.979286  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_531f1884-66a4-4d26-b72a-800faf92a0df\", \"cm_percents.pkl\", 1427)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest Classification Accuracy is "
      ],
      "metadata": {
        "id": "QNA5nkIhunO4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pVUAj50zzz5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To reference later: \n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb#scrollTo=UJ589fn8ST3x\n",
        "\n",
        "To train a model with class weights:\n",
        "\n",
        "```\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "weighted_model = make_model()\n",
        "weighted_model.load_weights(initial_weights)\n",
        "\n",
        "weighted_history = weighted_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stopping],\n",
        "    validation_data=(val_features, val_labels),\n",
        "\n",
        "    # The class weights go here\n",
        "    class_weight=class_weight)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "iLEt0OL5ziEq"
      }
    }
  ]
}