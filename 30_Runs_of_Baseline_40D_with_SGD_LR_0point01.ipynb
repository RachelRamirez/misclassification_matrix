{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachelRamirez/misclassification_matrix/blob/main/30_Runs_of_Baseline_40D_with_SGD_LR_0point01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to change the local time in Google Colab\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/US/Eastern /etc/localtime\n",
        "!date\n",
        "\n",
        "#If this doesn't show the local time correctly, then you need to restart.\n",
        "import time\n",
        "time.localtime(time.time())"
      ],
      "metadata": {
        "id": "7IIxYa87toxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcddd65-3065-4aa4-95ae-70c004e5799b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 03:17:38 PM EDT\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "time.struct_time(tm_year=2023, tm_mon=5, tm_mday=1, tm_hour=15, tm_min=17, tm_sec=38, tm_wday=0, tm_yday=121, tm_isdst=1)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "E_rggtG4FpXO"
      },
      "source": [
        "We'll start by writing a `.py` file which we'll import."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "id": "j2bDdei9Dxzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e597d42c-435d-4202-e5ab-8d8afeb12a12"
      },
      "source": [
        "%%writefile example.py\n",
        "def f():\n",
        "  print ('This is a function defined in a Python source file.')"
      ],
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting example.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ImportLibraries_DefineFunctions.py\n",
        "import time\n",
        "time.localtime(time.time())\n",
        "#For Reproducibility\n",
        "import numpy as np\n",
        "# np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "import tensorflow as tf\n",
        "# tf.random.set_seed(33)\n",
        "\n",
        "import random as python_random\n",
        "# python_random.seed(4)\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed\n",
        "seed = 342\n",
        "tf.keras.utils.set_random_seed(seed) #Possibly use next iteration if the above doesn't work   #This makes everything VERY DETERMINISTIC\n",
        "\n",
        "\n",
        "# Running more than once causes variation.  try adding this:\n",
        "# Set seed value\n",
        "seed_value = 56\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "print(\"TF version: \" , tf.__version__ )\n",
        "print(\"Keras version: \" , tf.keras.__version__ )\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "# from __future__ import print_function  #do i still need this?\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.utils import np_utils\n",
        "import keras.backend as K\n",
        "from itertools import product\n",
        "import functools\n",
        "from functools import partial\n",
        "from time import ctime\n",
        "from time import sleep\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd \n",
        "from sklearn.metrics import confusion_matrix, classification_report   #CLASSIFICATION REPORT IS FOR F1 SCORE AND BREAKOUT OF AL CATEGORIES ACCURACYS\n",
        "from  sklearn.utils import shuffle\n",
        "from sklearn.metrics import f1_score\n",
        " \n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "print(\"Finished Loading Libraries\")\n",
        "\n",
        "\n",
        "batch_size = 256 \n",
        "\n",
        "# I originally had it very  high batch size to reduce the variation in the data each batch and hope \n",
        "# it makes the model training more nearly identical which it did, then i bring it back down to something reasonable to get better results training the NN\n",
        "\n",
        "nb_classes = 10\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "# print(X_train.shape[0], 'train samples')\n",
        "# print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "#Create a Validation Set\n",
        "X_val = X_test[:7500]   #take the first 7500 for validation\n",
        "Y_val = Y_test[:7500]   #Take the first 7500 for validation\n",
        "y_val = y_test[:7500]\n",
        "\n",
        "X_test = X_test[7500:]  #Keep the last 2500 for test/holdout\n",
        "Y_test = Y_test[7500:]  #Keep the last 2500 for test/holdout\n",
        "y_test = y_test[7500:]\n",
        "\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_val.shape[0], 'validation samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "#Are the sets relatively balanced? Yes each category is between 8% and 11% per category\n",
        "print('Train', Y_train.sum(axis=0)/X_train.shape[0])\n",
        "print('Train # of 9s', Y_train.sum(axis=0)[9])\n",
        "print('Train # of 4s', Y_train.sum(axis=0)[4])\n",
        "\n",
        "print('Val', Y_val.sum(axis=0)/X_val.shape[0])\n",
        "print('Val # of 9s', Y_val.sum(axis=0)[9])\n",
        "print('Val # of 4s', Y_val.sum(axis=0)[4])\n",
        "\n",
        "print('Test', Y_test.sum(axis=0)/X_test.shape[0])\n",
        "print('Test  # of 9s', Y_test.sum(axis=0)[9])\n",
        "print('Test  # of 4s', Y_test.sum(axis=0)[4])\n",
        "\n",
        "#@title\n",
        "class WeightedCategoricalCrossentropy(tf.keras.losses.CategoricalCrossentropy):\n",
        "\n",
        "  def __init__(self, cost_mat, name='weighted_categorical_crossentropy', **kwargs):\n",
        "\n",
        "    cost_mat = np.array(cost_mat)   \n",
        "    ## when loading from config, self.cost_mat returns as a list, rather than an numpy array. \n",
        "    ## Adding the above line fixes this issue, enabling .ndim to call sucessfully. \n",
        "    ## However, this is probably not the best implementation\n",
        "    assert(cost_mat.ndim == 2)\n",
        "    assert(cost_mat.shape[0] == cost_mat.shape[1])\n",
        "    super().__init__(name=name, **kwargs)\n",
        "    self.cost_mat = K.cast_to_floatx(cost_mat)\n",
        "\n",
        "  def __call__(self, y_true, y_pred, sample_weight=None):\n",
        "    assert sample_weight is None, \"should only be derived from the cost matrix\"  \n",
        "    return super().__call__(\n",
        "        y_true=y_true, \n",
        "        y_pred=y_pred, \n",
        "        sample_weight=get_sample_weights(y_true, y_pred, self.cost_mat),\n",
        "    )\n",
        "\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    # Calling .update on the line above, during assignment, causes an error with config becoming None-type.\n",
        "    config.update({'cost_mat': (self.cost_mat)})\n",
        "    return config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    # something goes wrong here and changes self.cost_mat to a list variable.\n",
        "    # See above for temporary fix\n",
        "    return cls(**config)\n",
        "\n",
        "def get_sample_weights(y_true, y_pred, cost_m):\n",
        "    num_classes = len(cost_m)\n",
        "\n",
        "    y_pred.shape.assert_has_rank(2)\n",
        "    assert(y_pred.shape[1] == num_classes)\n",
        "    y_pred.shape.assert_is_compatible_with(y_true.shape)\n",
        "\n",
        "    y_pred = K.one_hot(K.argmax(y_pred), num_classes)\n",
        "\n",
        "    y_true_nk1 = K.expand_dims(y_true, 2)\n",
        "    y_pred_n1k = K.expand_dims(y_pred, 1)\n",
        "    cost_m_1kk = K.expand_dims(cost_m, 0)\n",
        "\n",
        "    sample_weights_nkk = cost_m_1kk * y_true_nk1 * y_pred_n1k\n",
        "    sample_weights_n = K.sum(sample_weights_nkk, axis=[1, 2])\n",
        "\n",
        "    return sample_weights_n\n",
        "\n",
        "\n",
        "# Register the loss in the Keras namespace to enable loading of the custom object.\n",
        "tf.keras.losses.WeightedCategoricalCrossentropy = WeightedCategoricalCrossentropy\n",
        " \n",
        "#@title\n",
        "def plot_model_history(model_history, nb_epoch, cm3): \n",
        "  # Parameters\n",
        "  # ----------\n",
        "  # model_history : keras.callbacks.History\n",
        "  #     The history object returned by the fit() method of the model.\n",
        "  # cm3 : 10x10 dataframe \n",
        "  #      10x10 dataframe of confusion matrix from predicted X_val categories\n",
        "  # nb_epoch = restored_weights : int\n",
        "  #     The epoch at which the weights were restored.\n",
        "  # tot_epochs : int\n",
        "  #     Calculated Total number of epochs for which the model was trained.\n",
        "  \n",
        "   \n",
        "  tot_epochs = max(model_history.epoch)+1  #if the total epochs ran is 28, it'll show up as 27 in the epoch object so we must add 1\n",
        "  print(\"Total Epochs: \", tot_epochs)\n",
        "\n",
        "  #if tot_epochs is the total number of epochs ran then early stop did not happen, and we need not minus patience\n",
        "  if tot_epochs == nb_epoch:\n",
        "    restored_weights = tot_epochs\n",
        "  else:\n",
        "    restored_weights  = tot_epochs-patience   #when using restore-best-weights and patience, it'll restore the best weights back\n",
        "  print(\"Restored weights at \", restored_weights, \"Patience used: \", patience)\n",
        "\n",
        "  fig = plt.figure(figsize=(20, 10)) # I don't think this works for some reason\n",
        "  fig, ax = plt.subplots(1,3)\n",
        "  ax[0].plot(range(1,tot_epochs+1), model_history.history['categorical_accuracy'], color='blue',             label='Training')\n",
        "  ax[0].plot(range(1,tot_epochs+1), model_history.history['val_categorical_accuracy'] , color='orange',             label='Validation')\n",
        "  ax[0].scatter((restored_weights), model_history.history['val_categorical_accuracy'][restored_weights-1] , color='orange')\n",
        "  ax[0].scatter(restored_weights, model_history.history['categorical_accuracy'][restored_weights-1], color='blue')\n",
        "  ax[0].annotate(text=str(restored_weights),  xy=(restored_weights, model_history.history['val_categorical_accuracy'][restored_weights-1]),\n",
        "                  textcoords=\"offset points\", xytext=(0,10), ha='center', color='black')\n",
        "  ax[0].legend()\n",
        "  ax[0].set_title('Training and Validation Accuracy')\n",
        "\n",
        "  ax[1].plot(range(1,tot_epochs+1), model_history.history['loss'], color= 'blue', label='Training')\n",
        "  ax[1].plot(range(1,tot_epochs+1), model_history.history['val_loss'], color='orange', label='Validation')\n",
        "  ax[1].scatter(restored_weights, model_history.history['loss'][restored_weights-1], color='blue')\n",
        "  ax[1].scatter((restored_weights), model_history.history['val_loss'][restored_weights-1] , color='orange')\n",
        "  ax[1].annotate(text=str(restored_weights),  xy=(restored_weights, model_history.history['val_loss'][restored_weights-1]),\n",
        "                  textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "  ax[1].legend()\n",
        "  ax[1].set_title('Training and Validation Loss')\n",
        "\n",
        "\n",
        "  cm3_wodiag = cm3*(np.ones((10,10)) - np.eye(10))\n",
        "\n",
        "  ax[2] = sns.heatmap(cm3_wodiag, annot=True, annot_kws={\"size\": 7},  fmt='g', cmap=sns.cm.rocket_r) # font size\n",
        "  ax[2].set_xlabel('Predicted Class')\n",
        "  ax[2].set_ylabel('True Class')\n",
        "  ax[2].set_title('# of misclassifications of 9 as 4 is '+str(cm3[4][9]))\n",
        "  cbar = ax[2].collections[0].colorbar\n",
        "  cbar.remove() # Just takes up valuable room and is worthless\n",
        "\n",
        "\n",
        "  plt.gcf().set_size_inches(15, 5)  # this works \n",
        "  # plt.gcf().suptitle(f\"Lambda Value {lambda_val} for {nb_epoch} Epochs and Patience {patience} \" )\n",
        "\n",
        "\n",
        "  #@title\n",
        "def create_model(): #Removed cost-matrix which is called up in the Compile Function and passed to the weighted-loss function\n",
        "  model = Sequential()\n",
        "  model.add(Dense(40, input_shape=(784,), kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(40, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(10,kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n",
        "  model.add(Activation('softmax'))\n",
        "  return model  #I removed Compile\n",
        "\n",
        "\n",
        "\n",
        "  #@title\n",
        "def log_confusion_matrix( epoch, logs):\n",
        "  # Use the model to predict the values from the validation dataset.\n",
        "  y_prediction = model.predict(X_val, verbose=0)     #I call it y_prediction3 because I just want to make sure this is  updated within and not interfering with the other prediction below\n",
        "  y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "\n",
        "  #Create confusion matrix \n",
        "  cm = confusion_matrix(y_val, y_prediction)\n",
        "  cm_array = np.asarray(cm)  #Indiv CM as array for storing\n",
        "  logs['9T_4P'] = cm[9,4]\n",
        "  logs['4T_9P'] = cm[4,9]\n",
        "\n",
        "  logs['0T_Acc'] = cm[0,0]/np.sum(cm[0])\n",
        "  logs['1T_Acc'] = cm[1,1]/np.sum(cm[1])\n",
        "  logs['2T_Acc'] = cm[2,2]/np.sum(cm[2])\n",
        "  logs['3T_Acc'] = cm[3,3]/np.sum(cm[3])\n",
        "  logs['4T_Acc'] = cm[4,4]/np.sum(cm[4])\n",
        "  logs['5T_Acc'] = cm[5,5]/np.sum(cm[5])\n",
        "  logs['6T_Acc'] = cm[6,6]/np.sum(cm[6])\n",
        "  logs['7T_Acc'] = cm[7,7]/np.sum(cm[7])\n",
        "  logs['8T_Acc'] = cm[8,8]/np.sum(cm[8])\n",
        "  logs['9T_Acc'] = cm[9,9]/np.sum(cm[9])\n",
        "\n",
        "\n",
        "  logs['cm_per_epoch'] = cm_array.reshape((1,100))\n",
        "\n",
        "#@title\n",
        "def log_classification_report( epoch, logs):\n",
        "  # Use the model to predict the values from the validation dataset.\n",
        "    y_prediction = model.predict(X_val, verbose=0)     #I call it y_prediction3 because I just want to make sure this is  updated within and not interfering with the other prediction below\n",
        "    y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "\n",
        "    #Create confusion matrix \n",
        "    cr = classification_report(y_val, y_prediction)\n",
        "    # print(cr)\n",
        "    logs['cr_per_epoch'] = cr \n",
        "\n",
        "\n",
        "    #@title\n",
        "def log_f1_score( epoch, logs):\n",
        "  # Use the model to predict the values from the validation dataset.\n",
        "    y_prediction = model.predict(X_val, verbose=0)     #I call it y_prediction3 because I just want to make sure this is  updated within and not interfering with the other prediction below\n",
        "    y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "\n",
        "\n",
        "    logs[\"f1_micro\"] = f1_score(y_val, y_prediction, average='micro')\n",
        "    logs[\"f1_macro\"] = f1_score(y_val, y_prediction, average='macro')\n",
        "    logs[\"f1_weighted\"] = f1_score(y_val, y_prediction, average='weighted')\n",
        "    logs[\"f1_notweighted\"] = f1_score(y_val, y_prediction, average=None)\n",
        "\n",
        "\n",
        "#@title\n",
        "def return_cm(model):\n",
        "  y_prediction = model.predict(X_val, verbose=0)\n",
        "  y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "  # Y_prediction = np_utils.to_categorical(y_prediction, nb_classes)\n",
        "\n",
        "  cm3 = confusion_matrix(y_val, y_prediction)\n",
        "  cm3 = pd.DataFrame(cm3, range(10),range(10))\n",
        "  return cm3\n",
        "\n",
        "  # # plt.figure(figsize = (4,4))\n",
        "  # # cm3\n",
        "  # sns.heatmap(cm3, annot=True, annot_kws={\"size\": 7},  fmt='g') # font size\n",
        "  # plt.show()\n",
        "  # # cm_using_weighted_new = cm3\n",
        " #@title\n",
        "\n",
        "def return_cr(model):\n",
        "  y_prediction = model.predict(X_val, verbose=0)\n",
        "  y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "  # Y_prediction = np_utils.to_categorical(y_prediction, nb_classes)\n",
        "\n",
        "  cr = classification_report(y_val, y_prediction)\n",
        "  print(cr)\n",
        "  return cr\n",
        "\n",
        "\n",
        "def return_f1score(model):\n",
        "  # sklearn.metrics.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')[source] \n",
        "  y_prediction = model.predict(X_val, verbose=0)\n",
        "  y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "  # Y_prediction = np_utils.to_categorical(y_prediction, nb_classes)\n",
        "\n",
        "  f1_notweighted = f1_score(y_val, y_prediction, average=None)\n",
        "  print(f1_notweighted)\n",
        "  f1_micro = f1_score(y_val, y_prediction, average='micro')\n",
        "  f1_macro = f1_score(y_val, y_prediction, average='macro')\n",
        "  f1_weighted = f1_score(y_val, y_prediction, average='weighted')\n",
        "  # print(\"Micro: \", f1_micro, \"Macro: \", f1_macro, \"Weighted: \", f1_weighted)\n",
        "  print(\"Micro: {:.5f} Macro: {:.5f} Weighted: {:.5f}\".format(f1_micro, f1_macro, f1_weighted))\n",
        "  # return f1\n",
        "\n",
        "\n",
        "\n",
        "#@title: plot_model_history_all\n",
        "def plot_model_history_all(model_history, nb_epoch=None, cm3=None): \n",
        "  # Parameters\n",
        "  # ----------\n",
        "  # tot_epochs : int\n",
        "  #     Total number of epochs for which the model was trained.\n",
        "  # model_history : keras.callbacks.History\n",
        "  #     The history object returned by the fit() method of the model.\n",
        "  # cm3 : 10x10 dataframe \n",
        "  #      10x10 dataframe of confusion matrix from predicted X_val categories\n",
        "  # restored_weights : int\n",
        "  #     The epoch at which the weights were restored.\n",
        "\n",
        "  \n",
        "\n",
        "  tot_epochs = max(model_history.epoch)+1  #if the total epochs ran is 28, it'll show up as 27 in the epoch object so we must add 1\n",
        "  # print(\"Total Epochs: \", tot_epochs)\n",
        "\n",
        "  #if tot_epochs is the total number of epochs ran then early stop did not happen, and we need not minus patience\n",
        "  if tot_epochs == nb_epoch:\n",
        "    restored_weights = tot_epochs\n",
        "  else:\n",
        "    restored_weights  = tot_epochs-patience   #when using restore-best-weights and patience, it'll restore the best weights back\n",
        "  # print(\"Restored weights at \", restored_weights, \"Patience used: \", patience)\n",
        "\n",
        "  ax[0].plot(range(1,tot_epochs+1), model_history.history['categorical_accuracy'], color='blue',           )\n",
        "  ax[0].plot(range(1,tot_epochs+1), model_history.history['val_categorical_accuracy'] , color='orange',    )\n",
        "  ax[0].scatter((restored_weights), model_history.history['val_categorical_accuracy'][restored_weights-1] , color='orange')\n",
        "  ax[0].scatter(restored_weights, model_history.history['categorical_accuracy'][restored_weights-1], color='blue')\n",
        "  ax[0].annotate(text=str(restored_weights),  xy=(restored_weights, model_history.history['val_categorical_accuracy'][restored_weights-1]),\n",
        "                  textcoords=\"offset points\", xytext=(0,10), ha='center', color='black')\n",
        "  # ax[0].legend()\n",
        "  ax[0].set_title('Training (Blue) and Validation (Orange) Accuracy', fontsize='8')\n",
        "\n",
        "  ax[1].plot(range(1,tot_epochs+1), model_history.history['loss'], color= 'blue',  )\n",
        "  ax[1].plot(range(1,tot_epochs+1), model_history.history['val_loss'], color='orange',  )\n",
        "  ax[1].scatter(restored_weights, model_history.history['loss'][restored_weights-1], color='blue')\n",
        "  ax[1].scatter((restored_weights), model_history.history['val_loss'][restored_weights-1] , color='orange')\n",
        "  ax[1].annotate(text=str(restored_weights),  xy=(restored_weights, model_history.history['val_loss'][restored_weights-1]),\n",
        "                  textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "  # ax[1].legend()\n",
        "  ax[1].set_title('Training (Blue) and Validation (Orange) Loss' , fontsize='8')\n",
        "\n",
        "\n",
        "  plt.gcf().set_size_inches(10, 5)  # this works \n",
        "  # plt.gcf().suptitle(f\"Lambda Value {lambda_val} for {nb_epoch} Epochs and Patience {patience} \" )\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## ----------------------------------------------------------------------------------------------\n",
        "## Tried to create a Callback to call the Classifcatinreport ever 5 epochs, but it doesnt work \n",
        "## because it cant see the model.  ZGoing back to trying to define the function to only be called every 5th epoch\n",
        "\n",
        "\n",
        "# class cr_callback(tf.keras.callbacks.Callback):\n",
        "\n",
        "#     def on_epoch_end(self, epoch, log=None):\n",
        "\n",
        "#         if epoch % 5 == 0:  # <- add additional condition here\n",
        "#             self._do_the_stuff()\n",
        "            \n",
        "            \n",
        "#     def _do_the_stuff(self, model):\n",
        "#         print('Do the stuff')\n",
        "#         y_prediction = model.predict(X_val, verbose=0)\n",
        "#         y_prediction  = np.argmax(y_prediction, axis=1)\n",
        "#         # Y_prediction = np_utils.to_categorical(y_prediction, nb_classes)\n",
        "#         cr = classification_report(y_val, y_prediction)\n",
        "#         logs['cr'] = cr\n",
        "\n",
        "#           # return cr\n",
        "        \n",
        "#     # def on_training_end(self, logs=None):\n",
        "#     #     self._do_the_stuff()\n",
        "\n",
        "\n",
        "\n",
        "## Saw this example ono Kaggle, but couldn't get it to work, it does give me an idea(if epoch==0)\n",
        "\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# class every10epochCallback(tf.keras.callbacks.Callback):\n",
        "#     def __init__(self, X_val, Y_val):\n",
        "#         super().__init__()\n",
        "#         self.X = X_val\n",
        "#         self.y = Y_val.argmax(axis=1)\n",
        "#     def on_epoch_begin(self, epoch, logs=None):\n",
        "#         if epoch == 0:\n",
        "#             return\n",
        "#         if epoch%10==0:\n",
        "#             pred = (model.predict(self.X))\n",
        "#             print('epoch: ',epoch,'  ,Accuracy:  ',accuracy_score(self.y,pred.argmax(axis=1)),' ')\n",
        "\n",
        "# model.fit(X_train, Y_train,batch_size=batch_size,epochs=10,verbose=0,  validation_data=(X_val, Y_val), shuffle=True, use_multiprocessing=True, \n",
        "#           callbacks=[every10epochCallback(X_val,Y_val)])\n"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3NeKdNCLXk1",
        "outputId": "5ddcc984-853c-4f00-c26b-3732fc6e15e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ImportLibraries_DefineFunctions.py\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oLPme2BLEDsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "628f4925-ccc4-483f-e81c-f0e94d5b4d6f",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# Bring the file into the local Python environment.\n",
        "execfile('ImportLibraries_DefineFunctions.py')\n",
        "\n",
        "# Call the function defined in the file.\n",
        "# f()\n",
        "time.localtime(time.time())\n"
      ],
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version:  2.12.0\n",
            "Keras version:  2.12.0\n",
            "Finished Loading Libraries\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "60000 train samples\n",
            "7500 validation samples\n",
            "2500 test samples\n",
            "Train [0.09871667 0.11236667 0.0993     0.10218333 0.09736667 0.09035\n",
            " 0.09863333 0.10441667 0.09751666 0.09915   ]\n",
            "Train # of 9s 5949.0\n",
            "Train # of 4s 5842.0\n",
            "Val [0.09586667 0.1132     0.10453334 0.10066666 0.09986667 0.09013333\n",
            " 0.09413333 0.1016     0.09746667 0.10253333]\n",
            "Val # of 9s 769.0\n",
            "Val # of 4s 749.0\n",
            "Test [0.1044 0.1144 0.0992 0.102  0.0932 0.0864 0.1008 0.1064 0.0972 0.096 ]\n",
            "Test  # of 9s 240.0\n",
            "Test  # of 4s 233.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "time.struct_time(tm_year=2023, tm_mon=5, tm_mday=1, tm_hour=15, tm_min=17, tm_sec=52, tm_wday=0, tm_yday=121, tm_isdst=1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# #As of 4/18 I am changing this code to save weights initially after five epochs using lambdavalue=1 initially\n",
        "\n",
        "# rms = RMSprop()  #https://keras.io/api/optimizers/rmsprop/ #default learning_rate=0.001\n",
        "sgd = SGD(learning_rate=0.01)\n",
        "\n",
        "patience = 0\n",
        "\n",
        "\n",
        "# SET THE IITIAL LAMBDA VALUE! \n",
        "cost_matrix = np.ones((10,10))\n",
        "lambda_val = 1\n",
        "\n",
        "Truth=9\n",
        "Predicted=4\n",
        "cost_matrix[Truth, Predicted] = lambda_val\n",
        "\n",
        "\n",
        "# # Define the per-epoch callback.\n",
        "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix, )\n",
        "# cr_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_classification_report, )\n",
        "# es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, verbose=1, restore_best_weights = True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ## Examples from TDS\n",
        "# from tensorflow.keras.callbacks import LambdaCallback\n",
        "# epoch_callback = LambdaCallback(\n",
        "#     on_epoch_begin=lambda epoch,logs: print('Starting Epoch {}!'.format(epoch+1))\n",
        "# )\n",
        "# batch_loss_callback = LambdaCallback(\n",
        "#     on_batch_end=lambda batch,logs: print('\\n After batch {}, the loss is {:7.2f}.'.format(batch, logs['loss']))\n",
        "# )\n",
        "# train_finish_callback = LambdaCallback(\n",
        "#     on_train_end=lambda logs: print('Training finished!')\n",
        "# )\n",
        "\n",
        "# # Lambda function using if else & else if\n",
        "# min = lambda a, b, c : f\"{a} is smaller\" if(a < b & b < c) \\\n",
        "#      else f\"{b} is smaller\"  if (b < c) else f\"{c} is smaller\" \n",
        "# print(min(40, 30, 10))\n",
        "\n",
        "epoch_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end = lambda epoch,logs: \n",
        "                                                   print(' Epoch {} modulus 10 is {}!'.format(epoch+1, (epoch+1)%10))  if(epoch+1)%10==0 else print(\"\", end=\" \")  )\n",
        "\n",
        "# cr_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end= lambda epoch, logs:\n",
        "# #                                                log_classification_report(epoch, logs) if(epoch+1)%5==0 else print(\" \") )\n",
        "#                                               #  return_cr if(epoch+1)%5==0 else print(\" \") )\n",
        "\n",
        "\n",
        "f1_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_f1_score)\n",
        "\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "# save the model weights\n",
        "model.save_weights('initial_0epochs.h5')\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss=WeightedCategoricalCrossentropy(cost_matrix), optimizer=sgd,  metrics='categorical_accuracy',)\n",
        "\n",
        "# model_history = model.fit(X_train, Y_train,  batch_size=batch_size, epochs=10, verbose=2,\n",
        "#         validation_data=(X_val, Y_val), shuffle=True, use_multiprocessing=True, callbacks = [ cm_callback, f1_callback])\n",
        "\n",
        "# model.save_weights('initial_10epochs.h5')\n",
        "\n",
        "# model.save_weights('initial_10epochs.h5')\n",
        "# model.save_weights('baseline_for_100epochs.h5')\n",
        "\n",
        "# save the model weights\n",
        "# model.save_weights('initial_150epochs.h5')\n",
        "\n",
        " \n",
        "# cr = return_cr(model)\n",
        "!date\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QcJ3LplOkww",
        "outputId": "4cf527f9-0442-4005-c34b-81a03be45d4a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 03:17:52 PM EDT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ImMl-yPWPfT0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below to generate variations of the model training / validation results after training with a cost matrix 30 times did not produce any variability.   Therefore I want to shuffle the training/validation deck randomly between training sessions to see if that helps introduce some randomness.  "
      ],
      "metadata": {
        "id": "RLYZ6gR4WjKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Training Runs - Commented out to ensure not run again when the notebook is saved with output"
      ],
      "metadata": {
        "id": "V_lUeeXP2Q5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This takes hours to run for about 40 replications so usually after running, I save the out put to GitHub for easy lookup later"
      ],
      "metadata": {
        "id": "owkJgwju2a52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from google.colab import files\n",
        "\n",
        "## -----------------------------------------------------------------------------------------------------\n",
        "## Now we need to load the weights of the model, and continue training with a different cost matrix\n",
        "## ------------------------------------------------------------------------------------------------------\n",
        "# load the model weights\n",
        "# model.load_weights('initial_5epochs.h5') \n",
        "\n",
        "cost_matrix = np.ones((10,10))\n",
        "\n",
        "model_history_all = []\n",
        "cm_all            = []\n",
        "\n",
        "# cost_list = [10, 100, 1000, 1] # Each one takes about 2 minutes 5*4*2=40 minutes for 5 costs/4 reps -- actually all took 40 reps took almost  1.5 hours\n",
        "cost_list = [1] # Each one takes about 2 minutes 5*4*2=40 minutes for 5 costs/4 reps -- actually all took 40 reps took almost  1.5 hours\n",
        "reps = 30\n",
        "\n",
        "for k in cost_list:\n",
        "  for i in range(reps):\n",
        "    print(\"starting rep \", i, \" for \", k , \"-cost.\")\n",
        "\n",
        "    cost_matrix[9,4] = k\n",
        "    model = create_model()\n",
        "\n",
        "    # model.load_weights('initial_10epochs.h5')\n",
        "\n",
        "    #I may need to re-initiate the optimizer to have a smaller learning rate\n",
        "    model.compile(loss=WeightedCategoricalCrossentropy(cost_matrix), optimizer=sgd,  metrics='categorical_accuracy',)\n",
        "    \n",
        "    nb_epoch = 110\n",
        "    # patience = 20\n",
        "\n",
        "    # es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, verbose=1, restore_best_weights = True)\n",
        "\n",
        "    X_train_shuffled = shuffle(X_train, random_state=42+i)\n",
        "    Y_train_shuffled = shuffle(Y_train, random_state=42+i)\n",
        " \n",
        "\n",
        "    history = model.fit(X_train_shuffled, Y_train_shuffled,          batch_size=batch_size, epochs=nb_epoch, verbose=0,\n",
        "            validation_data=(X_val, Y_val), shuffle=True, use_multiprocessing=True, callbacks = [ cm_callback, f1_callback, epoch_callback])\n",
        "\n",
        "    cm3 = return_cm(model)\n",
        "\n",
        "    del(history.model)\n",
        "    model_history_all.append(history)\n",
        "    cm_all.append(cm3)\n",
        "    ## Now I need to plot all of the \"model_history_all\"\n",
        "\n",
        "    import pickle\n",
        "\n",
        "    # save the variable to a pickle file\n",
        "    with open('baseline_models_lr01.pkl', 'wb') as f:\n",
        "        pickle.dump(model_history_all, f)\n",
        "\n",
        "    files.download('baseline_models_lr01.pkl')\n",
        "\n",
        "    with open('baseline_cms_lr01.pkl', 'wb') as f:\n",
        "        pickle.dump(cm_all, f)\n",
        "\n",
        "    files.download('baseline_cms_lr01.pkl')\n",
        "    !date\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # print(model_history_all) #18 items into _ is taking 1 hours and 3 minutes!  perhaps im not usng the right settings - i have no-accelerator on google colab"
      ],
      "metadata": {
        "id": "ZFgEx-T-fg28",
        "outputId": "7e9df85b-8cf0-4258-84d2-a2fe9ac23446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting rep  0  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_43d7e22c-7a4a-42f7-aba0-2c6e6bbdf03b\", \"baseline_models_lr01.pkl\", 146749)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_46fc7b40-e8b5-43e0-8ce5-e38668ef61b1\", \"baseline_cms_lr01.pkl\", 1384)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 03:21:35 PM EDT\n",
            "starting rep  1  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e478f39b-43df-4903-970c-dde9dfe1e04f\", \"baseline_models_lr01.pkl\", 293120)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5005bc13-96b2-41bf-a12e-42b45ca73f58\", \"baseline_cms_lr01.pkl\", 2338)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 03:25:58 PM EDT\n",
            "starting rep  2  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_963f1535-a283-4479-8bbf-88702a3c0f7c\", \"baseline_models_lr01.pkl\", 439490)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9733cb32-8fcd-43cc-8430-fef2d74872ad\", \"baseline_cms_lr01.pkl\", 3291)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 03:30:22 PM EDT\n",
            "starting rep  3  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_87ec3721-fd46-4526-81c7-fa8894d70a78\", \"baseline_models_lr01.pkl\", 585860)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e40907bc-fb9e-45fa-9049-c315fc41932a\", \"baseline_cms_lr01.pkl\", 4244)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 03:34:45 PM EDT\n",
            "starting rep  4  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0c455016-495b-49c4-a323-cc7faf1bb72d\", \"baseline_models_lr01.pkl\", 732239)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c1d73048-c359-4ef9-b756-3a769b057811\", \"baseline_cms_lr01.pkl\", 5197)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 03:38:14 PM EDT\n",
            "starting rep  5  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e5f2f866-e91d-4832-8805-73fe642cf1a8\", \"baseline_models_lr01.pkl\", 878609)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5ea14ad2-6b79-455c-82f2-d4acbb0f1608\", \"baseline_cms_lr01.pkl\", 6150)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 03:41:43 PM EDT\n",
            "starting rep  6  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b0d95b56-fd09-4277-b7cf-b24cb6208c07\", \"baseline_models_lr01.pkl\", 1024979)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0aa45f15-c799-4dbf-a293-389601b783cf\", \"baseline_cms_lr01.pkl\", 7103)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 03:46:07 PM EDT\n",
            "starting rep  7  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_311fbabb-7942-4d16-8cfb-68524eed00f2\", \"baseline_models_lr01.pkl\", 1171349)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_65a3f739-28bf-40b5-9a8b-9098f75a2544\", \"baseline_cms_lr01.pkl\", 8056)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 03:50:30 PM EDT\n",
            "starting rep  8  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b8aa9ddd-2a21-4f5d-bb9e-dd9dfffce27c\", \"baseline_models_lr01.pkl\", 1317728)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4178eee4-4a56-478f-8da8-d32e39ded3c6\", \"baseline_cms_lr01.pkl\", 9009)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 03:53:58 PM EDT\n",
            "starting rep  9  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_846e1965-f28e-4636-b5c9-70cec7d79581\", \"baseline_models_lr01.pkl\", 1464098)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7103ede8-99fd-4717-8e41-e58b7a268a02\", \"baseline_cms_lr01.pkl\", 9962)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 03:58:22 PM EDT\n",
            "starting rep  10  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9f77d6ef-d0bb-44cc-9148-0cba26ef2591\", \"baseline_models_lr01.pkl\", 1610468)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9635d24d-7cfb-4ba3-8490-a573430d8d9d\", \"baseline_cms_lr01.pkl\", 10915)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 04:02:46 PM EDT\n",
            "starting rep  11  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ebed49d8-d495-4fca-b6a2-23c046148e62\", \"baseline_models_lr01.pkl\", 1756838)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2acf3d65-60fa-4ba9-af64-6d8bf7fbcaad\", \"baseline_cms_lr01.pkl\", 11868)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 04:06:09 PM EDT\n",
            "starting rep  12  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a6d87797-ba40-4810-98f6-f46df3916905\", \"baseline_models_lr01.pkl\", 1903208)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8422a143-f9c4-4dea-b010-448f562578ba\", \"baseline_cms_lr01.pkl\", 12821)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 04:09:33 PM EDT\n",
            "starting rep  13  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n",
            "     Epoch 100 modulus 5 is 0!\n",
            "     Epoch 105 modulus 5 is 0!\n",
            "     Epoch 110 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3c874404-b3ef-4069-859a-7110ba989e27\", \"baseline_models_lr01.pkl\", 2049587)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_13c7b6e9-be42-4d8e-9f26-522c612bb16a\", \"baseline_cms_lr01.pkl\", 13774)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 01 May 2023 04:12:57 PM EDT\n",
            "starting rep  14  for  1 -cost.\n",
            "     Epoch 5 modulus 5 is 0!\n",
            "     Epoch 10 modulus 5 is 0!\n",
            "     Epoch 15 modulus 5 is 0!\n",
            "     Epoch 20 modulus 5 is 0!\n",
            "     Epoch 25 modulus 5 is 0!\n",
            "     Epoch 30 modulus 5 is 0!\n",
            "     Epoch 35 modulus 5 is 0!\n",
            "     Epoch 40 modulus 5 is 0!\n",
            "     Epoch 45 modulus 5 is 0!\n",
            "     Epoch 50 modulus 5 is 0!\n",
            "     Epoch 55 modulus 5 is 0!\n",
            "     Epoch 60 modulus 5 is 0!\n",
            "     Epoch 65 modulus 5 is 0!\n",
            "     Epoch 70 modulus 5 is 0!\n",
            "     Epoch 75 modulus 5 is 0!\n",
            "     Epoch 80 modulus 5 is 0!\n",
            "     Epoch 85 modulus 5 is 0!\n",
            "     Epoch 90 modulus 5 is 0!\n",
            "     Epoch 95 modulus 5 is 0!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f13cba0367b4>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     history = model.fit(X_train_shuffled, Y_train_shuffled,          batch_size=batch_size, epochs=nb_epoch, verbose=0,\n\u001b[0m\u001b[1;32m     41\u001b[0m             validation_data=(X_val, Y_val), shuffle=True, use_multiprocessing=True, callbacks = [ cm_callback, f1_callback, epoch_callback])\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                             \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         )\n\u001b[0;32m-> 1729\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1730\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2070\u001b[0m                         ):\n\u001b[1;32m   2071\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download the multiple runs and reps of Model History from training with different lambda values\n",
        "\n",
        "\n",
        "Also commented out because once everything is ran and saved, I don't want to accidentally save additional files"
      ],
      "metadata": {
        "id": "7z0g0vdr2w05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Download the history\n",
        "# from google.colab import files\n",
        "\n",
        "\n",
        "# #  SUPER IMPORTANT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "# for item in model_history_all:\n",
        "#   # item.history\n",
        "#   del item.model\n",
        "# # IF YOU DON'T DELETE THE MODEL YOU WON'T BE ABLE TO UNPICKLE YOUR RESULTS AND THAT WILL SUCK AND YOU WILL CRY\n",
        "# # and no ones wants to see you ugly cry over hours of wasted coding\n",
        "\n",
        "\n",
        "# import pickle\n",
        "\n",
        "# # create a variable\n",
        "# #model_history_all #50 items\n",
        "# #cm_all #50 items\n",
        "\n",
        "# # save the variable to a pickle file\n",
        "# with open('initial_10_secondphase_lambda_history.pkl', 'wb') as f:\n",
        "#     pickle.dump(model_history_all, f)\n",
        "\n",
        "# files.download('initial_10_secondphase_lambda_history.pkl')\n",
        "\n",
        "# with open('initial_10_secondphase_lambda_cm.pkl', 'wb') as f:\n",
        "#     pickle.dump(cm_all, f)\n",
        "\n",
        "# files.download('initial_10_secondphase_lambda_cm.pkl')\n"
      ],
      "metadata": {
        "id": "JLt4gsflmpun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Model History Variables from Pickle Files - must have weighted-categorical-accuracy defined"
      ],
      "metadata": {
        "id": "WPmV3ALQcsjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #Upload and save the history to variable \n",
        "# import pickle\n",
        "\n",
        "# # #load the pickle file\n",
        "# with open('initial_10_secondphase_lambda_history.pkl', 'rb') as handle:\n",
        "#     model_history_all = pickle.load(handle)\n",
        "\n",
        "# # import keras\n",
        "# # keras.models.load_model('initial_10_secondphase_lambda_history.pkl')\n",
        "# #use the loaded variable\n",
        "# print(model_history_all)\n",
        "\n",
        "# # #load the pickle file\n",
        "# with open('initial_10_secondphase_lambda_cm.pkl', 'rb') as handle:\n",
        "#     cm_all = pickle.load(handle)\n",
        "\n",
        "# # use the loaded variable\n",
        "# print(cm_all)\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "dXFoZGvVZ1oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example of how to concatenate multiple dataframes without causing an error.  Have to use pandas concatenate function."
      ],
      "metadata": {
        "id": "smchxHuJ3MsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pandas as pd\n",
        "\n",
        "# Create an empty dataframe\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Create a list of data\n",
        "data = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Use a for loop to fill the dataframe\n",
        "for x in data:\n",
        "    df = pd.concat([df, pd.DataFrame({'Number':[x], 'Square':[x**2]})], ignore_index=True)\n",
        "\n",
        "# Show the dataframe\n",
        "print(df)"
      ],
      "metadata": {
        "id": "oGYSkVqqk0xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the data into a Dataframe to be saved as a CSV file"
      ],
      "metadata": {
        "id": "IR2BLyPT3YFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#I want to break out the model_history and cm_history into a dataframe to be referenced by Cost and Rep\n",
        "import pandas as pd\n",
        "df = pd.DataFrame()\n",
        "count=1\n",
        "\n",
        "\n",
        "#It'd be better if i could refer to the \"cost\"/lambda2 as a variable in the model_history, \n",
        "# but i recreated it here\n",
        "# \n",
        "# cost_list = [10, 100, 1000, 1] # Each one takes about 2 minutes 5*4*2=40 minutes for 5 costs/4 reps -- actually all took 40 reps took almost  1.5 hours\n",
        "\n",
        "cost_list = [ 1]\n",
        "\n",
        "for k in cost_list:\n",
        "\n",
        "  \n",
        "#It'd be better if i could refer to the reps a variable in the model_history, \n",
        "# but i recreated it here as the range(10) that was originally used\n",
        "\n",
        "  for i in range(30):\n",
        "    # print(\"k: \", k, \"i: \", i)\n",
        "    df = pd.concat([df, pd.DataFrame({\"cost\": [k], \"rep\": [i],\n",
        "                                      \"model_history\": [model_history_all[count-1]],\n",
        "                                      # \"cm\": [cm_all[count-1]]\n",
        "                                      })] , \n",
        "                   ignore_index=True )\n",
        "    count+=1    \n",
        "\n",
        "\n",
        "# I create a dataframe with CSV but  don't save/download it \n",
        "df.to_csv('dataframe.csv',index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "Vw6G6TnPiVrJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "21835d82-40ef-4953-d4ef-e09d110539aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e21d7835ffd3>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# print(\"k: \", k, \"i: \", i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     df = pd.concat([df, pd.DataFrame({\"cost\": [k], \"rep\": [i],\n\u001b[0;32m---> 23\u001b[0;31m                                       \u001b[0;34m\"model_history\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_history_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                                       \u001b[0;31m# \"cm\": [cm_all[count-1]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                       })] , \n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #I want to add the 50 epochs i did of lambda1 = 1 using SGD to this list\n",
        "\n",
        "# df = pd.concat([df, pd.DataFrame({\"cost\": 1, \"rep\": 1,\n",
        "#                                       \"model_history\": [model_history],\n",
        "#                                       # \"cm\": [cm_all[count-1]]\n",
        "#                                       })] , \n",
        "#                    ignore_index=True )"
      ],
      "metadata": {
        "id": "lNqjDelK9VLl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Example of using df.groupby in a for loop to plot multiple types of data - doesn't include Label\n",
        "```\n",
        "for group in df.groupby(\"cost\"): \n",
        "  fig = plt.figure(figsize=(20, 10))  \n",
        "  fig, ax = plt.subplots(1,2) \n",
        "  ax[0].scatter(group[1][\"cost\"], group[1][\"quantity\"]) \n",
        "  ax[0].set_title(\"cost vs. quantity\") \n",
        "  ax[1].scatter(group[1][\"cost\"], group[1][\"revenue\"]) \n",
        "  ax[1].set_title(\"cost vs. revenue\")\n",
        "  plt.show()\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "zKCVz62dUpBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import time\n",
        "nb_epoch = 50\n",
        "patience = 0\n",
        "df.groupby(\"cost\")\n",
        "\n",
        "for x, group in df.groupby(\"cost\"):\n",
        "  fig = plt.figure(figsize=(20, 10)) \n",
        "  fig, ax = plt.subplots(1,2)\n",
        "  print(\"Group of Lambda-Value:\",   x)\n",
        "\n",
        "  # group\n",
        "  for item in group.model_history:\n",
        "    plot_model_history_all(item)    \n",
        "  plt.show()\n",
        "    # for item, cm3 in zip(group.model_history, group.cm):\n",
        "\n",
        "  #   # cm3_wodiag = cm3*(np.ones((10,10)) - np.eye(10))\n",
        "\n",
        "  #   # ax[2] = sns.heatmap(cm3_wodiag, annot=True, annot_kws={\"size\": 7},  fmt='g', cmap=sns.cm.rocket_r, cbar=False) # font size\n",
        "  #   # ax[2].set_xlabel('Predicted Class')\n",
        "  #   # ax[2].set_ylabel('True Class')\n",
        "  #   # ax[2].set_title('# of misclassifications of 9 as 4 is '+str(cm3[4][9]))\n",
        "  #   # cbar = ax[2].collections[0].colorbar\n",
        "  #   # cbar.remove() # Just takes up valuable room and is worthless\n",
        "  #   plot_model_history_all(item)    \n",
        "\n",
        "  #   #   ax[0].set_title(\"Lambda Value of\"+str(df[\"cost\"]))\n",
        "    \n",
        "  # #   # print(0+r,' to ', r+4+1)  #Correct"
      ],
      "metadata": {
        "id": "DSA5-95WZkj3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "3252cf00-974a-43df-8299-69a04809b70d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Group of Lambda-Value: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"model_history\"][0].history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocYFlDuP9qbL",
        "outputId": "dc78ba1b-f637-4e58-9d3d-3f4795b761b7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'categorical_accuracy', 'val_loss', 'val_categorical_accuracy', '9T_4P', '4T_9P', '0T_Acc', '1T_Acc', '2T_Acc', '3T_Acc', '4T_Acc', '5T_Acc', '6T_Acc', '7T_Acc', '8T_Acc', '9T_Acc', 'cm_per_epoch', 'f1_micro', 'f1_macro', 'f1_weighted', 'f1_notweighted'])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plots of the 14 (15?) completed runs look very similar.  The loss values, even with shuffling, are nearly identical at least within 0.01 for the first three epochs of runs 1 and 2 (haven't checked all, but the plot makes it look like the runs are nearly identical)"
      ],
      "metadata": {
        "id": "cnKubJqKCXOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"model_history\"][2].history[\"val_loss\"][0] - df[\"model_history\"][1].history[\"val_loss\"][0]\n",
        "df[\"model_history\"][2].history[\"val_loss\"][1] - df[\"model_history\"][1].history[\"val_loss\"][1]\n",
        "df[\"model_history\"][2].history[\"val_loss\"][2] - df[\"model_history\"][1].history[\"val_loss\"][2]"
      ],
      "metadata": {
        "id": "xRS1JJpl_yOq",
        "outputId": "be6142db-1abe-4c5d-f6a0-9c55a18de644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0016095638275146484"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is clear however is there doesn't seem to be any overfitting with the small learning rate, and that training could probably continue for another 20 epochs or more."
      ],
      "metadata": {
        "id": "-v1kwTOdC-Ds"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5orz3_QVDJws"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}